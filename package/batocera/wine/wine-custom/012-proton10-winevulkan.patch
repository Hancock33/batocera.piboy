diff --git a/configure.ac b/configure.ac
index 2f37f98890f..c93aab68305 100644
--- a/configure.ac
+++ b/configure.ac
@@ -3147,6 +3147,7 @@ WINE_CONFIG_MAKEFILE(dlls/setupapi/tests)
 WINE_CONFIG_MAKEFILE(dlls/setupx.dll16)
 WINE_CONFIG_MAKEFILE(dlls/sfc)
 WINE_CONFIG_MAKEFILE(dlls/sfc_os)
+WINE_CONFIG_MAKEFILE(dlls/sharedgpures.sys)
 WINE_CONFIG_MAKEFILE(dlls/shcore)
 WINE_CONFIG_MAKEFILE(dlls/shcore/tests)
 WINE_CONFIG_MAKEFILE(dlls/shdoclc)
diff --git a/dlls/sharedgpures.sys/Makefile.in b/dlls/sharedgpures.sys/Makefile.in
new file mode 100644
index 00000000000..9aca43fb45e
--- /dev/null
+++ b/dlls/sharedgpures.sys/Makefile.in
@@ -0,0 +1,6 @@
+MODULE    = sharedgpures.sys
+IMPORTS   = ntoskrnl
+EXTRADLLFLAGS = -Wl,--subsystem,native
+
+SOURCES = \
+	shared_resource.c
diff --git a/dlls/sharedgpures.sys/shared_resource.c b/dlls/sharedgpures.sys/shared_resource.c
new file mode 100644
index 00000000000..ad836662af0
--- /dev/null
+++ b/dlls/sharedgpures.sys/shared_resource.c
@@ -0,0 +1,518 @@
+#include <stdarg.h>
+
+#define NONAMELESSUNION
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winbase.h"
+#include "winternl.h"
+#include "winioctl.h"
+
+#include "ddk/wdm.h"
+
+#include "wine/debug.h"
+#include "wine/list.h"
+#include "wine/server.h"
+
+WINE_DEFAULT_DEBUG_CHANNEL(sharedgpures);
+
+static DRIVER_OBJECT *sharedgpures_driver;
+
+struct shared_resource
+{
+    unsigned int ref_count;
+    void *unix_resource;
+    WCHAR *name;
+    void *metadata;
+    SIZE_T metadata_size;
+    void **object_pool;
+    unsigned int object_pool_count;
+    UINT64 resource_size;
+};
+
+static struct shared_resource *resource_pool;
+static unsigned int resource_pool_size;
+
+/* TODO: If/when ntoskrnl gets support for referencing user handles directly, remove this function */
+static void *reference_client_handle(obj_handle_t handle)
+{
+    HANDLE client_process, kernel_handle;
+    OBJECT_ATTRIBUTES attr;
+    void *object = NULL;
+    CLIENT_ID cid;
+
+    attr.Length = sizeof(OBJECT_ATTRIBUTES);
+    attr.RootDirectory = 0;
+    attr.Attributes = OBJ_KERNEL_HANDLE;
+    attr.ObjectName = NULL;
+    attr.SecurityDescriptor = NULL;
+    attr.SecurityQualityOfService = NULL;
+
+    cid.UniqueProcess = PsGetCurrentProcessId();
+    cid.UniqueThread = 0;
+
+    if (NtOpenProcess(&client_process, PROCESS_ALL_ACCESS, &attr, &cid) != STATUS_SUCCESS)
+        return NULL;
+
+    if (NtDuplicateObject(client_process, wine_server_ptr_handle(handle), NtCurrentProcess(), &kernel_handle,
+                               0, OBJ_KERNEL_HANDLE, DUPLICATE_SAME_ACCESS) != STATUS_SUCCESS)
+    {
+        NtClose(client_process);
+        return NULL;
+    }
+
+    ObReferenceObjectByHandle(kernel_handle, 0, NULL, KernelMode, &object, NULL);
+
+    NtClose(client_process);
+    NtClose(kernel_handle);
+
+    return object;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_CREATE           CTL_CODE(FILE_DEVICE_VIDEO, 0, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+struct shared_resource_create
+{
+    UINT64 resource_size;
+    obj_handle_t unix_handle;
+    WCHAR name[1];
+};
+
+static NTSTATUS shared_resource_create(struct shared_resource **res, void *buff, SIZE_T insize, IO_STATUS_BLOCK *iosb)
+{
+    struct shared_resource_create *input = buff;
+    void *unix_resource;
+    unsigned int i;
+    LPWSTR name;
+
+    if (insize < sizeof(*input))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    if (input->name[ ((insize - offsetof(struct shared_resource_create, name)) / sizeof(WCHAR)) - 1 ])
+        return STATUS_INVALID_PARAMETER;
+
+    if (!(unix_resource = reference_client_handle(input->unix_handle)))
+        return STATUS_INVALID_HANDLE;
+
+    if (insize == sizeof(*input))
+        name = NULL;
+    else
+    {
+        name = ExAllocatePoolWithTag(NonPagedPool, insize - offsetof(struct shared_resource_create, name), 0);
+        wcscpy(name, &input->name[0]);
+    }
+
+    for (i = 0; i < resource_pool_size; i++)
+        if (!resource_pool[i].ref_count)
+            break;
+
+    if (i == resource_pool_size)
+    {
+        struct shared_resource *expanded_pool =
+            ExAllocatePoolWithTag(NonPagedPool, sizeof(struct shared_resource) * (resource_pool_size + 1024), 0);
+
+        if (resource_pool)
+        {
+            memcpy(expanded_pool, resource_pool, resource_pool_size * sizeof(struct shared_resource));
+            ExFreePoolWithTag(resource_pool, 0);
+        }
+
+        memset(&expanded_pool[resource_pool_size], 0, 1024 * sizeof (struct shared_resource));
+
+        resource_pool = expanded_pool;
+        resource_pool_size += 1024;
+    }
+
+    *res = &resource_pool[i];
+    (*res)->ref_count = 1;
+    (*res)->unix_resource = unix_resource;
+    (*res)->name = name;
+    (*res)->resource_size = input->resource_size;
+
+    iosb->Information = 0;
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_OPEN             CTL_CODE(FILE_DEVICE_VIDEO, 1, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+struct shared_resource_open
+{
+    obj_handle_t kmt_handle;
+    WCHAR name[1];
+};
+
+struct shared_resource_info
+{
+    UINT64 resource_size;
+};
+
+static unsigned int kmt_to_index(obj_handle_t kmt)
+{
+    if (!(kmt & 0x40000000) || (kmt - 2) % 4)
+        return -1;
+    return (((unsigned int) kmt & ~0x40000000) - 2) / 4;
+}
+
+static NTSTATUS shared_resource_open(struct shared_resource **res, void *buff, SIZE_T insize, IO_STATUS_BLOCK *iosb)
+{
+    struct shared_resource_open *input = buff;
+    unsigned int i;
+
+    if (insize < sizeof(*input))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    if (input->kmt_handle)
+    {
+        if (kmt_to_index(input->kmt_handle) >= resource_pool_size)
+            return STATUS_INVALID_HANDLE;
+
+        *res = &resource_pool[kmt_to_index(input->kmt_handle)];
+    }
+    else
+    {
+        if (input->name[ ((insize - offsetof(struct shared_resource_open, name)) / sizeof(WCHAR)) - 1 ])
+            return STATUS_INVALID_PARAMETER;
+
+        /* name lookup */
+        for (i = 0; i < resource_pool_size; i++)
+        {
+            if (resource_pool[i].name && !wcscmp(resource_pool[i].name, input->name))
+            {
+                *res = &resource_pool[i];
+                break;
+            }
+        }
+        if (i == resource_pool_size)
+            return STATUS_OBJECT_NAME_NOT_FOUND;
+    }
+
+    (*res)->ref_count++;
+    iosb->Information = 0;
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GETKMT           CTL_CODE(FILE_DEVICE_VIDEO, 2, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static obj_handle_t index_to_kmt(unsigned int idx)
+{
+    return (idx * 4 + 2) | 0x40000000;
+}
+
+static NTSTATUS shared_resource_getkmt(struct shared_resource *res, void *buff, SIZE_T outsize, IO_STATUS_BLOCK *iosb)
+{
+    if (outsize < sizeof(unsigned int))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    *((unsigned int *)buff) = index_to_kmt(res - resource_pool);
+
+    iosb->Information = sizeof(unsigned int);
+    return STATUS_SUCCESS;
+}
+
+/* TODO: If/when ntoskrnl gets support for opening user handles directly, remove this function */
+static obj_handle_t open_client_handle(void *object)
+{
+    HANDLE client_process, kernel_handle, handle = NULL;
+    OBJECT_ATTRIBUTES attr;
+    CLIENT_ID cid;
+
+    attr.Length = sizeof(OBJECT_ATTRIBUTES);
+    attr.RootDirectory = 0;
+    attr.Attributes = OBJ_KERNEL_HANDLE;
+    attr.ObjectName = NULL;
+    attr.SecurityDescriptor = NULL;
+    attr.SecurityQualityOfService = NULL;
+
+    cid.UniqueProcess = PsGetCurrentProcessId();
+    cid.UniqueThread = 0;
+
+    if (NtOpenProcess(&client_process, PROCESS_ALL_ACCESS, &attr, &cid) != STATUS_SUCCESS)
+        return 0;
+
+    if (ObOpenObjectByPointer(object, 0, NULL, GENERIC_ALL, NULL, KernelMode, &kernel_handle) != STATUS_SUCCESS)
+    {
+        NtClose(client_process);
+        return 0;
+    }
+
+    NtDuplicateObject(NtCurrentProcess(), kernel_handle, client_process, &handle,
+                        0, 0, DUPLICATE_SAME_ACCESS);
+
+    NtClose(client_process);
+    NtClose(kernel_handle);
+
+    return wine_server_obj_handle(handle);
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_UNIX_RESOURCE           CTL_CODE(FILE_DEVICE_VIDEO, 3, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static NTSTATUS shared_resource_get_unix_resource(struct shared_resource *res, void *buff, SIZE_T outsize, IO_STATUS_BLOCK *iosb)
+{
+    if (outsize < sizeof(obj_handle_t))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    *((obj_handle_t *)buff) = open_client_handle(res->unix_resource);
+
+    iosb->Information = sizeof(obj_handle_t);
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_SET_METADATA           CTL_CODE(FILE_DEVICE_VIDEO, 4, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+static NTSTATUS shared_resource_set_metadata(struct shared_resource *res, void *buff, SIZE_T insize, IO_STATUS_BLOCK *iosb)
+{
+    res->metadata = ExAllocatePoolWithTag(NonPagedPool, insize, 0);
+    memcpy(res->metadata, buff, insize);
+    res->metadata_size = insize;
+
+    iosb->Information = 0;
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_METADATA           CTL_CODE(FILE_DEVICE_VIDEO, 5, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static NTSTATUS shared_resource_get_metadata(struct shared_resource *res, void *buff, SIZE_T outsize, IO_STATUS_BLOCK *iosb)
+{
+    if (!res->metadata)
+        return STATUS_NOT_FOUND;
+
+    if (res->metadata_size > outsize)
+        return STATUS_BUFFER_TOO_SMALL;
+
+    memcpy(buff, res->metadata, res->metadata_size);
+    iosb->Information = res->metadata_size;
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_SET_OBJECT           CTL_CODE(FILE_DEVICE_VIDEO, 6, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+struct shared_resource_set_object
+{
+    unsigned int index;
+    obj_handle_t handle;
+};
+
+static NTSTATUS shared_resource_set_object(struct shared_resource *res, void *buff, SIZE_T insize, IO_STATUS_BLOCK *iosb)
+{
+    struct shared_resource_set_object *params = buff;
+    void *object;
+
+    if (insize < sizeof(*params))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    if (!(object = reference_client_handle(params->handle)))
+        return STATUS_INVALID_HANDLE;
+
+    if (params->index >= res->object_pool_count)
+    {
+        void **expanded_pool = ExAllocatePoolWithTag(NonPagedPool, (params->index + 1) * sizeof(void *), 0);
+
+        if (res->object_pool)
+        {
+            memcpy(expanded_pool, res->object_pool, res->object_pool_count * sizeof(void *));
+            ExFreePoolWithTag(res->object_pool, 0);
+        }
+
+        memset(&expanded_pool[res->object_pool_count], 0, (params->index + 1 - res->object_pool_count) * sizeof (void *));
+
+        res->object_pool = expanded_pool;
+        res->object_pool_count = params->index + 1;
+    }
+
+    if (res->object_pool[params->index])
+        ObDereferenceObject(res->object_pool[params->index]);
+
+    res->object_pool[params->index] = object;
+
+    iosb->Information = 0;
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_OBJECT           CTL_CODE(FILE_DEVICE_VIDEO, 6, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static NTSTATUS shared_resource_get_object(struct shared_resource *res, void *buff, SIZE_T insize, SIZE_T outsize, IO_STATUS_BLOCK *iosb)
+{
+    unsigned int index;
+
+    if (insize < sizeof(unsigned int) || outsize < sizeof(obj_handle_t))
+        return STATUS_INFO_LENGTH_MISMATCH;
+
+    index = *(unsigned int *)buff;
+
+    if (index >= res->object_pool_count || !res->object_pool[index])
+        return STATUS_INVALID_PARAMETER;
+
+    *((obj_handle_t *)buff) = open_client_handle(res->object_pool[index]);
+
+    iosb->Information = sizeof(obj_handle_t);
+    return STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_INFO CTL_CODE(FILE_DEVICE_VIDEO, 7, METHOD_BUFFERED, FILE_READ_ACCESS)
+static NTSTATUS shared_resource_get_info(struct shared_resource *res, void *buff, SIZE_T outsize, IO_STATUS_BLOCK *iosb)
+{
+    struct shared_resource_info *info = buff;
+
+    if (sizeof(*info) > outsize)
+        return STATUS_BUFFER_TOO_SMALL;
+
+    info->resource_size = res->resource_size;
+    iosb->Information = sizeof(*info);
+    return STATUS_SUCCESS;
+}
+
+
+static NTSTATUS WINAPI dispatch_create(DEVICE_OBJECT *device, IRP *irp)
+{
+    irp->IoStatus.u.Status = STATUS_SUCCESS;
+    IoCompleteRequest(irp, IO_NO_INCREMENT);
+    return STATUS_SUCCESS;
+}
+
+static NTSTATUS WINAPI dispatch_close(DEVICE_OBJECT *device, IRP *irp)
+{
+    IO_STACK_LOCATION *stack = IoGetCurrentIrpStackLocation(irp);
+    struct shared_resource *res = &resource_pool[ (UINT_PTR) stack->FileObject->FsContext ];
+
+    TRACE("Freeing shared resouce %p.\n", res);
+
+    if (res)
+    {
+        res->ref_count--;
+        if (!res->ref_count)
+        {
+            if (res->unix_resource)
+            {
+                /* TODO: see if its possible to destroy the object here (unlink?) */
+                ObDereferenceObject(res->unix_resource);
+                res->unix_resource = NULL;
+            }
+            if (res->metadata)
+            {
+                ExFreePoolWithTag(res->metadata, 0);
+                res->metadata = NULL;
+            }
+            if (res->object_pool)
+            {
+                unsigned int i;
+                for (i = 0; i < res->object_pool_count; i++)
+                {
+                    if (res->object_pool[i])
+                        ObDereferenceObject(res->object_pool[i]);
+                }
+                ExFreePoolWithTag(res->object_pool, 0);
+                res->object_pool = NULL;
+                res->object_pool_count = 0;
+            }
+        }
+    }
+
+    irp->IoStatus.u.Status = STATUS_SUCCESS;
+    IoCompleteRequest(irp, IO_NO_INCREMENT);
+    return STATUS_SUCCESS;
+}
+
+static NTSTATUS WINAPI dispatch_ioctl(DEVICE_OBJECT *device, IRP *irp)
+{
+    IO_STACK_LOCATION *stack = IoGetCurrentIrpStackLocation( irp );
+    struct shared_resource *res = &resource_pool[ (UINT_PTR) stack->FileObject->FsContext ];
+    NTSTATUS status;
+
+    TRACE( "ioctl %#lx insize %lu outsize %lu\n",
+           stack->Parameters.DeviceIoControl.IoControlCode,
+           stack->Parameters.DeviceIoControl.InputBufferLength,
+           stack->Parameters.DeviceIoControl.OutputBufferLength );
+
+    switch (stack->Parameters.DeviceIoControl.IoControlCode)
+    {
+        case IOCTL_SHARED_GPU_RESOURCE_CREATE:
+            status = shared_resource_create( &res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.InputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_OPEN:
+            status = shared_resource_open( &res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.InputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_GETKMT:
+            status = shared_resource_getkmt( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.OutputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_GET_UNIX_RESOURCE:
+            status = shared_resource_get_unix_resource( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.OutputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_SET_METADATA:
+            status = shared_resource_set_metadata( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.InputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_GET_METADATA:
+            status = shared_resource_get_metadata( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.OutputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_SET_OBJECT:
+            status = shared_resource_set_object( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.InputBufferLength,
+                                      &irp->IoStatus );
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_GET_OBJECT:
+            status = shared_resource_get_object( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.InputBufferLength,
+                                      stack->Parameters.DeviceIoControl.OutputBufferLength,
+                                      &irp->IoStatus);
+            break;
+        case IOCTL_SHARED_GPU_RESOURCE_GET_INFO:
+            status = shared_resource_get_info( res,
+                                      irp->AssociatedIrp.SystemBuffer,
+                                      stack->Parameters.DeviceIoControl.OutputBufferLength,
+                                      &irp->IoStatus );
+            break;
+    default:
+        FIXME( "ioctl %#lx not supported\n", stack->Parameters.DeviceIoControl.IoControlCode );
+        status = STATUS_NOT_SUPPORTED;
+        break;
+    }
+
+    if (!status)
+        stack->FileObject->FsContext = (void *)(UINT_PTR)(res - resource_pool);
+
+    irp->IoStatus.u.Status = status;
+    IoCompleteRequest( irp, IO_NO_INCREMENT );
+    return status;
+}
+
+NTSTATUS WINAPI DriverEntry( DRIVER_OBJECT *driver, UNICODE_STRING *path )
+{
+    static const WCHAR device_nameW[] = L"\\Device\\SharedGpuResource";
+    static const WCHAR link_nameW[] = L"\\??\\SharedGpuResource";
+    UNICODE_STRING device_name, link_name;
+    DEVICE_OBJECT *device;
+    NTSTATUS status;
+
+    sharedgpures_driver = driver;
+
+    driver->MajorFunction[IRP_MJ_CREATE] = dispatch_create;
+    driver->MajorFunction[IRP_MJ_CLOSE] = dispatch_close;
+    driver->MajorFunction[IRP_MJ_DEVICE_CONTROL] = dispatch_ioctl;
+
+    RtlInitUnicodeString(&device_name, device_nameW);
+    RtlInitUnicodeString(&link_name, link_nameW);
+
+    if ((status = IoCreateDevice(driver, 0, &device_name, 0, 0, FALSE, &device)))
+        return status;
+
+    return IoCreateSymbolicLink(&link_name, &device_name);
+}
diff --git a/dlls/sharedgpures.sys/sharedgpures.sys.spec b/dlls/sharedgpures.sys/sharedgpures.sys.spec
new file mode 100644
index 00000000000..76421d7e35b
--- /dev/null
+++ b/dlls/sharedgpures.sys/sharedgpures.sys.spec
@@ -0,0 +1 @@
+# nothing to export
diff --git a/dlls/vulkan-1/tests/vulkan.c b/dlls/vulkan-1/tests/vulkan.c
index 71ad2c4cf34..10403f3bd26 100644
--- a/dlls/vulkan-1/tests/vulkan.c
+++ b/dlls/vulkan-1/tests/vulkan.c
@@ -1154,8 +1154,9 @@ static void import_memory(VkDevice vk_device, VkMemoryAllocateInfo alloc_info, V
         import_handle_info.name = L"wine_test_buffer_export_name";
 
         vr = vkAllocateMemory(vk_device, &alloc_info, NULL, &memory);
-        ok(vr == VK_SUCCESS, "vkAllocateMemory failed, VkResult %d.\n", vr);
-        vkFreeMemory(vk_device, memory, NULL);
+        todo_wine ok(vr == VK_SUCCESS, "vkAllocateMemory failed, VkResult %d.\n", vr);
+        if (vr == VK_SUCCESS)
+            vkFreeMemory(vk_device, memory, NULL);
     }
 }
 
diff --git a/dlls/win32u/vulkan.c b/dlls/win32u/vulkan.c
index 6d6e5f81f54..a6c9052ef44 100644
--- a/dlls/win32u/vulkan.c
+++ b/dlls/win32u/vulkan.c
@@ -353,6 +353,7 @@ void win32u_vkDestroySwapchainKHR( VkDevice client_device, VkSwapchainKHR client
 static VkResult win32u_vkAcquireNextImage2KHR( VkDevice client_device, const VkAcquireNextImageInfoKHR *acquire_info,
                                                uint32_t *image_index )
 {
+    struct vulkan_semaphore *semaphore = vulkan_semaphore_from_handle( acquire_info->semaphore );
     struct swapchain *swapchain = swapchain_from_handle( acquire_info->swapchain );
     struct vulkan_device *device = vulkan_device_from_handle( client_device );
     VkAcquireNextImageInfoKHR acquire_info_host = *acquire_info;
@@ -361,6 +362,7 @@ static VkResult win32u_vkAcquireNextImage2KHR( VkDevice client_device, const VkA
     VkResult res;
 
     acquire_info_host.swapchain = swapchain->obj.host.swapchain;
+    acquire_info_host.semaphore = semaphore ? semaphore->host.semaphore : 0;
 
     res = device->p_vkAcquireNextImage2KHR( device->host.device, &acquire_info_host, image_index );
 
@@ -376,16 +378,17 @@ static VkResult win32u_vkAcquireNextImage2KHR( VkDevice client_device, const VkA
 }
 
 static VkResult win32u_vkAcquireNextImageKHR( VkDevice client_device, VkSwapchainKHR client_swapchain, uint64_t timeout,
-                                              VkSemaphore semaphore, VkFence fence, uint32_t *image_index )
+                                              VkSemaphore client_semaphore, VkFence fence, uint32_t *image_index )
 {
     struct swapchain *swapchain = swapchain_from_handle( client_swapchain );
     struct vulkan_device *device = vulkan_device_from_handle( client_device );
     struct surface *surface = swapchain->surface;
+    struct vulkan_semaphore *semaphore = vulkan_semaphore_from_handle( client_semaphore );
     RECT client_rect;
     VkResult res;
 
     res = device->p_vkAcquireNextImageKHR( device->host.device, swapchain->obj.host.swapchain, timeout,
-                                              semaphore, fence, image_index );
+                                           semaphore ? semaphore->host.semaphore : 0, fence, image_index );
 
     if (!res && NtUserGetClientRect( surface->hwnd, &client_rect, NtUserGetDpiForWindow( surface->hwnd ) ) &&
         !extents_equals( &swapchain->extents, &client_rect ))
@@ -404,14 +407,37 @@ static VkResult win32u_vkQueuePresentKHR( VkQueue client_queue, const VkPresentI
     VkSwapchainKHR swapchains_buffer[16], *swapchains = swapchains_buffer;
     VkPresentInfoKHR present_info_host = *present_info;
     struct vulkan_device *device = queue->device;
+    struct vulkan_semaphore *semaphore;
+    VkSemaphore *semaphores = NULL;
     VkResult res;
     UINT i;
 
     TRACE( "queue %p, present_info %p\n", queue, present_info );
 
+    if (present_info->waitSemaphoreCount)
+    {
+        semaphores = malloc( present_info->waitSemaphoreCount * sizeof(*semaphores) );
+        for (i = 0; i < present_info->waitSemaphoreCount; ++i)
+        {
+            semaphore = vulkan_semaphore_from_handle(present_info->pWaitSemaphores[i]);
+
+            if (semaphore->d3d12_fence)
+            {
+                FIXME("Waiting on D3D12-Fence compatible timeline semaphore not supported.\n");
+                free( semaphores );
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            }
+            semaphores[i] = semaphore->host.semaphore;
+        }
+        present_info_host.pWaitSemaphores = semaphores;
+    }
+
     if (present_info->swapchainCount > ARRAY_SIZE(swapchains_buffer) &&
         !(swapchains = malloc( present_info->swapchainCount * sizeof(*swapchains) )))
+    {
+        free( semaphores );
         return VK_ERROR_OUT_OF_HOST_MEMORY;
+    }
 
     for (i = 0; i < present_info->swapchainCount; i++)
     {
@@ -451,6 +477,7 @@ static VkResult win32u_vkQueuePresentKHR( VkQueue client_queue, const VkPresentI
     }
 
     if (swapchains != swapchains_buffer) free( swapchains );
+    free( semaphores );
 
     if (TRACE_ON( fps ))
     {
diff --git a/dlls/winevulkan/make_vulkan b/dlls/winevulkan/make_vulkan
index 2a7b192685c..76c122bbb96 100755
--- a/dlls/winevulkan/make_vulkan
+++ b/dlls/winevulkan/make_vulkan
@@ -97,14 +97,12 @@ UNSUPPORTED_EXTENSIONS = [
     "VK_EXT_full_screen_exclusive",
     "VK_GOOGLE_display_timing",
     "VK_KHR_external_fence_win32",
-    "VK_KHR_external_semaphore_win32",
     # Relates to external_semaphore and needs type conversions in bitflags.
     "VK_KHR_maintenance7", # Causes infinity recursion in struct convert code
     "VK_KHR_shared_presentable_image", # Needs WSI work.
     "VK_KHR_video_encode_h265", # StdVideoH265HrdParameters cannot be handled
     "VK_KHR_video_decode_h265", # by struct conversions.
     "VK_KHR_video_maintenance2", # Also affected by StdVideoH265HrdParameters.
-    "VK_KHR_win32_keyed_mutex",
     "VK_NV_external_memory_rdma", # Needs shared resources work.
     "VK_NV_external_compute_queue", # Has a new dispatchable handle
 
@@ -115,8 +113,6 @@ UNSUPPORTED_EXTENSIONS = [
     "VK_EXT_physical_device_drm",
     "VK_GOOGLE_surfaceless_query",
     "VK_KHR_external_fence_fd",
-    "VK_KHR_external_memory_fd",
-    "VK_KHR_external_semaphore_fd",
     "VK_SEC_amigo_profiling", # Angle specific.
 
     # Extensions which require callback handling
@@ -132,7 +128,6 @@ UNSUPPORTED_EXTENSIONS = [
 # but not expose to applications (useful for test commits)
 UNEXPOSED_EXTENSIONS = {
     "VK_EXT_map_memory_placed",
-    "VK_KHR_external_memory_win32",
     "VK_EXT_headless_surface",
 }
 
@@ -178,22 +173,51 @@ FUNCTION_OVERRIDES = {
 
     # Instance functions
     "vkCreateDevice" : {"extra_param" : "client_ptr"},
-    "vkGetPhysicalDeviceExternalBufferProperties" : {"dispatch" : False},
+    "vkGetPhysicalDeviceExternalBufferProperties" : {"dispatch" : True},
     "vkGetPhysicalDeviceExternalFenceProperties" : {"dispatch" : False},
-    "vkGetPhysicalDeviceExternalSemaphoreProperties" : {"dispatch" : False},
+    "vkGetPhysicalDeviceExternalSemaphoreProperties" : {"dispatch" : True},
 
     # Device functions
     "vkCreateCommandPool" : {"extra_param" : "client_ptr"},
     "vkGetDeviceProcAddr" : {"dispatch" : False},
+    "vkAllocateMemory" : {"dispatch" : True},
+    "vkGetSemaphoreCounterValue" : {"dispatch" : True},
+    "vkSignalSemaphore" : {"dispatch" : True},
+    "vkWaitSemaphores" : {"dispatch" : True},
+    "vkQueueBindSparse" : {"dispatch" : True},
+    "vkQueueSubmit" : {"dispatch" : True},
+    "vkQueueSubmit2" : {"dispatch" : True},
+    "vkDestroySemaphore" : {"dispatch" : True},
 
     # VK_KHR_external_fence_capabilities
     "vkGetPhysicalDeviceExternalFencePropertiesKHR" : {"dispatch" : False},
 
     # VK_KHR_external_memory_capabilities
-    "vkGetPhysicalDeviceExternalBufferPropertiesKHR" : {"dispatch" : False},
+    "vkGetPhysicalDeviceExternalBufferPropertiesKHR" : {"dispatch" : True},
 
     # VK_KHR_external_semaphore_capabilities
-    "vkGetPhysicalDeviceExternalSemaphorePropertiesKHR" : {"dispatch" : False},
+    "vkGetPhysicalDeviceExternalSemaphorePropertiesKHR" : {"dispatch" : True},
+
+    # VK_KHR_external_semaphore_win32
+    "vkCreateSemaphore" : {"dispatch" : True },
+    "vkGetSemaphoreWin32HandleKHR" : {"dispatch" : True},
+    "vkImportSemaphoreWin32HandleKHR" : {"dispatch" : True},
+
+    # VK_KHR_external_memory_win32
+    "vkGetMemoryWin32HandleKHR" : {"dispatch" : True},
+    "vkGetMemoryWin32HandlePropertiesKHR" : {"dispatch" : True},
+
+    # VK_KHR_timeline_semaphore
+    "vkGetSemaphoreCounterValueKHR" : {"dispatch" : True},
+    "vkSignalSemaphoreKHR" : {"dispatch" : True},
+    "vkWaitSemaphoresKHR" : {"dispatch" : True},
+
+    # VK_KHR_synchronization2
+    "vkQueueSubmit2KHR" : {"dispatch" : True},
+
+    # Custom functions
+    "wine_vkAcquireKeyedMutex" : {"dispatch": True},
+    "wine_vkReleaseKeyedMutex" : {"dispatch": True},
 }
 
 # functions for which a user driver entry must be generated
@@ -227,12 +251,15 @@ MANUAL_UNIX_THUNKS = {
     "vkCreateDevice",
     "vkCreateImage",
     "vkCreateInstance",
+    "vkCreateSemaphore",
     "vkDestroyCommandPool",
     "vkDestroyDebugReportCallbackEXT",
     "vkDestroyDebugUtilsMessengerEXT",
     "vkDestroyDeferredOperationKHR",
     "vkDestroyDevice",
     "vkDestroyInstance",
+    "vkGetSemaphoreWin32HandleKHR",
+    "vkImportSemaphoreWin32HandleKHR",
     "vkEnumerateDeviceExtensionProperties",
     "vkEnumerateDeviceLayerProperties",
     "vkEnumerateInstanceExtensionProperties",
@@ -246,6 +273,8 @@ MANUAL_UNIX_THUNKS = {
     "vkGetCalibratedTimestampsEXT",
     "vkGetCalibratedTimestampsKHR",
     "vkGetDeviceProcAddr",
+    "vkGetMemoryWin32HandleKHR",
+    "vkGetMemoryWin32HandlePropertiesKHR",
     "vkGetDeviceQueue",
     "vkGetDeviceQueue2",
     "vkGetInstanceProcAddr",
@@ -263,6 +292,20 @@ MANUAL_UNIX_THUNKS = {
     "vkMapMemory2KHR",
     "vkUnmapMemory",
     "vkUnmapMemory2KHR",
+    "vkGetSemaphoreCounterValue",
+    "vkSignalSemaphore",
+    "vkWaitSemaphores",
+    "vkQueueBindSparse",
+    "vkQueueSubmit",
+    "vkQueueSubmit2",
+    "vkDestroySemaphore",
+    "vkGetSemaphoreCounterValueKHR",
+    "vkSignalSemaphoreKHR",
+    "vkWaitSemaphoresKHR",
+    "vkQueueSubmit2KHR",
+    # Custom functions
+    "wine_vkAcquireKeyedMutex",
+    "wine_vkReleaseKeyedMutex",
 }
 
 # loader functions which are entirely manually implemented
@@ -292,8 +335,21 @@ STRUCT_CHAIN_CONVERSIONS = {
     # Ignore to not confuse host loader.
     "VkDeviceCreateInfo": ["VK_STRUCTURE_TYPE_LOADER_DEVICE_CREATE_INFO"],
     "VkInstanceCreateInfo": ["VK_STRUCTURE_TYPE_LOADER_INSTANCE_CREATE_INFO"],
+
+    # Structs which require pNext chain modification
+    "VkBufferCreateInfo": [],
+    "VkImageCreateInfo": [],
+    "VkMemoryAllocateInfo": [],
+    "VkPhysicalDeviceImageFormatInfo2": [],
+    "VkPhysicalDeviceExternalSemaphoreInfo": [],
+    "VkSemaphoreCreateInfo": [],
+    "VkSubmitInfo": [],
+    "VkSubmitInfo2": [],
+    "VkBindSparseInfo" : [],
 }
 
+STRUCT_COPY = {};
+
 # Some struct members are conditionally ignored and callers are free to leave them uninitialized.
 # We can't deduce that from XML, so we allow expressing it here.
 MEMBER_LENGTH_EXPRESSIONS = {
@@ -810,7 +866,14 @@ class VkFunction(object):
         proto += ", ".join([p.definition() for p in self.params])
 
         if is_thunk and self.extra_param:
-            proto += ", void *" + self.extra_param
+            extra_param_is_new = True
+            for p in self.params:
+                if p.name == self.extra_param:
+                    extra_param_is_new = False
+            if extra_param_is_new:
+                proto += ", void *" + self.extra_param
+            else:
+                proto += ", void *win_" + self.extra_param
 
         proto += ")"
         return proto
@@ -897,7 +960,7 @@ class VkFunction(object):
             if conv:
                 params += ", UlongToPtr({0}{1})".format(params_prefix, self.extra_param)
             else:
-                params += ", {0}{1}".format(params_prefix, self.extra_param)
+                params += ", (void *){0}{1}".format(params_prefix, self.extra_param)
 
         if self.name in MANUAL_UNIX_THUNKS:
             func_prefix = "wine_"
@@ -977,9 +1040,12 @@ class VkFunction(object):
         if conv:
             thunk += "    struct\n"
             thunk += "    {\n"
+            extra_param_is_new = True
             for p in self.params:
                 thunk += "        {0};\n".format(p.definition(conv=True, is_member=True))
-            if self.extra_param:
+                if p.name == self.extra_param:
+                    extra_param_is_new = False
+            if self.extra_param and extra_param_is_new:
                 thunk += "        PTR32 {0};\n".format(self.extra_param)
             if self.type != "void":
                 thunk += "        {0} result;\n".format(self.type)
@@ -1193,6 +1259,8 @@ class VkHandle(object):
             return "vulkan_instance_from_handle({0})->host.instance".format(name)
         if self.name == "VkDeviceMemory":
             return "wine_device_memory_from_handle({0})->host.device_memory".format(name)
+        if self.name == "VkSemaphore":
+            return "vulkan_semaphore_from_handle({0})->host.semaphore".format(name)
         if self.name == "VkPhysicalDevice":
             return "vulkan_physical_device_from_handle({0})->host.physical_device".format(name)
         if self.name == "VkQueue":
@@ -1208,7 +1276,8 @@ class VkHandle(object):
     def unwrap_handle(self, name, unwrap):
         if unwrap == Unwrap.HOST:
             return self.host_handle(name)
-        assert unwrap != Unwrap.NONE
+        if unwrap == Unwrap.NONE:
+            return name
         return None
 
     def is_wrapped(self):
@@ -1411,6 +1480,9 @@ class VkVariable(object):
                 if struct.needs_conversion(conv, unwrap, Direction.OUTPUT, is_const):
                     conversions.append(StructConversionFunction(struct, Direction.OUTPUT, conv, unwrap, is_const))
 
+            if struct.name in STRUCT_COPY:
+                conversions.append(StructConversionFunction(struct, Direction.INPUT, False, unwrap, is_const, True))
+
         if self.is_static_array() or self.is_dynamic_array():
             for conv in [False, True]:
                 if self.needs_conversion(conv, unwrap, Direction.INPUT, parent_const):
@@ -1533,14 +1605,14 @@ class VkMember(VkVariable):
                         values=values, object_type=object_type, bit_width=bit_width, returnedonly=returnedonly,
                         parent=parent, selection=selection, selector=selector)
 
-    def copy(self, input, output, direction, conv, unwrap):
+    def copy(self, input, output, direction, conv, unwrap, copy):
         """ Helper method for use by conversion logic to generate a C-code statement to copy this member.
             - `conv` indicates whether the statement is in a struct alignment conversion path. """
 
         win_type = "win32" if conv else "win64"
         suffix = convert_suffix(direction, win_type, unwrap, self.is_wrapped())
 
-        if self.needs_conversion(conv, unwrap, direction, False):
+        if self.needs_conversion(conv, unwrap, direction, False) and not copy:
             if self.is_dynamic_array():
                 # Array length is either a variable name (string) or an int.
                 count = self.get_dyn_array_len(input, conv)
@@ -1570,8 +1642,9 @@ class VkMember(VkVariable):
                     return "{0}{1} = {2} ? {3} : 0;\n".format(output, self.name, self.value(input, conv),
                         handle.unwrap_handle(self.value(input, conv), unwrap))
                 else:
-                    return "{0}{1} = {2};\n".format(output, self.name,
-                        handle.unwrap_handle(self.value(input, conv), unwrap))
+                    input_name = "{0}{1}".format(input, self.name)
+                    return "{0}{1} = {2} ? {3} : VK_NULL_HANDLE;\n".format(output, self.name,
+                        input_name, handle.unwrap_handle(self.value(input, conv), unwrap))
             elif self.is_generic_handle():
                 if direction == Direction.OUTPUT:
                     LOGGER.error("OUTPUT parameter {0}.{1} cannot be unwrapped".format(self.type, self.name))
@@ -1590,6 +1663,11 @@ class VkMember(VkVariable):
             for l in self.array_lens:
                 bytes_count = "{0} * ".format(l) + bytes_count
             return "memcpy({0}{1}, {2}{1}, {3});\n".format(output, self.name, input, bytes_count)
+        elif self.is_dynamic_array() and copy:
+            if self.type == "void":
+                return "MEMDUP_VOID(ctx, {0}{1}, {2}{1}, {3});\n".format(output, self.name, input, self.get_dyn_array_len(input, conv))
+            else:
+                return "MEMDUP(ctx, {0}{1}, {2}{1}, {3});\n".format(output, self.name, input, self.get_dyn_array_len(input, conv))
         elif conv and direction == Direction.OUTPUT and self.is_pointer():
             return "{0}{1} = PtrToUlong({2}{1});\n".format(output, self.name, input)
         elif conv and direction == Direction.INPUT and self.is_pointer():
@@ -2316,17 +2394,21 @@ class VkStruct(Sequence):
 
 
 class StructConversionFunction(object):
-    def __init__(self, struct, direction, conv, unwrap, const):
+    def __init__(self, struct, direction, conv, unwrap, const, copy=False):
         self.direction = direction
         self.operand = struct
         self.type = struct.name
         self.conv = conv
         self.unwrap = unwrap
         self.const = const
+        self.copy = copy
 
-        name = "convert_{0}_".format(self.type)
-        win_type = "win32" if self.conv else "win64"
-        name += convert_suffix(direction, win_type, unwrap, struct.is_wrapped())
+        if copy:
+            name = "copy_{0}".format(self.type)
+        else:
+            name = "convert_{0}_".format(self.type)
+            win_type = "win32" if self.conv else "win64"
+            name += convert_suffix(direction, win_type, unwrap, struct.is_wrapped())
         self.name = name
 
     def __eq__(self, other):
@@ -2358,7 +2440,7 @@ class StructConversionFunction(object):
 
         body = ""
 
-        if not self.conv:
+        if not self.conv and not self.copy:
             body += "#ifdef _WIN64\n"
 
         needs_alloc = self.direction != Direction.OUTPUT and self.operand.needs_alloc(self.conv, self.unwrap)
@@ -2368,8 +2450,11 @@ class StructConversionFunction(object):
         if self.direction == Direction.OUTPUT and self.const:
             win_type = "const " + win_type
 
-        if self.conv:
+        if self.copy:
+            body += "void {0}(".format(self.name)
+        else:
             body += "static inline void {0}(".format(self.name)
+        if self.conv:
 
             if self.direction == Direction.OUTPUT:
                 params = ["const {0} *in".format(self.type), "{0} *out".format(win_type)]
@@ -2386,8 +2471,6 @@ class StructConversionFunction(object):
             body += ")\n"
 
         else:
-            body += "static inline void {0}(".format(self.name)
-
             params = ["const {0} *in".format(self.type), "{0} *out".format(self.type)]
 
             # Generate parameter list
@@ -2430,7 +2513,7 @@ class StructConversionFunction(object):
                 body += " || ".join("selector == {}".format(s) for s in m.selection)
                 body += ")\n    "
 
-            body += "    " + m.copy("in->", "out->", self.direction, self.conv, self.unwrap)
+            body += "    " + m.copy("in->", "out->", self.direction, self.conv, self.unwrap, self.copy)
 
         if needs_extensions:
             if self.conv and self.direction == Direction.INPUT:
@@ -2444,9 +2527,12 @@ class StructConversionFunction(object):
             ident = "            "
 
             if self.direction == Direction.INPUT and self.type in STRUCT_CHAIN_CONVERSIONS:
+                has_any_chain_conversions = False
                 for i in STRUCT_CHAIN_CONVERSIONS[self.type]:
                     body += "        case {0}:\n".format(i)
-                body += ident + "break;\n"
+                    has_any_chain_conversions = True
+                if has_any_chain_conversions:
+                    body += ident + "break;\n"
 
             for ext in self.operand.struct_extensions:
                 if not ext.required:
@@ -2456,6 +2542,8 @@ class StructConversionFunction(object):
                     continue
 
                 stype = next(x for x in ext.members if x.name == "sType").values
+                if self.type in STRUCT_CHAIN_CONVERSIONS and stype in STRUCT_CHAIN_CONVERSIONS[self.type]:
+                    continue
                 win_type = ext.name + "32" if self.conv and ext.needs_win32_type() else ext.name
                 if self.direction == Direction.INPUT:
                     in_type = "const " + win_type
@@ -2484,7 +2572,7 @@ class StructConversionFunction(object):
                     if m.name == "pNext":
                         copy_body += ident + "out_ext->pNext = NULL;\n"
                         continue
-                    copy_body += ident + m.copy("in_ext->", "out_ext->", self.direction, self.conv, Unwrap.HOST)
+                    copy_body += ident + m.copy("in_ext->", "out_ext->", self.direction, self.conv, Unwrap.HOST, self.copy)
 
                 # Generate the definition of "in_ext" if we need it
                 if "in_ext->" in copy_body:
@@ -2499,7 +2587,18 @@ class StructConversionFunction(object):
 
             body += "        default:\n"
             if self.direction == Direction.INPUT:
-                body += ident + "FIXME(\"Unhandled sType %u.\\n\", in_header->sType);\n"
+                body += ident + "if ((in_header->sType >> 16) == 0x7ead)\n"
+                body += ident + "{\n"
+                body += ident + "    VkBaseOutStructure *out_ext = conversion_context_alloc(ctx, 32);\n";
+                body += ident + "    memcpy(out_ext, in_header, 32);\n";
+                body += ident + "    out_ext->pNext = NULL;\n";
+                body += ident + "    out_header->pNext = (void *)out_ext;\n";
+                body += ident + "    out_header = (void *)out_ext;\n";
+                body += ident + "}\n"
+                body += ident + "else\n"
+                body += ident + "{\n"
+                body += ident + "    FIXME(\"Unhandled sType %u.\\n\", in_header->sType);\n"
+                body += ident + "}\n"
             body += "            break;\n"
             body += "        }\n"
             body += "    }\n"
@@ -2508,7 +2607,7 @@ class StructConversionFunction(object):
             body += "        FIXME(\"Unexpected pNext\\n\");\n"
 
         body += "}\n"
-        if not self.conv:
+        if not self.conv and not self.copy:
             body += "#endif /* _WIN64 */\n"
         body += "\n"
 
@@ -3017,9 +3116,13 @@ class VkGenerator(object):
 
             f.write("struct {0}_params\n".format(vk_func.name))
             f.write("{\n");
+            extra_param_is_new = True
             for p in vk_func.params:
                 f.write("    {0};\n".format(p.definition(is_member=True)))
-            if vk_func.extra_param:
+                if p.name == vk_func.extra_param:
+                    extra_param_is_new = False
+
+            if vk_func.extra_param and extra_param_is_new:
                 f.write("    void *{0};\n".format(vk_func.extra_param))
             if vk_func.type != "void":
                 f.write("    {0} result;\n".format(vk_func.type))
@@ -3161,6 +3264,28 @@ class VkGenerator(object):
                 f.write(" \\\n    USE_VK_FUNC({0})".format(vk_func.name))
         f.write("\n\n")
 
+        f.write("typedef VkResult (*PFN_native_vkCreateInstance)(const VkInstanceCreateInfo *, const VkAllocationCallbacks *, VkInstance *,\n")
+        f.write("                                                       void * (*)(VkInstance, const char *), void *);\n");
+        f.write("typedef VkResult (*PFN_native_vkCreateDevice)(VkPhysicalDevice, const VkDeviceCreateInfo *, const VkAllocationCallbacks *, VkDevice *,\n");
+        f.write("                                                     void * (*)(VkInstance, const char *), void *);\n\n");
+        f.write("typedef struct VkCreateInfoWineDeviceCallback {\n");
+        f.write("    VkStructureType             sType;\n");
+        f.write("    const void*                 pNext;\n");
+        f.write("    PFN_native_vkCreateDevice   native_create_callback;\n");
+        f.write("    void*                       context;\n");
+        f.write("} VkCreateInfoWineDeviceCallback;\n");
+
+        f.write("#define VK_STRUCTURE_TYPE_CREATE_INFO_WINE_DEVICE_CALLBACK 2125312001\n");
+
+        f.write("typedef struct VkCreateInfoWineInstanceCallback {\n");
+        f.write("    VkStructureType             sType;\n");
+        f.write("    const void*                 pNext;\n");
+        f.write("    PFN_native_vkCreateInstance native_create_callback;\n");
+        f.write("    void*                       context;\n");
+        f.write("} VkCreateInfoWineInstanceCallback;\n");
+
+        f.write("#define VK_STRUCTURE_TYPE_CREATE_INFO_WINE_INSTANCE_CALLBACK 2125312002\n");
+
         f.write("#endif /* __WINE_VULKAN_H */\n")
 
     def generate_vulkan_spec(self, f):
@@ -3244,6 +3369,10 @@ class VkRegistry(object):
 
         root.extend(video_root)
 
+        tree_custom = ET.parse("vk_custom.xml")
+        root_custom = tree_custom.getroot()
+        root.extend(root_custom)
+
         self._parse_enums(root)
         self._parse_types(root)
         self._parse_commands(root)
diff --git a/dlls/winevulkan/vk_custom.xml b/dlls/winevulkan/vk_custom.xml
new file mode 100644
index 00000000000..a9fd68548c4
--- /dev/null
+++ b/dlls/winevulkan/vk_custom.xml
@@ -0,0 +1,24 @@
+<?xml version="1.0" encoding="UTF-8"?>
+<registry>
+    <commands>
+        <command successcodes="VK_SUCCESS,VK_TIMEOUT" errorcodes="VK_ERROR_UNKNOWN">
+            <proto><type>VkResult</type> <name>wine_vkAcquireKeyedMutex</name></proto>
+            <param><type>VkDevice</type> <name>device</name></param>
+            <param><type>VkDeviceMemory</type> <name>memory</name></param>
+            <param><type>uint64_t</type> <name>key</name></param>
+            <param><type>uint32_t</type> <name>timeout_ms</name></param>
+        </command>
+        <command successcodes="VK_SUCCESS" errorcodes="VK_ERROR_UNKNOWN">
+            <proto><type>VkResult</type> <name>wine_vkReleaseKeyedMutex</name></proto>
+            <param><type>VkDevice</type> <name>device</name></param>
+            <param><type>VkDeviceMemory</type> <name>memory</name></param>
+            <param><type>uint64_t</type> <name>key</name></param>
+        </command>
+    </commands>
+    <feature api="vulkan,vulkansc" name="WINE_CUSTOM" comment="Wine custom functions.">
+        <require>
+            <command name="wine_vkAcquireKeyedMutex"/>
+            <command name="wine_vkReleaseKeyedMutex"/>
+        </require>
+    </feature>
+</registry>
diff --git a/dlls/winevulkan/vulkan.c b/dlls/winevulkan/vulkan.c
index ac93931092b..b369da154cd 100644
--- a/dlls/winevulkan/vulkan.c
+++ b/dlls/winevulkan/vulkan.c
@@ -23,6 +23,23 @@
 
 #include "config.h"
 #include <time.h>
+#include <unistd.h>
+#include <stdbool.h>
+#include <errno.h>
+#include <stdio.h>
+#include <assert.h>
+#include <limits.h>
+#ifdef HAVE_SYS_SYSCALL_H
+# include <sys/syscall.h>
+#endif
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "windef.h"
+#include "winnt.h"
+#include "winioctl.h"
+#include "wine/server.h"
+#include "wine/list.h"
 
 #include "vulkan_private.h"
 #include "wine/vulkan_driver.h"
@@ -32,6 +49,8 @@
 
 WINE_DEFAULT_DEBUG_CHANNEL(vulkan);
 
+static int debug_level;
+
 static PFN_vkCreateInstance p_vkCreateInstance;
 static PFN_vkEnumerateInstanceVersion p_vkEnumerateInstanceVersion;
 static PFN_vkEnumerateInstanceExtensionProperties p_vkEnumerateInstanceExtensionProperties;
@@ -48,10 +67,10 @@ static struct wine_phys_dev *wine_phys_dev_from_handle(VkPhysicalDevice handle)
     return CONTAINING_RECORD(object, struct wine_phys_dev, obj);
 }
 
-static struct wine_device *wine_device_from_handle(VkDevice handle)
+static struct wine_semaphore *wine_semaphore_from_handle(VkSemaphore handle)
 {
-    struct vulkan_device *object = vulkan_device_from_handle(handle);
-    return CONTAINING_RECORD(object, struct wine_device, obj);
+    struct vulkan_semaphore *object = vulkan_semaphore_from_handle(handle);
+    return CONTAINING_RECORD(object, struct wine_semaphore, obj);
 }
 
 static void vulkan_object_init_ptr( struct vulkan_object *obj, UINT64 host_handle, struct vulkan_client_object *client )
@@ -90,6 +109,24 @@ static uint32_t wine_vk_count_struct_(void *s, VkStructureType t)
 
 const struct vulkan_funcs *vk_funcs;
 
+#define wine_vk_find_unlink_struct(s, t) wine_vk_find_unlink_struct_((void *)s, VK_STRUCTURE_TYPE_##t)
+static void *wine_vk_find_unlink_struct_(void *s, VkStructureType t)
+{
+    VkBaseInStructure *prev = s;
+    VkBaseInStructure *header;
+
+    for (header = (VkBaseInStructure *)prev->pNext; header; prev = header, header = (VkBaseInStructure *)header->pNext)
+    {
+        if (header->sType == t) {
+            prev->pNext = header->pNext;
+            header->pNext = NULL;
+            return header;
+        }
+    }
+
+    return NULL;
+}
+
 static int vulkan_object_compare(const void *key, const struct rb_entry *entry)
 {
     struct vulkan_object *object = RB_ENTRY_VALUE(entry, struct vulkan_object, entry);
@@ -164,6 +201,57 @@ static void append_debug_utils_object(const VkDebugUtilsObjectNameInfoEXT *objec
     dst->object_name_len = append_string(object->pObjectName, strings, strings_len);
 }
 
+static void signal_timeline_sem(struct vulkan_device *device, VkSemaphore sem, UINT64 *value)
+{
+    /* May be called from native thread. */
+    struct VkSemaphoreSignalInfo info = { 0 };
+    VkResult res;
+
+    info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_SIGNAL_INFO;
+    info.semaphore = sem;
+    info.value = *value + 1;
+    __atomic_store_n(value, info.value, __ATOMIC_RELEASE);
+    if (device->physical_device->api_version < VK_API_VERSION_1_2 || device->physical_device->instance->api_version < VK_API_VERSION_1_2)
+        res = device->p_vkSignalSemaphoreKHR(device->host.device, &info);
+    else
+        res = device->p_vkSignalSemaphore(device->host.device, &info);
+    if (res != VK_SUCCESS)
+        fprintf(stderr, "err:winevulkan:signal_timeline_sem vkSignalSemaphore failed, res=%d.\n", res);
+}
+
+static VkResult wait_semaphores(struct vulkan_device *device, const VkSemaphoreWaitInfo *wait_info, uint64_t timeout)
+{
+    if (device->physical_device->api_version < VK_API_VERSION_1_2 || device->physical_device->instance->api_version < VK_API_VERSION_1_2)
+        return device->p_vkWaitSemaphoresKHR(device->host.device, wait_info, timeout);
+    return device->p_vkWaitSemaphores(device->host.device, wait_info, timeout);
+}
+
+static VkResult get_semaphore_value(struct vulkan_device *device, VkSemaphore sem, uint64_t *value)
+{
+    if (device->physical_device->api_version < VK_API_VERSION_1_2 || device->physical_device->instance->api_version < VK_API_VERSION_1_2)
+        return device->p_vkGetSemaphoreCounterValueKHR(device->host.device, sem, value);
+    return device->p_vkGetSemaphoreCounterValue(device->host.device, sem, value);
+}
+
+
+static void set_transient_client_handle(struct wine_instance *instance, uint64_t client_handle)
+{
+    uint64_t *handle = pthread_getspecific(instance->transient_object_handle);
+    if (!handle)
+    {
+        handle = malloc(sizeof(uint64_t));
+        pthread_setspecific(instance->transient_object_handle, handle);
+    }
+    *handle = client_handle;
+}
+
+static uint64_t get_transient_handle(struct wine_instance *instance)
+{
+    uint64_t *handle = pthread_getspecific(instance->transient_object_handle);
+    return handle && *handle;
+}
+
+
 static VkBool32 debug_utils_callback_conversion(VkDebugUtilsMessageSeverityFlagBitsEXT severity,
     VkDebugUtilsMessageTypeFlagsEXT message_types,
     const VkDebugUtilsMessengerCallbackDataEXT *callback_data,
@@ -174,6 +262,8 @@ static VkBool32 debug_utils_callback_conversion(VkDebugUtilsMessageSeverityFlagB
     struct wine_debug_utils_messenger *object;
     struct debug_utils_object dummy_object, *objects;
     struct debug_utils_label dummy_label, *labels;
+    VkInstance instance;
+    struct wine_instance *wine_instance;
     UINT size, strings_len;
     char *ptr, *strings;
     ULONG ret_len;
@@ -183,13 +273,16 @@ static VkBool32 debug_utils_callback_conversion(VkDebugUtilsMessageSeverityFlagB
     TRACE("%i, %u, %p, %p\n", severity, message_types, callback_data, user_data);
 
     object = user_data;
+    instance = object->instance->host.instance;
 
-    if (!object->instance->host.instance)
+    if (!instance)
     {
         /* instance wasn't yet created, this is a message from the host loader */
         return VK_FALSE;
     }
 
+    wine_instance = CONTAINING_RECORD(object->instance, struct wine_instance, obj);
+
     if ((address = callback_data->pNext))
     {
         if (address->sType != VK_STRUCTURE_TYPE_DEVICE_ADDRESS_BINDING_CALLBACK_DATA_EXT) address = NULL;
@@ -246,6 +339,8 @@ static VkBool32 debug_utils_callback_conversion(VkDebugUtilsMessageSeverityFlagB
         if (wine_vk_is_type_wrapped(objects[i].object_type))
         {
             objects[i].object_handle = client_handle_from_host(object->instance, objects[i].object_handle);
+            if (!objects[i].object_handle)
+                objects[i].object_handle = get_transient_handle(wine_instance);
             if (!objects[i].object_handle)
             {
                 WARN("handle conversion failed 0x%s\n", wine_dbgstr_longlong(callback_data->pObjects[i].objectHandle));
@@ -334,7 +429,8 @@ static VkResult wine_vk_physical_device_init(struct wine_phys_dev *object, VkPhy
     BOOL have_memory_placed = FALSE, have_map_memory2 = FALSE;
     uint32_t num_host_properties, num_properties = 0;
     VkExtensionProperties *host_properties = NULL;
-    BOOL have_external_memory_host = FALSE;
+    VkPhysicalDeviceProperties physdev_properties;
+    BOOL have_external_memory_host = FALSE, have_external_memory_fd = FALSE, have_external_semaphore_fd = FALSE;
     VkResult res;
     unsigned int i, j;
 
@@ -343,6 +439,9 @@ static VkResult wine_vk_physical_device_init(struct wine_phys_dev *object, VkPhy
 
     instance->p_vkGetPhysicalDeviceMemoryProperties(host_physical_device, &object->memory_properties);
 
+    instance->p_vkGetPhysicalDeviceProperties(host_physical_device, &physdev_properties);
+    object->obj.api_version = physdev_properties.apiVersion;
+
     res = instance->p_vkEnumerateDeviceExtensionProperties(host_physical_device,
             NULL, &num_host_properties, NULL);
     if (res != VK_SUCCESS)
@@ -371,6 +470,25 @@ static VkResult wine_vk_physical_device_init(struct wine_phys_dev *object, VkPhy
      */
     for (i = 0; i < num_host_properties; i++)
     {
+        if (!strcmp(host_properties[i].extensionName, "VK_KHR_external_memory_fd"))
+        {
+            TRACE("Substituting VK_KHR_external_memory_fd for VK_KHR_external_memory_win32\n");
+
+            snprintf(host_properties[i].extensionName, sizeof(host_properties[i].extensionName),
+                    VK_KHR_EXTERNAL_MEMORY_WIN32_EXTENSION_NAME);
+            host_properties[i].specVersion = VK_KHR_EXTERNAL_MEMORY_WIN32_SPEC_VERSION;
+            have_external_memory_fd = TRUE;
+        }
+        if (!strcmp(host_properties[i].extensionName, "VK_KHR_external_semaphore_fd"))
+        {
+            TRACE("Substituting VK_KHR_external_semaphore_fd for VK_KHR_external_semaphore_win32\n");
+
+            snprintf(host_properties[i].extensionName, sizeof(host_properties[i].extensionName),
+                    VK_KHR_EXTERNAL_SEMAPHORE_WIN32_EXTENSION_NAME);
+            host_properties[i].specVersion = VK_KHR_EXTERNAL_SEMAPHORE_WIN32_SPEC_VERSION;
+            have_external_semaphore_fd = TRUE;
+        }
+
         if (wine_vk_device_extension_supported(host_properties[i].extensionName))
         {
             TRACE("Enabling extension '%s' for physical device %p\n", host_properties[i].extensionName, object);
@@ -390,7 +508,8 @@ static VkResult wine_vk_physical_device_init(struct wine_phys_dev *object, VkPhy
             have_map_memory2 = TRUE;
     }
 
-    TRACE("Host supported extensions %u, Wine supported extensions %u\n", num_host_properties, num_properties);
+    if (have_external_memory_fd && have_external_semaphore_fd)
+        ++num_properties; /* VK_KHR_win32_keyed_mutex */
 
     if (!(object->extensions = calloc(num_properties, sizeof(*object->extensions))))
     {
@@ -406,7 +525,15 @@ static VkResult wine_vk_physical_device_init(struct wine_phys_dev *object, VkPhy
             j++;
         }
     }
+    if (have_external_memory_fd && have_external_semaphore_fd)
+    {
+        strcpy(object->extensions[j].extensionName, VK_KHR_WIN32_KEYED_MUTEX_EXTENSION_NAME);
+        object->extensions[j].specVersion = VK_KHR_WIN32_KEYED_MUTEX_SPEC_VERSION;
+        TRACE("Enabling extension '%s' for physical device %p\n", object->extensions[j].extensionName, object);
+        ++j;
+    }
     object->extension_count = num_properties;
+    TRACE("Host supported extensions %u, Wine supported extensions %u\n", num_host_properties, num_properties);
 
     if (zero_bits && have_memory_placed && have_map_memory2)
     {
@@ -487,11 +614,10 @@ static void wine_vk_free_command_buffers(struct vulkan_device *device,
     }
 }
 
-static void wine_vk_device_init_queues(struct wine_device *object, const VkDeviceQueueCreateInfo *info)
+static void wine_vk_device_init_queues(struct vulkan_device *device, const VkDeviceQueueCreateInfo *info)
 {
-    struct wine_queue *queues = object->queues + object->queue_count;
-    struct vulkan_device *device = &object->obj;
-    VkQueue client_queues = device->client.device->queues + object->queue_count;
+    struct vulkan_queue *queues = device->queues + device->queue_count;
+    VkQueue client_queues = device->client.device->queues + device->queue_count;
     VkDeviceQueueInfo2 queue_info;
     UINT i;
 
@@ -499,7 +625,7 @@ static void wine_vk_device_init_queues(struct wine_device *object, const VkDevic
 
     for (i = 0; i < info->queueCount; i++)
     {
-        struct wine_queue *queue = queues + i;
+        struct vulkan_queue *queue = queues + i;
         VkQueue host_queue, client_queue = client_queues + i;
 
         /* The Vulkan spec says:
@@ -521,16 +647,59 @@ static void wine_vk_device_init_queues(struct wine_device *object, const VkDevic
             device->p_vkGetDeviceQueue(device->host.device, info->queueFamilyIndex, i, &host_queue);
         }
 
-        vulkan_object_init_ptr(&queue->obj.obj, (UINT_PTR)host_queue, &client_queue->obj);
-        queue->obj.device = device;
+        vulkan_object_init_ptr(&queue->obj, (UINT_PTR)host_queue, &client_queue->obj);
+        queue->device = device;
         queue->family_index = info->queueFamilyIndex;
         queue->queue_index = i;
         queue->flags = info->flags;
 
-        TRACE("Got device %p queue %p, host_queue %p.\n", device, queue, queue->obj.host.queue);
+        TRACE("Got device %p queue %p, host_queue %p.\n", device, queue, queue->host.queue);
     }
 
-    object->queue_count += info->queueCount;
+    device->queue_count += info->queueCount;
+}
+
+static char *cc_strdup(struct conversion_context *ctx, const char *s)
+{
+    int len = strlen(s) + 1;
+    char *ret;
+
+    ret = conversion_context_alloc(ctx, len);
+    memcpy(ret, s, len);
+    return ret;
+}
+
+static void parse_xr_extensions(struct conversion_context *ctx, const char **extra_extensions, unsigned int *extra_count)
+{
+    char *iter, *start;
+
+    iter = getenv("__WINE_OPENXR_VK_DEVICE_EXTENSIONS");
+    if (!iter) return;
+    iter = cc_strdup(ctx, iter);
+
+    TRACE("got var: %s\n", iter);
+    start = iter;
+    do
+    {
+        if(*iter == ' ')
+        {
+            *iter = 0;
+            extra_extensions[(*extra_count)++] = cc_strdup(ctx, start);
+            TRACE("added %s to list\n", extra_extensions[(*extra_count) - 1]);
+            iter++;
+            start = iter;
+        }
+        else if(*iter == 0)
+        {
+            extra_extensions[(*extra_count)++] = cc_strdup(ctx, start);
+            TRACE("added %s to list\n", extra_extensions[(*extra_count) - 1]);
+            break;
+        }
+        else
+        {
+            iter++;
+        }
+    } while (1);
 }
 
 static const char *find_extension(const char *const *extensions, uint32_t count, const char *ext)
@@ -544,13 +713,20 @@ static const char *find_extension(const char *const *extensions, uint32_t count,
 }
 
 static VkResult wine_vk_device_convert_create_info(VkPhysicalDevice client_physical_device,
-        struct conversion_context *ctx, const VkDeviceCreateInfo *src, VkDeviceCreateInfo *dst)
+        struct conversion_context *ctx, const VkDeviceCreateInfo *src, VkDeviceCreateInfo *dst,
+        struct vulkan_device *device)
 {
+    static const char *wine_xr_extension_name = "VK_WINE_openxr_device_extensions";
     struct wine_phys_dev *phys_dev = wine_phys_dev_from_handle(client_physical_device);
-    const char *extra_extensions[3], * const*extensions = src->ppEnabledExtensionNames;
+    const char *extra_extensions[65], * const*extensions = src->ppEnabledExtensionNames;
     unsigned int i, extra_count = 0, extensions_count = src->enabledExtensionCount;
+    unsigned int j, remove_count = 0;
+    const char *remove_extensions[65];
+    VkBaseOutStructure *header;
 
     *dst = *src;
+    if ((header = (VkBaseOutStructure *)dst->pNext) && header->sType == VK_STRUCTURE_TYPE_CREATE_INFO_WINE_DEVICE_CALLBACK)
+        dst->pNext = header->pNext;
 
     /* Should be filtered out by loader as ICDs don't support layers. */
     dst->enabledLayerCount = 0;
@@ -561,13 +737,41 @@ static VkResult wine_vk_device_convert_create_info(VkPhysicalDevice client_physi
     {
         const char *extension_name = extensions[i];
         TRACE("Extension %u: %s.\n", i, debugstr_a(extension_name));
-        if (!wine_vk_device_extension_supported(extension_name))
-        {
-            WARN("Extension %s is not supported.\n", debugstr_a(extension_name));
-            return VK_ERROR_EXTENSION_NOT_PRESENT;
-        }
     }
 
+    if (find_extension(extensions, extensions_count, wine_xr_extension_name))
+    {
+        parse_xr_extensions(ctx, extra_extensions, &extra_count);
+        remove_extensions[remove_count++] = wine_xr_extension_name;
+    }
+
+    if (find_extension(extensions, extensions_count, "VK_KHR_external_memory_win32"))
+    {
+        extra_extensions[extra_count++] = "VK_KHR_external_memory_fd";
+        remove_extensions[remove_count++] = "VK_KHR_external_memory_win32";
+    }
+
+    if (find_extension(extensions, extensions_count, "VK_KHR_external_semaphore_win32"))
+    {
+        extra_extensions[extra_count++] = "VK_KHR_external_semaphore_fd";
+        remove_extensions[remove_count++] = "VK_KHR_external_semaphore_win32";
+    }
+
+    if (find_extension(extensions, extensions_count, "VK_KHR_win32_keyed_mutex"))
+    {
+        if (!find_extension(extensions, extensions_count, "VK_KHR_external_memory_win32"))
+            extra_extensions[extra_count++] = "VK_KHR_external_memory_fd";
+        if (!find_extension(extensions, extensions_count, "VK_KHR_external_semaphore_win32"))
+            extra_extensions[extra_count++] = "VK_KHR_external_semaphore_fd";
+        remove_extensions[remove_count++] = "VK_KHR_win32_keyed_mutex";
+        device->keyed_mutexes_enabled = TRUE;
+    }
+
+
+    if ((phys_dev->obj.api_version < VK_API_VERSION_1_2 || phys_dev->obj.instance->api_version < VK_API_VERSION_1_2)
+                && !find_extension(extensions, extensions_count, "VK_KHR_timeline_semaphore"))
+        extra_extensions[extra_count++] = "VK_KHR_timeline_semaphore";
+
     if (phys_dev->map_placed_align)
     {
         VkPhysicalDeviceMapMemoryPlacedFeaturesEXT *map_placed_features;
@@ -606,6 +810,20 @@ static VkResult wine_vk_device_convert_create_info(VkPhysicalDevice client_physi
         dst->enabledExtensionCount += extra_count;
         new_extensions = conversion_context_alloc(ctx, dst->enabledExtensionCount * sizeof(*new_extensions));
         memcpy(new_extensions, extensions, extensions_count * sizeof(*new_extensions));
+        for (i = 0; i < extensions_count; i++)
+        {
+            for (j = 0; j < remove_count; ++j)
+            {
+                if (!strcmp(new_extensions[i], remove_extensions[j]))
+                {
+                    --dst->enabledExtensionCount;
+                    --extensions_count;
+                    memmove(&new_extensions[i], &new_extensions[i + 1], sizeof(*new_extensions) * (extensions_count - i));
+                    --i;
+                    break;
+                }
+            }
+        }
         memcpy(new_extensions + extensions_count, extra_extensions, extra_count * sizeof(*new_extensions));
         dst->ppEnabledExtensionNames = new_extensions;
     }
@@ -655,6 +873,9 @@ static VkResult wine_vk_instance_convert_create_info(struct conversion_context *
 
     *dst = *src;
 
+    if ((header = (VkBaseInStructure *)dst->pNext) && header->sType == VK_STRUCTURE_TYPE_CREATE_INFO_WINE_INSTANCE_CALLBACK)
+        dst->pNext = header->pNext;
+
     instance->utils_messenger_count = wine_vk_count_struct(dst, DEBUG_UTILS_MESSENGER_CREATE_INFO_EXT);
     instance->utils_messengers =  calloc(instance->utils_messenger_count, sizeof(*instance->utils_messengers));
     header = (VkBaseInStructure *) dst;
@@ -697,11 +918,6 @@ static VkResult wine_vk_instance_convert_create_info(struct conversion_context *
     {
         const char *extension_name = src->ppEnabledExtensionNames[i];
         TRACE("Extension %u: %s.\n", i, debugstr_a(extension_name));
-        if (!wine_vk_instance_extension_supported(extension_name))
-        {
-            WARN("Extension %s is not supported.\n", debugstr_a(extension_name));
-            return VK_ERROR_EXTENSION_NOT_PRESENT;
-        }
     }
 
     new_extensions = conversion_context_alloc(ctx, (src->enabledExtensionCount + 2) *
@@ -781,6 +997,7 @@ static VkResult wine_vk_instance_init_physical_devices(struct wine_instance *obj
         res = wine_vk_physical_device_init(phys_dev, host_physical_devices[i], &client_instance->phys_devs[i], instance);
         if (res != VK_SUCCESS)
             goto err;
+        TRACE("added host_physical_devices[i] %p.\n", host_physical_devices[i]);
     }
     object->phys_dev_count = phys_dev_count;
 
@@ -871,9 +1088,15 @@ VkResult wine_vkCreateDevice(VkPhysicalDevice client_physical_device, const VkDe
     VkDevice host_device, client_device = client_ptr;
     VkDeviceCreateInfo create_info_host;
     struct conversion_context ctx;
-    struct wine_device *device;
-    unsigned int queue_count, i;
+    struct vulkan_device *device;
+    unsigned int queue_count, props_count, i;
     VkResult res;
+    size_t size;
+    void *ptr;
+
+    PFN_native_vkCreateDevice native_create_device = NULL;
+    void *native_create_device_context = NULL;
+    VkCreateInfoWineDeviceCallback *callback;
 
     if (allocator)
         FIXME("Support for allocation callbacks not implemented yet\n");
@@ -889,51 +1112,82 @@ VkResult wine_vkCreateDevice(VkPhysicalDevice client_physical_device, const VkDe
         TRACE("Driver version: %#x.\n", properties.driverVersion);
     }
 
+    size = sizeof(*device);
+
+    instance->p_vkGetPhysicalDeviceQueueFamilyProperties(physical_device->host.physical_device, &props_count, NULL);
+    size += props_count * sizeof(*device->queue_props);
+
     /* We need to cache all queues within the device as each requires wrapping since queues are dispatchable objects. */
     for (queue_count = 0, i = 0; i < create_info->queueCreateInfoCount; i++)
         queue_count += create_info->pQueueCreateInfos[i].queueCount;
+    size += queue_count * sizeof(*device->queues);
 
-    if (!(device = calloc(1, offsetof(struct wine_device, queues[queue_count]))))
-        return VK_ERROR_OUT_OF_HOST_MEMORY;
+    if (!(device = ptr = calloc(1, size))) return VK_ERROR_OUT_OF_HOST_MEMORY;
+    ptr = (char *)ptr + sizeof(*device);
+    device->queue_props = ptr;
+    ptr = (char *)ptr + props_count * sizeof(*device->queue_props);
+    device->queues = ptr;
+    ptr = (char *)ptr + queue_count * sizeof(*device->queues);
+
+    if ((callback = (VkCreateInfoWineDeviceCallback *)create_info->pNext)
+            && callback->sType == VK_STRUCTURE_TYPE_CREATE_INFO_WINE_DEVICE_CALLBACK)
+    {
+        native_create_device = callback->native_create_callback;
+        native_create_device_context = callback->context;
+    }
+
+    pthread_mutex_init(&device->signaller_mutex, NULL);
+    list_init(&device->sem_poll_list);
+    list_init(&device->free_fence_ops_list);
 
     init_conversion_context(&ctx);
-    res = wine_vk_device_convert_create_info(client_physical_device, &ctx, create_info, &create_info_host);
+    res = wine_vk_device_convert_create_info(client_physical_device, &ctx, create_info, &create_info_host, device);
     if (res == VK_SUCCESS)
-        res = instance->p_vkCreateDevice(physical_device->host.physical_device, &create_info_host,
-                                               NULL /* allocator */, &host_device);
+    {
+        if (native_create_device)
+            res = native_create_device(physical_device->host.physical_device, &create_info_host,
+                                       NULL /* allocator */, &host_device,
+                                       (void *)vk_funcs->p_vkGetInstanceProcAddr, native_create_device_context);
+        else
+            res = instance->p_vkCreateDevice(physical_device->host.physical_device, &create_info_host,
+                                             NULL /* allocator */, &host_device);
+    }
     free_conversion_context(&ctx);
     if (res != VK_SUCCESS)
     {
         WARN("Failed to create device, res=%d.\n", res);
+        pthread_mutex_destroy(&device->signaller_mutex);
         free(device);
         return res;
     }
 
-    vulkan_object_init_ptr(&device->obj.obj, (UINT_PTR)host_device, &client_device->obj);
-    device->obj.physical_device = physical_device;
+    vulkan_object_init_ptr(&device->obj, (UINT_PTR)host_device, &client_device->obj);
+    device->physical_device = physical_device;
 
     /* Just load all function pointers we are aware off. The loader takes care of filtering.
      * We use vkGetDeviceProcAddr as opposed to vkGetInstanceProcAddr for efficiency reasons
      * as functions pass through fewer dispatch tables within the loader.
      */
 #define USE_VK_FUNC(name)                                                                          \
-    device->obj.p_##name = (void *)vk_funcs->p_vkGetDeviceProcAddr(device->obj.host.device, #name);  \
-    if (device->obj.p_##name == NULL) TRACE("Not found '%s'.\n", #name);
+    device->p_##name = (void *)vk_funcs->p_vkGetDeviceProcAddr(device->host.device, #name);  \
+    if (device->p_##name == NULL) TRACE("Not found '%s'.\n", #name);
     ALL_VK_DEVICE_FUNCS
 #undef USE_VK_FUNC
 
+    instance->p_vkGetPhysicalDeviceQueueFamilyProperties(physical_device->host.physical_device, &props_count, device->queue_props);
+
     for (i = 0; i < create_info_host.queueCreateInfoCount; i++)
         wine_vk_device_init_queues(device, create_info_host.pQueueCreateInfos + i);
 
     client_device->quirks = CONTAINING_RECORD(instance, struct wine_instance, obj)->quirks;
 
-    TRACE("Created device %p, host_device %p.\n", device, device->obj.host.device);
+    TRACE("Created device %p, host_device %p.\n", device, device->host.device);
     for (i = 0; i < device->queue_count; i++)
     {
-        struct wine_queue *queue = device->queues + i;
-        vulkan_instance_insert_object(instance, &queue->obj.obj);
+        struct vulkan_queue *queue = device->queues + i;
+        vulkan_instance_insert_object(instance, &queue->obj);
     }
-    vulkan_instance_insert_object(instance, &device->obj.obj);
+    vulkan_instance_insert_object(instance, &device->obj);
 
     *ret = client_device;
     return VK_SUCCESS;
@@ -943,6 +1197,9 @@ VkResult wine_vkCreateInstance(const VkInstanceCreateInfo *create_info,
                                const VkAllocationCallbacks *allocator, VkInstance *ret,
                                void *client_ptr)
 {
+    PFN_native_vkCreateInstance native_create_instance = NULL;
+    void *native_create_instance_context = NULL;
+    VkCreateInfoWineInstanceCallback *callback;
     VkInstanceCreateInfo create_info_host;
     const VkApplicationInfo *app_info;
     struct conversion_context ctx;
@@ -960,10 +1217,23 @@ VkResult wine_vkCreateInstance(const VkInstanceCreateInfo *create_info,
         return VK_ERROR_OUT_OF_HOST_MEMORY;
     }
 
+    if ((callback = (VkCreateInfoWineInstanceCallback *)create_info->pNext)
+            && callback->sType == VK_STRUCTURE_TYPE_CREATE_INFO_WINE_INSTANCE_CALLBACK)
+    {
+        native_create_instance = callback->native_create_callback;
+        native_create_instance_context = callback->context;
+    }
+
     init_conversion_context(&ctx);
     res = wine_vk_instance_convert_create_info(&ctx, create_info, &create_info_host, instance);
     if (res == VK_SUCCESS)
-        res = p_vkCreateInstance(&create_info_host, NULL /* allocator */, &host_instance);
+    {
+        if (native_create_instance)
+            res = native_create_instance(&create_info_host, NULL /* allocator */, &host_instance,
+                    (void *)vk_funcs->p_vkGetInstanceProcAddr, native_create_instance_context);
+        else
+            res = p_vkCreateInstance(&create_info_host, NULL /* allocator */, &host_instance);
+    }
     free_conversion_context(&ctx);
     if (res != VK_SUCCESS)
     {
@@ -1009,10 +1279,14 @@ VkResult wine_vkCreateInstance(const VkInstanceCreateInfo *create_info,
                 app_info->engineVersion);
         TRACE("API version %#x.\n", app_info->apiVersion);
 
+        instance->obj.api_version = app_info->apiVersion;
+
         if (app_info->pEngineName && !strcmp(app_info->pEngineName, "idTech"))
             instance->quirks |= WINEVULKAN_QUIRK_GET_DEVICE_PROC_ADDR;
     }
 
+    pthread_key_create(&instance->transient_object_handle, free);
+
     TRACE("Created instance %p, host_instance %p.\n", instance, instance->obj.host.instance);
 
     for (i = 0; i < instance->phys_dev_count; i++)
@@ -1028,8 +1302,9 @@ VkResult wine_vkCreateInstance(const VkInstanceCreateInfo *create_info,
 
 void wine_vkDestroyDevice(VkDevice client_device, const VkAllocationCallbacks *allocator)
 {
-    struct wine_device *device = wine_device_from_handle(client_device);
-    struct vulkan_instance *instance = device->obj.physical_device->instance;
+    struct pending_d3d12_fence_op *op, *next;
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct vulkan_instance *instance = device->physical_device->instance;
     unsigned int i;
 
     if (allocator)
@@ -1037,10 +1312,30 @@ void wine_vkDestroyDevice(VkDevice client_device, const VkAllocationCallbacks *a
     if (!device)
         return;
 
-    device->obj.p_vkDestroyDevice(device->obj.host.device, NULL /* pAllocator */);
+    if (device->signaller_thread)
+    {
+        TRACE("Shutting down signaller thread.\n");
+        pthread_mutex_lock(&device->signaller_mutex);
+        device->stop = 1;
+        signal_timeline_sem(device, device->sem_poll_update.sem, &device->sem_poll_update.value);
+        pthread_mutex_unlock(&device->signaller_mutex);
+        pthread_join(device->signaller_thread, NULL);
+        device->p_vkDestroySemaphore(device->host.device, device->sem_poll_update.sem, NULL);
+        pthread_cond_destroy(&device->sem_poll_updated_cond);
+        TRACE("Signaller thread shut down.\n");
+    }
+    pthread_mutex_destroy(&device->signaller_mutex);
+
+    LIST_FOR_EACH_ENTRY_SAFE(op, next, &device->free_fence_ops_list, struct pending_d3d12_fence_op, entry)
+    {
+        device->p_vkDestroySemaphore(device->host.device, op->local_sem.sem, NULL);
+        free(op);
+    }
+
+    device->p_vkDestroyDevice(device->host.device, NULL /* pAllocator */);
     for (i = 0; i < device->queue_count; i++)
-        vulkan_instance_remove_object(instance, &device->queues[i].obj.obj);
-    vulkan_instance_remove_object(instance, &device->obj.obj);
+        vulkan_instance_remove_object(instance, &device->queues[i].obj);
+    vulkan_instance_remove_object(instance, &device->obj);
 
     free(device);
 }
@@ -1063,6 +1358,8 @@ void wine_vkDestroyInstance(VkInstance client_instance, const VkAllocationCallba
     }
     vulkan_instance_remove_object(&instance->obj, &instance->obj.obj);
 
+    pthread_key_delete(instance->transient_object_handle);
+
     if (instance->objects.compare) pthread_rwlock_destroy(&instance->objects_lock);
     free(instance->utils_messengers);
     free(instance);
@@ -1216,8 +1513,8 @@ void wine_vkFreeCommandBuffers(VkDevice client_device, VkCommandPool command_poo
 
 static VkQueue wine_vk_device_find_queue(VkDevice client_device, const VkDeviceQueueInfo2 *info)
 {
-    struct wine_device *device = wine_device_from_handle(client_device);
-    struct wine_queue *queue;
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct vulkan_queue *queue;
     uint32_t i;
 
     for (i = 0; i < device->queue_count; i++)
@@ -1227,7 +1524,7 @@ static VkQueue wine_vk_device_find_queue(VkDevice client_device, const VkDeviceQ
                 && queue->queue_index == info->queueIndex
                 && queue->flags == info->flags)
         {
-            return queue->obj.client.queue;
+            return queue->client.queue;
         }
     }
 
@@ -1366,64 +1663,144 @@ void wine_vkGetPhysicalDeviceExternalFencePropertiesKHR(VkPhysicalDevice client_
     properties->externalFenceFeatures = 0;
 }
 
+static inline void wine_vk_normalize_handle_types_win(VkExternalMemoryHandleTypeFlags *types)
+{
+    *types &=
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_HEAP_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_MAPPED_FOREIGN_MEMORY_BIT_EXT;
+}
+
+static inline void wine_vk_normalize_handle_types_host(VkExternalMemoryHandleTypeFlags *types)
+{
+    *types &=
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT |
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT |
+/*      predicated on VK_KHR_external_memory_dma_buf
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_DMA_BUF_BIT_EXT | */
+        VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_MAPPED_FOREIGN_MEMORY_BIT_EXT;
+}
+
+static const VkExternalMemoryHandleTypeFlagBits wine_vk_handle_over_fd_types =
+                VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT |
+                VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT |
+                VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT |
+                VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT;
+
+static void wine_vk_get_physical_device_external_buffer_properties(struct wine_phys_dev *phys_dev,
+        void (*p_vkGetPhysicalDeviceExternalBufferProperties)(VkPhysicalDevice, const VkPhysicalDeviceExternalBufferInfo *, VkExternalBufferProperties *),
+        const VkPhysicalDeviceExternalBufferInfo *buffer_info, VkExternalBufferProperties *properties)
+{
+    VkPhysicalDeviceExternalBufferInfo buffer_info_dup = *buffer_info;
+
+    wine_vk_normalize_handle_types_win(&buffer_info_dup.handleType);
+    if (buffer_info_dup.handleType & wine_vk_handle_over_fd_types)
+        buffer_info_dup.handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+    wine_vk_normalize_handle_types_host(&buffer_info_dup.handleType);
+
+    if (buffer_info->handleType && !buffer_info_dup.handleType)
+    {
+        memset(&properties->externalMemoryProperties, 0, sizeof(properties->externalMemoryProperties));
+        return;
+    }
+
+    p_vkGetPhysicalDeviceExternalBufferProperties(phys_dev->obj.host.physical_device, &buffer_info_dup, properties);
+
+    if (properties->externalMemoryProperties.exportFromImportedHandleTypes & VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT)
+        properties->externalMemoryProperties.exportFromImportedHandleTypes |= wine_vk_handle_over_fd_types;
+    wine_vk_normalize_handle_types_win(&properties->externalMemoryProperties.exportFromImportedHandleTypes);
+
+    if (properties->externalMemoryProperties.compatibleHandleTypes & VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT)
+        properties->externalMemoryProperties.compatibleHandleTypes |= wine_vk_handle_over_fd_types;
+    wine_vk_normalize_handle_types_win(&properties->externalMemoryProperties.compatibleHandleTypes);
+}
+
 void wine_vkGetPhysicalDeviceExternalBufferProperties(VkPhysicalDevice client_physical_device,
                                                       const VkPhysicalDeviceExternalBufferInfo *buffer_info,
                                                       VkExternalBufferProperties *properties)
 {
-    memset(&properties->externalMemoryProperties, 0, sizeof(properties->externalMemoryProperties));
+    struct wine_phys_dev *phys_dev = wine_phys_dev_from_handle(client_physical_device);
+    wine_vk_get_physical_device_external_buffer_properties(phys_dev, phys_dev->obj.instance->p_vkGetPhysicalDeviceExternalBufferProperties, buffer_info, properties);
 }
 
 void wine_vkGetPhysicalDeviceExternalBufferPropertiesKHR(VkPhysicalDevice client_physical_device,
                                                          const VkPhysicalDeviceExternalBufferInfo *buffer_info,
                                                          VkExternalBufferProperties *properties)
 {
-    memset(&properties->externalMemoryProperties, 0, sizeof(properties->externalMemoryProperties));
+    struct wine_phys_dev *phys_dev = wine_phys_dev_from_handle(client_physical_device);
+    wine_vk_get_physical_device_external_buffer_properties(phys_dev, phys_dev->obj.instance->p_vkGetPhysicalDeviceExternalBufferPropertiesKHR, buffer_info, properties);
 }
 
-VkResult wine_vkGetPhysicalDeviceImageFormatProperties2(VkPhysicalDevice client_physical_device,
-                                                        const VkPhysicalDeviceImageFormatInfo2 *format_info,
-                                                        VkImageFormatProperties2 *properties)
+static VkResult wine_vk_get_physical_device_image_format_properties_2(struct vulkan_physical_device *physical_device,
+        VkResult (*p_vkGetPhysicalDeviceImageFormatProperties2)(VkPhysicalDevice, const VkPhysicalDeviceImageFormatInfo2 *, VkImageFormatProperties2 *),
+        const VkPhysicalDeviceImageFormatInfo2 *format_info, VkImageFormatProperties2 *properties)
 {
-    struct vulkan_physical_device *physical_device = vulkan_physical_device_from_handle(client_physical_device);
-    struct vulkan_instance *instance = physical_device->instance;
+    VkPhysicalDeviceExternalImageFormatInfo *external_image_info;
     VkExternalImageFormatProperties *external_image_properties;
     VkResult res;
 
-    res = instance->p_vkGetPhysicalDeviceImageFormatProperties2(physical_device->host.physical_device, format_info, properties);
+    if ((external_image_info = find_next_struct(format_info, VK_STRUCTURE_TYPE_PHYSICAL_DEVICE_EXTERNAL_IMAGE_FORMAT_INFO))
+            && external_image_info->handleType)
+    {
+        wine_vk_normalize_handle_types_win(&external_image_info->handleType);
+
+        if (external_image_info->handleType & wine_vk_handle_over_fd_types)
+            external_image_info->handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+        wine_vk_normalize_handle_types_host(&external_image_info->handleType);
+        if (!external_image_info->handleType)
+        {
+            FIXME("Unsupported handle type %#x.\n", external_image_info->handleType);
+            return VK_ERROR_FORMAT_NOT_SUPPORTED;
+        }
+    }
+
+    res = p_vkGetPhysicalDeviceImageFormatProperties2(physical_device->host.physical_device, format_info, properties);
 
     if ((external_image_properties = find_next_struct(properties,
                                                       VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES)))
     {
         VkExternalMemoryProperties *p = &external_image_properties->externalMemoryProperties;
-        p->externalMemoryFeatures = 0;
-        p->exportFromImportedHandleTypes = 0;
-        p->compatibleHandleTypes = 0;
+
+        if (p->exportFromImportedHandleTypes & VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT)
+            p->exportFromImportedHandleTypes |= wine_vk_handle_over_fd_types;
+        wine_vk_normalize_handle_types_win(&p->exportFromImportedHandleTypes);
+
+        if (p->compatibleHandleTypes & VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT)
+            p->compatibleHandleTypes |= wine_vk_handle_over_fd_types;
+        wine_vk_normalize_handle_types_win(&p->compatibleHandleTypes);
     }
 
     return res;
 }
 
+VkResult wine_vkGetPhysicalDeviceImageFormatProperties2(VkPhysicalDevice client_physical_device,
+                                                        const VkPhysicalDeviceImageFormatInfo2 *format_info,
+                                                        VkImageFormatProperties2 *properties)
+{
+    struct vulkan_physical_device *physical_device = vulkan_physical_device_from_handle(client_physical_device);
+    struct vulkan_instance *instance = physical_device->instance;
+
+    return wine_vk_get_physical_device_image_format_properties_2(physical_device,
+            instance->p_vkGetPhysicalDeviceImageFormatProperties2,
+            format_info, properties);
+}
+
 VkResult wine_vkGetPhysicalDeviceImageFormatProperties2KHR(VkPhysicalDevice client_physical_device,
                                                            const VkPhysicalDeviceImageFormatInfo2 *format_info,
                                                            VkImageFormatProperties2 *properties)
 {
     struct vulkan_physical_device *physical_device = vulkan_physical_device_from_handle(client_physical_device);
     struct vulkan_instance *instance = physical_device->instance;
-    VkExternalImageFormatProperties *external_image_properties;
-    VkResult res;
 
-    res = instance->p_vkGetPhysicalDeviceImageFormatProperties2KHR(physical_device->host.physical_device, format_info, properties);
-
-    if ((external_image_properties = find_next_struct(properties,
-                                                      VK_STRUCTURE_TYPE_EXTERNAL_IMAGE_FORMAT_PROPERTIES)))
-    {
-        VkExternalMemoryProperties *p = &external_image_properties->externalMemoryProperties;
-        p->externalMemoryFeatures = 0;
-        p->exportFromImportedHandleTypes = 0;
-        p->compatibleHandleTypes = 0;
-    }
-
-    return res;
+    return wine_vk_get_physical_device_image_format_properties_2(physical_device,
+            instance->p_vkGetPhysicalDeviceImageFormatProperties2KHR,
+            format_info, properties);
 }
 
 /* From ntdll/unix/sync.c */
@@ -1630,546 +2007,2698 @@ VkResult wine_vkGetPhysicalDeviceCalibrateableTimeDomainsKHR(VkPhysicalDevice cl
 
 
 
-void wine_vkGetPhysicalDeviceExternalSemaphoreProperties(VkPhysicalDevice client_physical_device,
-                                                         const VkPhysicalDeviceExternalSemaphoreInfo *info,
-                                                         VkExternalSemaphoreProperties *properties)
+static inline void wine_vk_normalize_semaphore_handle_types_win(VkExternalSemaphoreHandleTypeFlags *types)
 {
-    properties->exportFromImportedHandleTypes = 0;
-    properties->compatibleHandleTypes = 0;
-    properties->externalSemaphoreFeatures = 0;
+    *types &=
+        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT |
+        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT |
+        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT;
 }
 
-void wine_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR(VkPhysicalDevice client_physical_device,
-                                                            const VkPhysicalDeviceExternalSemaphoreInfo *info,
-                                                            VkExternalSemaphoreProperties *properties)
+static inline void wine_vk_normalize_semaphore_handle_types_host(VkExternalSemaphoreHandleTypeFlags *types)
 {
-    properties->exportFromImportedHandleTypes = 0;
-    properties->compatibleHandleTypes = 0;
-    properties->externalSemaphoreFeatures = 0;
+    *types &=
+        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT |
+        VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_SYNC_FD_BIT;
 }
 
-VkResult wine_vkAllocateMemory(VkDevice client_device, const VkMemoryAllocateInfo *alloc_info,
-                               const VkAllocationCallbacks *allocator, VkDeviceMemory *ret)
+static void wine_vk_get_physical_device_external_semaphore_properties(struct wine_phys_dev *phys_dev,
+    void (*p_vkGetPhysicalDeviceExternalSemaphoreProperties)(VkPhysicalDevice, const VkPhysicalDeviceExternalSemaphoreInfo *, VkExternalSemaphoreProperties *),
+    const VkPhysicalDeviceExternalSemaphoreInfo *semaphore_info, VkExternalSemaphoreProperties *properties)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    struct vulkan_instance *instance = device->physical_device->instance;
-    struct wine_device_memory *memory;
-    VkMemoryAllocateInfo info = *alloc_info;
-    VkImportMemoryHostPointerInfoEXT host_pointer_info;
-    VkDeviceMemory host_device_memory;
-    uint32_t mem_flags;
-    void *mapping = NULL;
-    VkResult result;
+    VkPhysicalDeviceExternalSemaphoreInfo semaphore_info_dup = *semaphore_info;
+    VkSemaphoreTypeCreateInfo semaphore_type_info, *p_semaphore_type_info;
 
-    /* For host visible memory, we try to use VK_EXT_external_memory_host on wow64
-     * to ensure that mapped pointer is 32-bit. */
-    mem_flags = physical_device->memory_properties.memoryTypes[alloc_info->memoryTypeIndex].propertyFlags;
-    if (physical_device->external_memory_align && (mem_flags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) &&
-        !find_next_struct(alloc_info->pNext, VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT))
+    switch(semaphore_info->handleType)
     {
-        VkMemoryHostPointerPropertiesEXT props =
-        {
-            .sType = VK_STRUCTURE_TYPE_MEMORY_HOST_POINTER_PROPERTIES_EXT,
-        };
-        uint32_t i, align = physical_device->external_memory_align - 1;
-        SIZE_T alloc_size = info.allocationSize;
-        static int once;
-
-        if (!once++)
-            FIXME("Using VK_EXT_external_memory_host\n");
-
-        if (NtAllocateVirtualMemory(GetCurrentProcess(), &mapping, zero_bits, &alloc_size,
-                                    MEM_COMMIT, PAGE_READWRITE))
-        {
-            ERR("NtAllocateVirtualMemory failed\n");
-            return VK_ERROR_OUT_OF_HOST_MEMORY;
-        }
-
-        result = device->p_vkGetMemoryHostPointerPropertiesEXT(device->host.device,
-                VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT, mapping, &props);
-        if (result != VK_SUCCESS)
+        case VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT:
+            semaphore_info_dup.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+            break;
+        case VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT:
         {
-            ERR("vkGetMemoryHostPointerPropertiesEXT failed: %d\n", result);
-            return result;
-        }
+            unsigned int i;
 
-        if (!(props.memoryTypeBits & (1u << info.memoryTypeIndex)))
-        {
-            /* If requested memory type is not allowed to use external memory,
-             * try to find a supported compatible type. */
-            uint32_t mask = mem_flags & ~VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
-            for (i = 0; i < physical_device->memory_properties.memoryTypeCount; i++)
+            if (phys_dev->obj.api_version < VK_API_VERSION_1_2 ||
+                phys_dev->obj.instance->api_version < VK_API_VERSION_1_2)
             {
-                if (!(props.memoryTypeBits & (1u << i)))
-                    continue;
-                if ((physical_device->memory_properties.memoryTypes[i].propertyFlags & mask) != mask)
-                    continue;
-
-                TRACE("Memory type not compatible with host memory, using %u instead\n", i);
-                info.memoryTypeIndex = i;
-                break;
+                for (i = 0; i < phys_dev->extension_count; i++)
+                {
+                    if (!strcmp(phys_dev->extensions[i].extensionName, "VK_KHR_timeline_semaphore"))
+                        break;
+                }
+                if (i == phys_dev->extension_count)
+                {
+                    properties->exportFromImportedHandleTypes = 0;
+                    properties->compatibleHandleTypes = 0;
+                    properties->externalSemaphoreFeatures = 0;
+                    return;
+                }
             }
-            if (i == physical_device->memory_properties.memoryTypeCount)
+
+            if ((p_semaphore_type_info = find_next_struct(&semaphore_info_dup, VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO)))
             {
-                FIXME("Not found compatible memory type\n");
-                alloc_size = 0;
-                NtFreeVirtualMemory(GetCurrentProcess(), &mapping, &alloc_size, MEM_RELEASE);
+                p_semaphore_type_info->semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+                p_semaphore_type_info->initialValue = 0;
             }
-        }
+            else
+            {
+                semaphore_type_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+                semaphore_type_info.pNext = semaphore_info_dup.pNext;
+                semaphore_type_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+                semaphore_type_info.initialValue = 0;
 
-        if (props.memoryTypeBits & (1u << info.memoryTypeIndex))
-        {
-            host_pointer_info.sType = VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT;
-            host_pointer_info.handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
-            host_pointer_info.pHostPointer = mapping;
-            host_pointer_info.pNext = info.pNext;
-            info.pNext = &host_pointer_info;
+                semaphore_info_dup.pNext = &semaphore_type_info;
+            }
 
-            info.allocationSize = (info.allocationSize + align) & ~align;
+            semaphore_info_dup.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+            break;
         }
+        default:
+            semaphore_info_dup.handleType = 0;
+            break;
     }
 
-    if (!(memory = malloc(sizeof(*memory))))
-        return VK_ERROR_OUT_OF_HOST_MEMORY;
-
-    result = device->p_vkAllocateMemory(device->host.device, &info, NULL, &host_device_memory);
-    if (result != VK_SUCCESS)
+    if (semaphore_info->handleType && !semaphore_info_dup.handleType)
     {
-        free(memory);
-        return result;
+        properties->exportFromImportedHandleTypes = 0;
+        properties->compatibleHandleTypes = 0;
+        properties->externalSemaphoreFeatures = 0;
+        return;
     }
 
-    vulkan_object_init(&memory->obj, host_device_memory);
-    memory->size = info.allocationSize;
-    memory->vm_map = mapping;
-    vulkan_instance_insert_object(instance, &memory->obj);
+    p_vkGetPhysicalDeviceExternalSemaphoreProperties(phys_dev->obj.host.physical_device, &semaphore_info_dup, properties);
 
-    *ret = memory->client.device_memory;
-    return VK_SUCCESS;
+    if (properties->exportFromImportedHandleTypes & VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT)
+        properties->exportFromImportedHandleTypes = semaphore_info->handleType;
+    wine_vk_normalize_semaphore_handle_types_win(&properties->exportFromImportedHandleTypes);
+
+    if (properties->compatibleHandleTypes & VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT)
+        properties->compatibleHandleTypes = semaphore_info->handleType;
+    wine_vk_normalize_semaphore_handle_types_win(&properties->compatibleHandleTypes);
 }
 
-void wine_vkFreeMemory(VkDevice client_device, VkDeviceMemory memory_handle, const VkAllocationCallbacks *allocator)
+void wine_vkGetPhysicalDeviceExternalSemaphoreProperties(VkPhysicalDevice client_physical_device,
+                                                         const VkPhysicalDeviceExternalSemaphoreInfo *info,
+                                                         VkExternalSemaphoreProperties *properties)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    struct vulkan_instance *instance = device->physical_device->instance;
-    struct wine_device_memory *memory;
+    struct wine_phys_dev *phys_dev = wine_phys_dev_from_handle(client_physical_device);
 
-    if (!memory_handle)
-        return;
-    memory = wine_device_memory_from_handle(memory_handle);
+    TRACE("%p, %p, %p\n", phys_dev, info, properties);
+    wine_vk_get_physical_device_external_semaphore_properties(phys_dev, phys_dev->obj.instance->p_vkGetPhysicalDeviceExternalSemaphoreProperties, info, properties);
+}
 
-    if (memory->vm_map && !physical_device->external_memory_align)
+void wine_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR(VkPhysicalDevice client_physical_device,
+                                                            const VkPhysicalDeviceExternalSemaphoreInfo *info,
+                                                            VkExternalSemaphoreProperties *properties)
+{
+    struct wine_phys_dev *phys_dev = wine_phys_dev_from_handle(client_physical_device);
+
+    TRACE("%p, %p, %p\n", phys_dev, info, properties);
+    wine_vk_get_physical_device_external_semaphore_properties(phys_dev, phys_dev->obj.instance->p_vkGetPhysicalDeviceExternalSemaphorePropertiesKHR, info, properties);
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_CREATE           CTL_CODE(FILE_DEVICE_VIDEO, 0, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+struct shared_resource_create
+{
+    UINT64 resource_size;
+    obj_handle_t unix_handle;
+    WCHAR name[1];
+};
+
+static HANDLE create_gpu_resource(int fd, LPCWSTR name, UINT64 resource_size)
+{
+    static const WCHAR shared_gpu_resourceW[] = {'\\','?','?','\\','S','h','a','r','e','d','G','p','u','R','e','s','o','u','r','c','e',0};
+    HANDLE unix_resource = INVALID_HANDLE_VALUE;
+    struct shared_resource_create *inbuff;
+    UNICODE_STRING shared_gpu_resource_us;
+    HANDLE shared_resource;
+    OBJECT_ATTRIBUTES attr;
+    IO_STATUS_BLOCK iosb;
+    NTSTATUS status;
+    DWORD in_size;
+
+    TRACE("Creating shared vulkan resource fd %d name %s.\n", fd, debugstr_w(name));
+
+    if (wine_server_fd_to_handle(fd, GENERIC_ALL, 0, &unix_resource) != STATUS_SUCCESS)
+        return INVALID_HANDLE_VALUE;
+
+    init_unicode_string(&shared_gpu_resource_us, shared_gpu_resourceW);
+
+    attr.Length = sizeof(attr);
+    attr.RootDirectory = 0;
+    attr.Attributes = 0;
+    attr.ObjectName = &shared_gpu_resource_us;
+    attr.SecurityDescriptor = NULL;
+    attr.SecurityQualityOfService = NULL;
+
+    if ((status = NtCreateFile(&shared_resource, GENERIC_READ | GENERIC_WRITE, &attr, &iosb, NULL, FILE_ATTRIBUTE_NORMAL, FILE_SHARE_READ | FILE_SHARE_WRITE, FILE_OPEN, 0, NULL, 0)))
     {
-        const VkMemoryUnmapInfoKHR info =
-        {
-            .sType = VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO_KHR,
-            .memory = memory->host.device_memory,
-            .flags = VK_MEMORY_UNMAP_RESERVE_BIT_EXT,
-        };
-        device->p_vkUnmapMemory2KHR(device->host.device, &info);
+        ERR("Failed to load open a shared resource handle, status %#lx.\n", (long int)status);
+        NtClose(unix_resource);
+        return INVALID_HANDLE_VALUE;
     }
 
-    device->p_vkFreeMemory(device->host.device, memory->host.device_memory, NULL);
-    vulkan_instance_remove_object(instance, &memory->obj);
+    in_size = sizeof(*inbuff) + (name ? lstrlenW(name) * sizeof(WCHAR) : 0);
+    inbuff = calloc(1, in_size);
+    inbuff->unix_handle = wine_server_obj_handle(unix_resource);
+    inbuff->resource_size = resource_size;
+    if (name)
+        lstrcpyW(&inbuff->name[0], name);
 
-    if (memory->vm_map)
+    if ((status = NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_CREATE,
+            inbuff, in_size, NULL, 0)))
+
+    free(inbuff);
+    NtClose(unix_resource);
+
+    if (status)
     {
-        SIZE_T alloc_size = 0;
-        NtFreeVirtualMemory(GetCurrentProcess(), &memory->vm_map, &alloc_size, MEM_RELEASE);
+        ERR("Failed to create video resource, status %#lx.\n", (long int)status);
+        NtClose(shared_resource);
+        return INVALID_HANDLE_VALUE;
     }
 
-    free(memory);
+    return shared_resource;
 }
 
-VkResult wine_vkMapMemory(VkDevice client_device, VkDeviceMemory memory, VkDeviceSize offset,
-                          VkDeviceSize size, VkMemoryMapFlags flags, void **data)
+#define IOCTL_SHARED_GPU_RESOURCE_OPEN             CTL_CODE(FILE_DEVICE_VIDEO, 1, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+struct shared_resource_open
 {
-    const VkMemoryMapInfoKHR info =
-    {
-      .sType = VK_STRUCTURE_TYPE_MEMORY_MAP_INFO_KHR,
-      .flags = flags,
-      .memory = memory,
-      .offset = offset,
-      .size = size,
-   };
+    obj_handle_t kmt_handle;
+    WCHAR name[1];
+};
 
-   return wine_vkMapMemory2KHR(client_device, &info, data);
-}
+struct shared_resource_info
+{
+    UINT64 resource_size;
+};
 
-VkResult wine_vkMapMemory2KHR(VkDevice client_device, const VkMemoryMapInfoKHR *map_info, void **data)
+static HANDLE open_shared_resource(HANDLE kmt_handle, LPCWSTR name)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    struct wine_device_memory *memory = wine_device_memory_from_handle(map_info->memory);
-    VkMemoryMapInfoKHR info = *map_info;
-    VkMemoryMapPlacedInfoEXT placed_info =
+    static const WCHAR shared_gpu_resourceW[] = {'\\','?','?','\\','S','h','a','r','e','d','G','p','u','R','e','s','o','u','r','c','e',0};
+    UNICODE_STRING shared_gpu_resource_us;
+    struct shared_resource_open *inbuff;
+    HANDLE shared_resource;
+    OBJECT_ATTRIBUTES attr;
+    IO_STATUS_BLOCK iosb;
+    NTSTATUS status;
+    DWORD in_size;
+
+    init_unicode_string(&shared_gpu_resource_us, shared_gpu_resourceW);
+
+    attr.Length = sizeof(attr);
+    attr.RootDirectory = 0;
+    attr.Attributes = 0;
+    attr.ObjectName = &shared_gpu_resource_us;
+    attr.SecurityDescriptor = NULL;
+    attr.SecurityQualityOfService = NULL;
+
+    if ((status = NtCreateFile(&shared_resource, GENERIC_READ | GENERIC_WRITE, &attr, &iosb, NULL, FILE_ATTRIBUTE_NORMAL, FILE_SHARE_READ | FILE_SHARE_WRITE, FILE_OPEN, 0, NULL, 0)))
     {
-        .sType = VK_STRUCTURE_TYPE_MEMORY_MAP_PLACED_INFO_EXT,
-    };
-    VkResult result;
+        ERR("Failed to load open a shared resource handle, status %#lx.\n", (long int)status);
+        return INVALID_HANDLE_VALUE;
+    }
 
-    info.memory = memory->host.device_memory;
-    if (memory->vm_map)
+    in_size = sizeof(*inbuff) + (name ? lstrlenW(name) * sizeof(WCHAR) : 0);
+    inbuff = calloc(1, in_size);
+    inbuff->kmt_handle = wine_server_obj_handle(kmt_handle);
+    if (name)
+        lstrcpyW(&inbuff->name[0], name);
+
+    status = NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_OPEN,
+            inbuff, in_size, NULL, 0);
+
+    free(inbuff);
+
+    if (status)
     {
-        *data = (char *)memory->vm_map + info.offset;
-        TRACE("returning %p\n", *data);
-        return VK_SUCCESS;
+        ERR("Failed to open video resource, status %#lx.\n", (long int)status);
+        NtClose(shared_resource);
+        return INVALID_HANDLE_VALUE;
     }
 
-    if (physical_device->map_placed_align)
-    {
-        SIZE_T alloc_size = memory->size;
+    return shared_resource;
+}
 
-        placed_info.pNext = info.pNext;
-        info.pNext = &placed_info;
-        info.offset = 0;
-        info.size = VK_WHOLE_SIZE;
-        info.flags |=  VK_MEMORY_MAP_PLACED_BIT_EXT;
+#define IOCTL_SHARED_GPU_RESOURCE_GET_INFO CTL_CODE(FILE_DEVICE_VIDEO, 7, METHOD_BUFFERED, FILE_READ_ACCESS)
 
-        if (NtAllocateVirtualMemory(GetCurrentProcess(), &placed_info.pPlacedAddress, zero_bits, &alloc_size,
-                                    MEM_COMMIT, PAGE_READWRITE))
-        {
-            ERR("NtAllocateVirtualMemory failed\n");
-            return VK_ERROR_OUT_OF_HOST_MEMORY;
-        }
-    }
+static BOOL shared_resource_get_info(HANDLE handle, struct shared_resource_info *info)
+{
+    IO_STATUS_BLOCK iosb;
+    unsigned int status;
 
-    if (device->p_vkMapMemory2KHR)
+    status = NtDeviceIoControlFile(handle, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_GET_INFO,
+            NULL, 0, info, sizeof(*info));
+    if (status)
+        ERR("Failed to get shared resource info, status %#x.\n", status);
+
+    return !status;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_UNIX_RESOURCE           CTL_CODE(FILE_DEVICE_VIDEO, 3, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static int get_shared_resource_fd(HANDLE shared_resource)
+{
+    IO_STATUS_BLOCK iosb;
+    obj_handle_t unix_resource;
+    NTSTATUS status;
+    int ret;
+
+    if (NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_GET_UNIX_RESOURCE,
+            NULL, 0, &unix_resource, sizeof(unix_resource)))
+        return -1;
+
+    status = wine_server_handle_to_fd(wine_server_ptr_handle(unix_resource), FILE_READ_DATA, &ret, NULL);
+    NtClose(wine_server_ptr_handle(unix_resource));
+    return status == STATUS_SUCCESS ? ret : -1;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GETKMT           CTL_CODE(FILE_DEVICE_VIDEO, 2, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static HANDLE get_shared_resource_kmt_handle(HANDLE shared_resource)
+{
+    IO_STATUS_BLOCK iosb;
+    obj_handle_t kmt_handle;
+
+    if (NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_GETKMT,
+            NULL, 0, &kmt_handle, sizeof(kmt_handle)))
+        return INVALID_HANDLE_VALUE;
+
+    return wine_server_ptr_handle(kmt_handle);
+}
+
+static bool set_shared_resource_object(HANDLE shared_resource, unsigned int index, HANDLE handle);
+static HANDLE get_shared_resource_object(HANDLE shared_resource, unsigned int index);
+
+static void destroy_keyed_mutex(struct vulkan_device *device, struct wine_device_memory *memory)
+{
+    if (memory->keyed_mutex_shm)
     {
-        result = device->p_vkMapMemory2KHR(device->host.device, &info, data);
+        NtUnmapViewOfSection(GetCurrentProcess(), memory->keyed_mutex_shm);
+        memory->keyed_mutex_shm = NULL;
     }
-    else
+    if (memory->keyed_mutex_sem)
     {
-        assert(!info.pNext);
-        result = device->p_vkMapMemory(device->host.device, info.memory, info.offset,
-                                             info.size, info.flags, data);
+        device->p_vkDestroySemaphore(device->host.device, memory->keyed_mutex_sem, NULL);
+        memory->keyed_mutex_sem = VK_NULL_HANDLE;
     }
+}
 
-    if (placed_info.pPlacedAddress)
+static void create_keyed_mutex(struct vulkan_device *device, struct wine_device_memory *memory)
+{
+    VkExportSemaphoreCreateInfo timeline_export_info;
+    VkSemaphoreTypeCreateInfo type_info;
+    VkSemaphoreCreateInfo create_info;
+    VkSemaphoreGetFdInfoKHR fd_info;
+    pthread_mutexattr_t mutex_attr;
+    OBJECT_ATTRIBUTES attr;
+    HANDLE section_handle;
+    LARGE_INTEGER li;
+    HANDLE handle;
+    SIZE_T size;
+    VkResult vr;
+    int fd;
+
+    InitializeObjectAttributes(&attr, NULL, 0, NULL, NULL);
+    size = li.QuadPart = sizeof(*memory->keyed_mutex_shm);
+    if (NtCreateSection(&section_handle, STANDARD_RIGHTS_REQUIRED | SECTION_QUERY | SECTION_MAP_READ | SECTION_MAP_WRITE, &attr, &li, PAGE_READWRITE, SEC_COMMIT, NULL))
     {
-        if (result != VK_SUCCESS)
-        {
-            SIZE_T alloc_size = 0;
-            ERR("vkMapMemory2EXT failed: %d\n", result);
-            NtFreeVirtualMemory(GetCurrentProcess(), &placed_info.pPlacedAddress, &alloc_size, MEM_RELEASE);
-            return result;
-        }
-        memory->vm_map = placed_info.pPlacedAddress;
-        *data = (char *)memory->vm_map + map_info->offset;
-        TRACE("Using placed mapping %p\n", memory->vm_map);
+        ERR("NtCreateSection failed.\n");
+        return;
     }
 
-#ifdef _WIN64
-    if (NtCurrentTeb()->WowTebOffset && result == VK_SUCCESS && (UINT_PTR)*data >> 32)
+    if (!set_shared_resource_object(memory->handle, 0, section_handle))
     {
-        FIXME("returned mapping %p does not fit 32-bit pointer\n", *data);
-        device->p_vkUnmapMemory(device->host.device, memory->host.device_memory);
-        *data = NULL;
-        result = VK_ERROR_OUT_OF_HOST_MEMORY;
+        NtClose(section_handle);
+        ERR("set_shared_resource_object failed.\n");
+        return;
     }
-#endif
 
-    return result;
-}
-
-void wine_vkUnmapMemory(VkDevice client_device, VkDeviceMemory memory)
-{
-    const VkMemoryUnmapInfoKHR info =
+    if (NtMapViewOfSection(section_handle, GetCurrentProcess(), (void**) &memory->keyed_mutex_shm, 0, 0, NULL, &size, ViewShare, 0, PAGE_READWRITE))
     {
-        .sType = VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO_KHR,
-        .memory = memory,
-    };
+        NtClose(section_handle);
+        ERR("NtMapViewOfSection failed.\n");
+        return;
+    }
 
-    wine_vkUnmapMemory2KHR(client_device, &info);
-}
+    NtClose(section_handle);
 
-VkResult wine_vkUnmapMemory2KHR(VkDevice client_device, const VkMemoryUnmapInfoKHR *unmap_info)
-{
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    struct wine_device_memory *memory = wine_device_memory_from_handle(unmap_info->memory);
-    VkMemoryUnmapInfoKHR info;
-    VkResult result;
+    timeline_export_info.sType = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO;
+    timeline_export_info.pNext = NULL;
+    timeline_export_info.handleTypes = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
 
-    if (memory->vm_map && physical_device->external_memory_align)
-        return VK_SUCCESS;
+    type_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+    type_info.pNext = &timeline_export_info;
+    type_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+    type_info.initialValue = 0;
 
-    if (!device->p_vkUnmapMemory2KHR)
+    create_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+    create_info.pNext = &type_info;
+    create_info.flags = 0;
+
+    if ((vr = device->p_vkCreateSemaphore(device->host.device, &create_info, NULL, &memory->keyed_mutex_sem)) != VK_SUCCESS)
     {
-        assert(!unmap_info->pNext && !memory->vm_map);
-        device->p_vkUnmapMemory(device->host.device, memory->host.device_memory);
-        return VK_SUCCESS;
+        ERR("Failed to create semaphore, vr %d.\n", vr);
+        goto error;
     }
+    fd_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR;
+    fd_info.pNext = NULL;
+    fd_info.semaphore = memory->keyed_mutex_sem;
+    fd_info.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
 
-    info = *unmap_info;
-    info.memory = memory->host.device_memory;
-    if (memory->vm_map)
-        info.flags |= VK_MEMORY_UNMAP_RESERVE_BIT_EXT;
-
-    result = device->p_vkUnmapMemory2KHR(device->host.device, &info);
-
-    if (result == VK_SUCCESS && memory->vm_map)
+    if ((vr = device->p_vkGetSemaphoreFdKHR(device->host.device, &fd_info, &fd)) != VK_SUCCESS)
     {
-        SIZE_T size = 0;
-        NtFreeVirtualMemory(GetCurrentProcess(), &memory->vm_map, &size, MEM_RELEASE);
-        memory->vm_map = NULL;
+        ERR("Failed to export semaphore fd, vr %d.\n", vr);
+        goto error;
     }
-    return result;
+    if (wine_server_fd_to_handle(fd, GENERIC_ALL, 0, &handle) != STATUS_SUCCESS)
+    {
+        ERR("wine_server_fd_to_handle failed.\n");
+        close(fd);
+        goto error;
+    }
+    close(fd);
+    if (!set_shared_resource_object(memory->handle, 1, handle))
+    {
+        ERR("set_shared_resource_object failed.\n");
+        NtClose(handle);
+        goto error;
+    }
+    NtClose(handle);
+
+    pthread_mutexattr_init(&mutex_attr);
+    pthread_mutexattr_setpshared(&mutex_attr, PTHREAD_PROCESS_SHARED);
+    if (pthread_mutex_init(&memory->keyed_mutex_shm->mutex, &mutex_attr))
+    memory->keyed_mutex_shm->instance_id_counter = 1;
+    memory->keyed_mutex_instance_id = ++memory->keyed_mutex_shm->instance_id_counter;
+    TRACE("memory %p, created keyed mutex.\n", memory);
+    return;
+
+error:
+    destroy_keyed_mutex(device, memory);
 }
 
-VkResult wine_vkCreateBuffer(VkDevice client_device, const VkBufferCreateInfo *create_info,
-                             const VkAllocationCallbacks *allocator, VkBuffer *buffer)
+static void import_keyed_mutex(struct vulkan_device *device, struct wine_device_memory *memory)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    VkExternalMemoryBufferCreateInfo external_memory_info;
-    VkBufferCreateInfo info = *create_info;
+    VkSemaphoreTypeCreateInfo type_info;
+    VkImportSemaphoreFdInfoKHR fd_info;
+    VkSemaphoreCreateInfo create_info;
+    HANDLE section_handle, sem_handle;
+    SIZE_T size;
 
-    if (physical_device->external_memory_align &&
-        !find_next_struct(info.pNext, VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO))
+    VkResult vr;
+
+    if (!(section_handle = get_shared_resource_object(memory->handle, 0)))
     {
-        external_memory_info.sType = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO;
-        external_memory_info.pNext = info.pNext;
-        external_memory_info.handleTypes = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
-        info.pNext = &external_memory_info;
+        TRACE("No section handle.\n");
+        return;
+    }
+    if (!(sem_handle = get_shared_resource_object(memory->handle, 1)))
+    {
+        ERR("No smeaphore handle.\n");
+        NtClose(section_handle);
+        return;
     }
 
-    return device->p_vkCreateBuffer(device->host.device, &info, NULL, buffer);
-}
+    size = sizeof(*memory->keyed_mutex_shm);
+    if (NtMapViewOfSection(section_handle, GetCurrentProcess(), (void**) &memory->keyed_mutex_shm, 0, 0, NULL, &size, ViewShare, 0, PAGE_READWRITE))
+    {
+        ERR("NtMapViewOfSection failed.\n");
+        goto error;
+    }
 
-VkResult wine_vkCreateImage(VkDevice client_device, const VkImageCreateInfo *create_info,
-                            const VkAllocationCallbacks *allocator, VkImage *image)
-{
-    struct vulkan_device *device = vulkan_device_from_handle(client_device);
-    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
-    VkExternalMemoryImageCreateInfo external_memory_info;
-    VkImageCreateInfo info = *create_info;
+    type_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+    type_info.pNext = NULL;
+    type_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+    type_info.initialValue = 0;
 
-    if (physical_device->external_memory_align &&
-        !find_next_struct(info.pNext, VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO))
+    create_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+    create_info.pNext = &type_info;
+    create_info.flags = 0;
+
+    if ((vr = device->p_vkCreateSemaphore(device->host.device, &create_info, NULL, &memory->keyed_mutex_sem)) != VK_SUCCESS)
     {
-        external_memory_info.sType = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO;
-        external_memory_info.pNext = info.pNext;
-        external_memory_info.handleTypes = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
-        info.pNext = &external_memory_info;
+        ERR("Failed to create semaphore, vr %d.\n", vr);
+        goto error;
     }
 
-    return device->p_vkCreateImage(device->host.device, &info, NULL, image);
+    fd_info.sType = VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_FD_INFO_KHR;
+    fd_info.pNext = NULL;
+    fd_info.semaphore = memory->keyed_mutex_sem;
+    fd_info.flags = 0;
+    fd_info.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+    if (wine_server_handle_to_fd(sem_handle, FILE_READ_DATA, &fd_info.fd, NULL))
+    {
+        ERR("wine_server_handle_to_fd failed.\n");
+        goto error;
+    }
+
+    vr = device->p_vkImportSemaphoreFdKHR(device->host.device, &fd_info);
+    if (vr != VK_SUCCESS)
+    {
+        ERR("vkImportSemaphoreFdKHR failed, vr %d.\n", vr);
+        close(fd_info.fd);
+        goto error;
+    }
+    /* Not closing fd on successful import, the driver now owns it. */
+
+    memory->keyed_mutex_instance_id = InterlockedIncrement64((LONGLONG *)&memory->keyed_mutex_shm->instance_id_counter);
+    TRACE("memory %p, imported keyed mutex.\n", memory);
+    return;
+error:
+    NtClose(section_handle);
+    NtClose(sem_handle);
+    destroy_keyed_mutex(device, memory);
 }
 
-VkResult wine_vkCreateDebugUtilsMessengerEXT(VkInstance client_instance,
-                                             const VkDebugUtilsMessengerCreateInfoEXT *create_info,
-                                             const VkAllocationCallbacks *allocator,
-                                             VkDebugUtilsMessengerEXT *messenger)
+static VkResult acquire_keyed_mutex(struct vulkan_device *device, struct wine_device_memory *memory, uint64_t key,
+        uint32_t timeout_ms)
 {
-    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
-    VkDebugUtilsMessengerCreateInfoEXT wine_create_info;
-    VkDebugUtilsMessengerEXT host_debug_messenger;
-    struct wine_debug_utils_messenger *object;
-    VkResult res;
+    ULONG end_wait, curr_tick, remaining_wait;
+    VkSemaphoreWaitInfo wait_info = { 0 };
+    uint64_t timeline;
+    VkResult vr;
 
-    if (allocator)
-        FIXME("Support for allocation callbacks not implemented yet\n");
+    if (!memory->keyed_mutex_shm)
+        return VK_ERROR_UNKNOWN;
 
-    if (!(object = calloc(1, sizeof(*object))))
-        return VK_ERROR_OUT_OF_HOST_MEMORY;
+    wait_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO;
+    wait_info.semaphoreCount = 1;
+    wait_info.pSemaphores = &memory->keyed_mutex_sem;
+    wait_info.pValues = &timeline;
 
-    wine_create_info = *create_info;
-    wine_create_info.pfnUserCallback = (void *) &debug_utils_callback_conversion;
-    wine_create_info.pUserData = object;
+    end_wait = NtGetTickCount() + timeout_ms;
 
-    res = instance->p_vkCreateDebugUtilsMessengerEXT(instance->host.instance, &wine_create_info,
-                                                           NULL, &host_debug_messenger);
-    if (res != VK_SUCCESS)
+    while (1)
     {
-        free(object);
-        return res;
-    }
-
-    vulkan_object_init(&object->obj, host_debug_messenger);
-    object->instance = instance;
-    object->user_callback = (UINT_PTR)create_info->pfnUserCallback;
-    object->user_data = (UINT_PTR)create_info->pUserData;
-    vulkan_instance_insert_object(instance, &object->obj);
+        pthread_mutex_lock(&memory->keyed_mutex_shm->mutex);
+
+        if (memory->keyed_mutex_shm->acquired_to_instance)
+        {
+            if ((vr = get_semaphore_value(device, memory->keyed_mutex_sem, &timeline)) != VK_SUCCESS)
+            {
+                pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+                return VK_ERROR_UNKNOWN;
+            }
+            assert(timeline == memory->keyed_mutex_shm->timeline_value
+                    || timeline == memory->keyed_mutex_shm->timeline_value + 1);
+            if (timeline == memory->keyed_mutex_shm->timeline_value + 1)
+            {
+                /* released from queue. */
+                assert(memory->keyed_mutex_shm->timeline_queued_release == timeline);
+                memory->keyed_mutex_shm->timeline_queued_release = 0;
+                ++memory->keyed_mutex_shm->timeline_value;
+                memory->keyed_mutex_shm->acquired_to_instance = 0;
+            }
+        }
+
+        if (memory->keyed_mutex_shm->acquired_to_instance == memory->keyed_mutex_instance_id
+                && !memory->keyed_mutex_shm->timeline_queued_release)
+        {
+            /* Already acquired to this device. */
+            pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+            return VK_ERROR_UNKNOWN;
+        }
+        if (!memory->keyed_mutex_shm->acquired_to_instance && memory->keyed_mutex_shm->key == key)
+        {
+            /* Can acquire. */
+            memory->keyed_mutex_shm->acquired_to_instance = memory->keyed_mutex_instance_id;
+            pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+            return VK_SUCCESS;
+        }
+        curr_tick = NtGetTickCount();
+        if (!timeout_ms || curr_tick >= end_wait)
+        {
+            pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+            return VK_TIMEOUT;
+        }
+        remaining_wait = timeout_ms == INFINITE ? INFINITE : end_wait - curr_tick;
+        timeline = memory->keyed_mutex_shm->timeline_value + 1;
+        pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+
+        vr = wait_semaphores(device, &wait_info, remaining_wait * 1000000ull);
+        if (vr != VK_SUCCESS && vr != VK_TIMEOUT)
+        {
+            ERR("vkWaitSemaphores failed, vr %d.\n", vr);
+            return VK_ERROR_UNKNOWN;
+        }
+    }
+}
+
+static VkResult release_keyed_mutex(struct vulkan_device *device, struct wine_device_memory *memory, uint64_t key,
+        uint64_t *timeline_value)
+{
+    if (!memory->keyed_mutex_shm)
+        return VK_ERROR_UNKNOWN;
+
+    pthread_mutex_lock(&memory->keyed_mutex_shm->mutex);
+    if (memory->keyed_mutex_shm->acquired_to_instance != memory->keyed_mutex_instance_id
+            || memory->keyed_mutex_shm->timeline_queued_release)
+    {
+        pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+        return VK_ERROR_UNKNOWN;
+    }
+    memory->keyed_mutex_shm->key = key;
+    if (timeline_value)
+    {
+        /* Return timeline value to signal from queue. */
+        *timeline_value = memory->keyed_mutex_shm->timeline_value + 1;
+        memory->keyed_mutex_shm->timeline_queued_release = *timeline_value;
+    }
+    else
+    {
+        /* Release immediately. */
+        memory->keyed_mutex_shm->acquired_to_instance = 0;
+        signal_timeline_sem(device, memory->keyed_mutex_sem, &memory->keyed_mutex_shm->timeline_value);
+    }
+    pthread_mutex_unlock(&memory->keyed_mutex_shm->mutex);
+
+    return VK_SUCCESS;
+}
+
+VkResult wine_vkAllocateMemory(VkDevice client_device, const VkMemoryAllocateInfo *alloc_info,
+                               const VkAllocationCallbacks *allocator, VkDeviceMemory *ret)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    struct vulkan_instance *instance = device->physical_device->instance;
+    struct wine_instance *wine_instance = CONTAINING_RECORD(instance, struct wine_instance, obj);
+    struct wine_device_memory *memory;
+    VkMemoryAllocateInfo info = *alloc_info;
+    VkImportMemoryHostPointerInfoEXT host_pointer_info;
+    VkDeviceMemory host_device_memory;
+    uint32_t mem_flags;
+    void *mapping = NULL;
+    VkResult result;
+
+    const VkImportMemoryWin32HandleInfoKHR *handle_import_info;
+    const VkExportMemoryWin32HandleInfoKHR *handle_export_info;
+    VkExportMemoryAllocateInfo *export_info;
+    VkImportMemoryFdInfoKHR fd_import_info;
+    VkMemoryGetFdInfoKHR get_fd_info;
+    int fd;
+
+    if (!(memory = calloc(sizeof(*memory), 1)))
+        return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+    memory->handle = INVALID_HANDLE_VALUE;
+    fd_import_info.fd = -1;
+    fd_import_info.pNext = NULL;
+
+    /* find and process handle import/export info and grab it */
+    handle_import_info = wine_vk_find_unlink_struct(&info, IMPORT_MEMORY_WIN32_HANDLE_INFO_KHR);
+    handle_export_info = wine_vk_find_unlink_struct(&info, EXPORT_MEMORY_WIN32_HANDLE_INFO_KHR);
+    if (handle_export_info && handle_export_info->pAttributes && handle_export_info->pAttributes->lpSecurityDescriptor)
+        FIXME("Support for custom security descriptor not implemented.\n");
+
+    if ((export_info = find_next_struct(alloc_info, VK_STRUCTURE_TYPE_EXPORT_MEMORY_ALLOCATE_INFO)))
+    {
+        memory->handle_types = export_info->handleTypes;
+        if (export_info->handleTypes & wine_vk_handle_over_fd_types)
+            export_info->handleTypes |= VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+        wine_vk_normalize_handle_types_host(&export_info->handleTypes);
+    }
+
+    mem_flags = physical_device->memory_properties.memoryTypes[alloc_info->memoryTypeIndex].propertyFlags;
+
+    /* Vulkan consumes imported FDs, but not imported HANDLEs */
+    if (handle_import_info)
+    {
+        struct shared_resource_info res_info;
+
+        fd_import_info.sType = VK_STRUCTURE_TYPE_IMPORT_MEMORY_FD_INFO_KHR;
+        fd_import_info.pNext = info.pNext;
+        fd_import_info.handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+        info.pNext = &fd_import_info;
+
+        TRACE("import handle type %#x.\n", handle_import_info->handleType);
+
+        switch (handle_import_info->handleType)
+        {
+            case VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT:
+            case VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT:
+                if (handle_import_info->handle)
+                    NtDuplicateObject( NtCurrentProcess(), handle_import_info->handle, NtCurrentProcess(), &memory->handle, 0, 0, DUPLICATE_SAME_ACCESS );
+                else if (handle_import_info->name)
+                    memory->handle = open_shared_resource( 0, handle_import_info->name );
+                break;
+            case VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT:
+            case VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT:
+                /* FIXME: the spec says that device memory imported from a KMT handle doesn't keep a reference to the underyling payload.
+                   This means that in cases where on windows an application leaks VkDeviceMemory objects, we leak the full payload.  To
+                   fix this, we would need wine_dev_mem objects to store no reference to the payload, that means no host VkDeviceMemory
+                   object (as objects imported from FDs hold a reference to the payload), and no win32 handle to the object. We would then
+                   extend make_vulkan to have the thunks converting wine_dev_mem to native handles open the VkDeviceMemory from the KMT
+                   handle, use it in the host function, then close it again. */
+                memory->handle = open_shared_resource( handle_import_info->handle, NULL );
+                break;
+            default:
+                WARN("Invalid handle type %08x passed in.\n", handle_import_info->handleType);
+                result = VK_ERROR_INVALID_EXTERNAL_HANDLE;
+                goto done;
+        }
+
+        if (memory->handle != INVALID_HANDLE_VALUE)
+            fd_import_info.fd = get_shared_resource_fd(memory->handle);
+
+        if (fd_import_info.fd == -1)
+        {
+            TRACE("Couldn't access resource handle or name. type=%08x handle=%p name=%s\n", handle_import_info->handleType, handle_import_info->handle,
+                    handle_import_info->name ? debugstr_w(handle_import_info->name) : "");
+            result = VK_ERROR_INVALID_EXTERNAL_HANDLE;
+            goto done;
+        }
+
+        /* From VkMemoryAllocateInfo spec: "if the parameters define an import operation and the external handle type is
+         * VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT, VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT,
+         * or VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D12_RESOURCE_BIT, allocationSize is ignored.". Although test suggests
+         * that it is also true for opaque Win32 handles. */
+        if (shared_resource_get_info(memory->handle, &res_info))
+        {
+            if (res_info.resource_size)
+            {
+                TRACE("Shared resource size %llu.\n", (long long)res_info.resource_size);
+                if (info.allocationSize && info.allocationSize != res_info.resource_size)
+                    FIXME("Shared resource allocationSize %llu, resource_size %llu.\n",
+                            (long long)info.allocationSize, (long long)res_info.resource_size);
+                info.allocationSize = res_info.resource_size;
+            }
+            else
+            {
+                ERR("Zero shared resource size.\n");
+            }
+        }
+        if (device->keyed_mutexes_enabled)
+            import_keyed_mutex(device, memory);
+    }
+    else if (physical_device->external_memory_align && (mem_flags & VK_MEMORY_PROPERTY_HOST_VISIBLE_BIT) &&
+        !find_next_struct(alloc_info->pNext, VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT))
+    {
+        /* For host visible memory, we try to use VK_EXT_external_memory_host on wow64
+         * to ensure that mapped pointer is 32-bit. */
+        VkMemoryHostPointerPropertiesEXT props =
+        {
+            .sType = VK_STRUCTURE_TYPE_MEMORY_HOST_POINTER_PROPERTIES_EXT,
+        };
+        uint32_t i, align = physical_device->external_memory_align - 1;
+        SIZE_T alloc_size = info.allocationSize;
+        static int once;
+
+        if (!once++)
+            FIXME("Using VK_EXT_external_memory_host\n");
+
+        if (NtAllocateVirtualMemory(GetCurrentProcess(), &mapping, zero_bits, &alloc_size,
+                                    MEM_COMMIT, PAGE_READWRITE))
+        {
+            ERR("NtAllocateVirtualMemory failed\n");
+            free(memory);
+            return VK_ERROR_OUT_OF_HOST_MEMORY;
+        }
+
+        result = device->p_vkGetMemoryHostPointerPropertiesEXT(device->host.device,
+                VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT, mapping, &props);
+        if (result != VK_SUCCESS)
+        {
+            ERR("vkGetMemoryHostPointerPropertiesEXT failed: %d\n", result);
+            free(memory);
+            return result;
+        }
+
+        if (!(props.memoryTypeBits & (1u << info.memoryTypeIndex)))
+        {
+            /* If requested memory type is not allowed to use external memory,
+             * try to find a supported compatible type. */
+            uint32_t mask = mem_flags & ~VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT;
+            for (i = 0; i < physical_device->memory_properties.memoryTypeCount; i++)
+            {
+                if (!(props.memoryTypeBits & (1u << i)))
+                    continue;
+                if ((physical_device->memory_properties.memoryTypes[i].propertyFlags & mask) != mask)
+                    continue;
+
+                TRACE("Memory type not compatible with host memory, using %u instead\n", i);
+                info.memoryTypeIndex = i;
+                break;
+            }
+            if (i == physical_device->memory_properties.memoryTypeCount)
+            {
+                FIXME("Not found compatible memory type\n");
+                alloc_size = 0;
+                NtFreeVirtualMemory(GetCurrentProcess(), &mapping, &alloc_size, MEM_RELEASE);
+            }
+        }
+
+        if (props.memoryTypeBits & (1u << info.memoryTypeIndex))
+        {
+            host_pointer_info.sType = VK_STRUCTURE_TYPE_IMPORT_MEMORY_HOST_POINTER_INFO_EXT;
+            host_pointer_info.handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
+            host_pointer_info.pHostPointer = mapping;
+            host_pointer_info.pNext = info.pNext;
+            info.pNext = &host_pointer_info;
+
+            info.allocationSize = (info.allocationSize + align) & ~align;
+        }
+    }
+
+    set_transient_client_handle(wine_instance, (uintptr_t)memory);
+    result = device->p_vkAllocateMemory(device->host.device, &info, NULL, &host_device_memory);
+    if (result == VK_SUCCESS && memory->handle == INVALID_HANDLE_VALUE && export_info && export_info->handleTypes & VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT)
+    {
+        get_fd_info.sType = VK_STRUCTURE_TYPE_MEMORY_GET_FD_INFO_KHR;
+        get_fd_info.pNext = NULL;
+        get_fd_info.memory = host_device_memory;
+        get_fd_info.handleType = VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+        if (device->p_vkGetMemoryFdKHR(device->host.device, &get_fd_info, &fd) == VK_SUCCESS)
+        {
+            memory->handle = create_gpu_resource(fd, handle_export_info ? handle_export_info->name : NULL, alloc_info->allocationSize);
+            memory->access = handle_export_info ? handle_export_info->dwAccess : GENERIC_ALL;
+            if (handle_export_info && handle_export_info->pAttributes)
+                memory->inherit = handle_export_info->pAttributes->bInheritHandle;
+            else
+                memory->inherit = FALSE;
+            close(fd);
+            if (device->keyed_mutexes_enabled)
+                create_keyed_mutex(device, memory);
+        }
+
+        if (memory->handle == INVALID_HANDLE_VALUE)
+        {
+            device->p_vkFreeMemory(device->host.device, host_device_memory, NULL);
+            result = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+    }
+done:
+    if (result != VK_SUCCESS)
+    {
+        if (fd_import_info.fd != -1)
+            close(fd_import_info.fd);
+        if (memory->handle != INVALID_HANDLE_VALUE)
+            NtClose(memory->handle);
+        free(memory);
+        return result;
+    }
+
+    vulkan_object_init(&memory->obj, host_device_memory);
+    memory->size = info.allocationSize;
+    memory->vm_map = mapping;
+    vulkan_instance_insert_object(instance, &memory->obj);
+
+    *ret = memory->client.device_memory;
+    return VK_SUCCESS;
+}
+
+void wine_vkFreeMemory(VkDevice client_device, VkDeviceMemory memory_handle, const VkAllocationCallbacks *allocator)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    struct vulkan_instance *instance = device->physical_device->instance;
+    struct wine_device_memory *memory;
+
+    if (!memory_handle)
+        return;
+    memory = wine_device_memory_from_handle(memory_handle);
+
+    destroy_keyed_mutex(device, memory);
+    if (memory->vm_map && !physical_device->external_memory_align)
+    {
+        const VkMemoryUnmapInfoKHR info =
+        {
+            .sType = VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO_KHR,
+            .memory = memory->host.device_memory,
+            .flags = VK_MEMORY_UNMAP_RESERVE_BIT_EXT,
+        };
+        device->p_vkUnmapMemory2KHR(device->host.device, &info);
+    }
+
+    device->p_vkFreeMemory(device->host.device, memory->host.device_memory, NULL);
+    vulkan_instance_remove_object(instance, &memory->obj);
+
+    if (memory->vm_map)
+    {
+        SIZE_T alloc_size = 0;
+        NtFreeVirtualMemory(GetCurrentProcess(), &memory->vm_map, &alloc_size, MEM_RELEASE);
+    }
+
+    if (memory->handle != INVALID_HANDLE_VALUE)
+        NtClose(memory->handle);
+
+    free(memory);
+}
+
+VkResult wine_vkMapMemory(VkDevice client_device, VkDeviceMemory memory, VkDeviceSize offset,
+                          VkDeviceSize size, VkMemoryMapFlags flags, void **data)
+{
+    const VkMemoryMapInfoKHR info =
+    {
+      .sType = VK_STRUCTURE_TYPE_MEMORY_MAP_INFO_KHR,
+      .flags = flags,
+      .memory = memory,
+      .offset = offset,
+      .size = size,
+   };
+
+   return wine_vkMapMemory2KHR(client_device, &info, data);
+}
+
+VkResult wine_vkMapMemory2KHR(VkDevice client_device, const VkMemoryMapInfoKHR *map_info, void **data)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    struct wine_device_memory *memory = wine_device_memory_from_handle(map_info->memory);
+    VkMemoryMapInfoKHR info = *map_info;
+    VkMemoryMapPlacedInfoEXT placed_info =
+    {
+        .sType = VK_STRUCTURE_TYPE_MEMORY_MAP_PLACED_INFO_EXT,
+    };
+    VkResult result;
+
+    info.memory = memory->host.device_memory;
+    if (memory->vm_map)
+    {
+        *data = (char *)memory->vm_map + info.offset;
+        TRACE("returning %p\n", *data);
+        return VK_SUCCESS;
+    }
+
+    if (physical_device->map_placed_align)
+    {
+        SIZE_T alloc_size = memory->size;
+
+        placed_info.pNext = info.pNext;
+        info.pNext = &placed_info;
+        info.offset = 0;
+        info.size = VK_WHOLE_SIZE;
+        info.flags |=  VK_MEMORY_MAP_PLACED_BIT_EXT;
+
+        if (NtAllocateVirtualMemory(GetCurrentProcess(), &placed_info.pPlacedAddress, zero_bits, &alloc_size,
+                                    MEM_COMMIT, PAGE_READWRITE))
+        {
+            ERR("NtAllocateVirtualMemory failed\n");
+            return VK_ERROR_OUT_OF_HOST_MEMORY;
+        }
+    }
+
+    if (device->p_vkMapMemory2KHR)
+    {
+        result = device->p_vkMapMemory2KHR(device->host.device, &info, data);
+    }
+    else
+    {
+        assert(!info.pNext);
+        result = device->p_vkMapMemory(device->host.device, info.memory, info.offset,
+                                             info.size, info.flags, data);
+    }
+
+    if (placed_info.pPlacedAddress)
+    {
+        if (result != VK_SUCCESS)
+        {
+            SIZE_T alloc_size = 0;
+            ERR("vkMapMemory2EXT failed: %d\n", result);
+            NtFreeVirtualMemory(GetCurrentProcess(), &placed_info.pPlacedAddress, &alloc_size, MEM_RELEASE);
+            return result;
+        }
+        memory->vm_map = placed_info.pPlacedAddress;
+        *data = (char *)memory->vm_map + map_info->offset;
+        TRACE("Using placed mapping %p\n", memory->vm_map);
+    }
+
+#ifdef _WIN64
+    if (NtCurrentTeb()->WowTebOffset && result == VK_SUCCESS && (UINT_PTR)*data >> 32)
+    {
+        FIXME("returned mapping %p does not fit 32-bit pointer\n", *data);
+        device->p_vkUnmapMemory(device->host.device, memory->host.device_memory);
+        *data = NULL;
+        result = VK_ERROR_OUT_OF_HOST_MEMORY;
+    }
+#endif
+
+    return result;
+}
+
+void wine_vkUnmapMemory(VkDevice client_device, VkDeviceMemory memory)
+{
+    const VkMemoryUnmapInfoKHR info =
+    {
+        .sType = VK_STRUCTURE_TYPE_MEMORY_UNMAP_INFO_KHR,
+        .memory = memory,
+    };
+
+    wine_vkUnmapMemory2KHR(client_device, &info);
+}
+
+VkResult wine_vkUnmapMemory2KHR(VkDevice client_device, const VkMemoryUnmapInfoKHR *unmap_info)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    struct wine_device_memory *memory = wine_device_memory_from_handle(unmap_info->memory);
+    VkMemoryUnmapInfoKHR info;
+    VkResult result;
+
+    if (memory->vm_map && physical_device->external_memory_align)
+        return VK_SUCCESS;
+
+    if (!device->p_vkUnmapMemory2KHR)
+    {
+        assert(!unmap_info->pNext && !memory->vm_map);
+        device->p_vkUnmapMemory(device->host.device, memory->host.device_memory);
+        return VK_SUCCESS;
+    }
+
+    info = *unmap_info;
+    info.memory = memory->host.device_memory;
+    if (memory->vm_map)
+        info.flags |= VK_MEMORY_UNMAP_RESERVE_BIT_EXT;
+
+    result = device->p_vkUnmapMemory2KHR(device->host.device, &info);
+
+    if (result == VK_SUCCESS && memory->vm_map)
+    {
+        SIZE_T size = 0;
+        NtFreeVirtualMemory(GetCurrentProcess(), &memory->vm_map, &size, MEM_RELEASE);
+        memory->vm_map = NULL;
+    }
+    return result;
+}
+
+VkResult wine_vkCreateBuffer(VkDevice client_device, const VkBufferCreateInfo *create_info,
+                             const VkAllocationCallbacks *allocator, VkBuffer *buffer)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    VkExternalMemoryBufferCreateInfo external_memory_info, *ext_info;
+    VkBufferCreateInfo info = *create_info;
+
+    if ((ext_info = find_next_struct(create_info, VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO)))
+    {
+        if (ext_info->handleTypes & wine_vk_handle_over_fd_types)
+            ext_info->handleTypes |= VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT;
+        wine_vk_normalize_handle_types_host(&ext_info->handleTypes);
+    }
+    else if (physical_device->external_memory_align &&
+        !find_next_struct(info.pNext, VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO))
+    {
+        external_memory_info.sType = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_BUFFER_CREATE_INFO;
+        external_memory_info.pNext = info.pNext;
+        external_memory_info.handleTypes = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
+        info.pNext = &external_memory_info;
+    }
+
+    return device->p_vkCreateBuffer(device->host.device, &info, NULL, buffer);
+}
+
+VkResult wine_vkCreateImage(VkDevice client_device, const VkImageCreateInfo *create_info,
+                            const VkAllocationCallbacks *allocator, VkImage *image)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    VkExternalMemoryImageCreateInfo external_memory_info, *update_info;
+    VkImageCreateInfo info = *create_info;
+
+    if ((update_info = find_next_struct(info.pNext, VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO)))
+    {
+        if (update_info->handleTypes & wine_vk_handle_over_fd_types)
+            update_info->handleTypes |= VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_FD_BIT_KHR;
+        wine_vk_normalize_handle_types_host(&update_info->handleTypes);
+    }
+    else if (physical_device->external_memory_align)
+    {
+        external_memory_info.sType = VK_STRUCTURE_TYPE_EXTERNAL_MEMORY_IMAGE_CREATE_INFO;
+        external_memory_info.pNext = info.pNext;
+        external_memory_info.handleTypes = VK_EXTERNAL_MEMORY_HANDLE_TYPE_HOST_ALLOCATION_BIT_EXT;
+        info.pNext = &external_memory_info;
+    }
+
+    return device->p_vkCreateImage(device->host.device, &info, NULL, image);
+}
+
+VkResult wine_vkCreateDebugUtilsMessengerEXT(VkInstance client_instance,
+                                             const VkDebugUtilsMessengerCreateInfoEXT *create_info,
+                                             const VkAllocationCallbacks *allocator,
+                                             VkDebugUtilsMessengerEXT *messenger)
+{
+    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
+    VkDebugUtilsMessengerCreateInfoEXT wine_create_info;
+    VkDebugUtilsMessengerEXT host_debug_messenger;
+    struct wine_debug_utils_messenger *object;
+    VkResult res;
+
+    if (allocator)
+        FIXME("Support for allocation callbacks not implemented yet\n");
+
+    if (!(object = calloc(1, sizeof(*object))))
+        return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+    wine_create_info = *create_info;
+    wine_create_info.pfnUserCallback = (void *) &debug_utils_callback_conversion;
+    wine_create_info.pUserData = object;
+
+    res = instance->p_vkCreateDebugUtilsMessengerEXT(instance->host.instance, &wine_create_info,
+                                                           NULL, &host_debug_messenger);
+    if (res != VK_SUCCESS)
+    {
+        free(object);
+        return res;
+    }
+
+    vulkan_object_init(&object->obj, host_debug_messenger);
+    object->instance = instance;
+    object->user_callback = (UINT_PTR)create_info->pfnUserCallback;
+    object->user_data = (UINT_PTR)create_info->pUserData;
+    vulkan_instance_insert_object(instance, &object->obj);
 
     *messenger = object->client.debug_messenger;
     return VK_SUCCESS;
 }
 
-void wine_vkDestroyDebugUtilsMessengerEXT(VkInstance client_instance, VkDebugUtilsMessengerEXT messenger,
-                                          const VkAllocationCallbacks *allocator)
+void wine_vkDestroyDebugUtilsMessengerEXT(VkInstance client_instance, VkDebugUtilsMessengerEXT messenger,
+                                          const VkAllocationCallbacks *allocator)
+{
+    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
+    struct wine_debug_utils_messenger *object;
+
+    object = wine_debug_utils_messenger_from_handle(messenger);
+
+    if (!object)
+        return;
+
+    instance->p_vkDestroyDebugUtilsMessengerEXT(instance->host.instance, object->host.debug_messenger, NULL);
+    vulkan_instance_remove_object(instance, &object->obj);
+
+    free(object);
+}
+
+VkResult wine_vkCreateDebugReportCallbackEXT(VkInstance client_instance,
+                                             const VkDebugReportCallbackCreateInfoEXT *create_info,
+                                             const VkAllocationCallbacks *allocator,
+                                             VkDebugReportCallbackEXT *callback)
+{
+    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
+    VkDebugReportCallbackCreateInfoEXT wine_create_info;
+    VkDebugReportCallbackEXT host_debug_callback;
+    struct wine_debug_report_callback *object;
+    VkResult res;
+
+    if (allocator)
+        FIXME("Support for allocation callbacks not implemented yet\n");
+
+    if (!(object = calloc(1, sizeof(*object))))
+        return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+    wine_create_info = *create_info;
+    wine_create_info.pfnCallback = (void *) debug_report_callback_conversion;
+    wine_create_info.pUserData = object;
+
+    res = instance->p_vkCreateDebugReportCallbackEXT(instance->host.instance, &wine_create_info,
+                                                           NULL, &host_debug_callback);
+    if (res != VK_SUCCESS)
+    {
+        free(object);
+        return res;
+    }
+
+    vulkan_object_init(&object->obj, host_debug_callback);
+    object->instance = instance;
+    object->user_callback = (UINT_PTR)create_info->pfnCallback;
+    object->user_data = (UINT_PTR)create_info->pUserData;
+    vulkan_instance_insert_object(instance, &object->obj);
+
+    *callback = object->client.debug_callback;
+    return VK_SUCCESS;
+}
+
+void wine_vkDestroyDebugReportCallbackEXT(VkInstance client_instance, VkDebugReportCallbackEXT callback,
+                                          const VkAllocationCallbacks *allocator)
+{
+    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
+    struct wine_debug_report_callback *object;
+
+    object = wine_debug_report_callback_from_handle(callback);
+
+    if (!object)
+        return;
+
+    instance->p_vkDestroyDebugReportCallbackEXT(instance->host.instance, object->host.debug_callback, NULL);
+    vulkan_instance_remove_object(instance, &object->obj);
+
+    free(object);
+}
+
+VkResult wine_vkCreateDeferredOperationKHR(VkDevice device_handle,
+                                           const VkAllocationCallbacks* allocator,
+                                           VkDeferredOperationKHR*      operation)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+    struct vulkan_instance *instance = device->physical_device->instance;
+    VkDeferredOperationKHR host_deferred_operation;
+    struct wine_deferred_operation *object;
+    VkResult res;
+
+    if (allocator)
+        FIXME("Support for allocation callbacks not implemented yet\n");
+
+    if (!(object = calloc(1, sizeof(*object))))
+        return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+    res = device->p_vkCreateDeferredOperationKHR(device->host.device, NULL, &host_deferred_operation);
+    if (res != VK_SUCCESS)
+    {
+        free(object);
+        return res;
+    }
+
+    vulkan_object_init(&object->obj, host_deferred_operation);
+    init_conversion_context(&object->ctx);
+    vulkan_instance_insert_object(instance, &object->obj);
+
+    *operation = object->client.deferred_operation;
+    return VK_SUCCESS;
+}
+
+void wine_vkDestroyDeferredOperationKHR(VkDevice device_handle,
+                                        VkDeferredOperationKHR       operation,
+                                        const VkAllocationCallbacks* allocator)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+    struct vulkan_instance *instance = device->physical_device->instance;
+    struct wine_deferred_operation *object;
+
+    object = wine_deferred_operation_from_handle(operation);
+
+    if (!object)
+        return;
+
+    device->p_vkDestroyDeferredOperationKHR(device->host.device, object->host.deferred_operation, NULL);
+    vulkan_instance_remove_object(instance, &object->obj);
+
+    free_conversion_context(&object->ctx);
+    free(object);
+}
+
+static void substitute_function_name(const char **name)
+{
+    if (!strcmp(*name, "vkGetMemoryWin32HandleKHR") || !strcmp(*name, "vkGetMemoryWin32HandlePropertiesKHR"))
+        *name = "vkGetMemoryFdKHR";
+    else if (!strcmp(*name, "vkGetSemaphoreWin32HandleKHR"))
+        *name = "vkGetSemaphoreFdKHR";
+    else if (!strcmp(*name, "vkImportSemaphoreWin32HandleKHR"))
+        *name = "vkImportSemaphoreFdKHR";
+    else if (!strcmp(*name, "wine_vkAcquireKeyedMutex") || !strcmp(*name, "wine_vkReleaseKeyedMutex"))
+        *name = "vkImportSemaphoreFdKHR";
+}
+
+#ifdef _WIN64
+
+NTSTATUS vk_is_available_instance_function(void *arg)
+{
+    struct is_available_instance_function_params *params = arg;
+    struct wine_instance *instance = wine_instance_from_handle(params->instance);
+    substitute_function_name(&params->name);
+
+    if (!strcmp(params->name, "vkCreateWin32SurfaceKHR"))
+        return instance->enable_win32_surface;
+    if (!strcmp(params->name, "vkGetPhysicalDeviceWin32PresentationSupportKHR"))
+        return instance->enable_win32_surface;
+
+    return !!vk_funcs->p_vkGetInstanceProcAddr(instance->obj.host.instance, params->name);
+}
+
+NTSTATUS vk_is_available_device_function(void *arg)
+{
+    struct is_available_device_function_params *params = arg;
+    struct vulkan_device *device = vulkan_device_from_handle(params->device);
+    substitute_function_name(&params->name);
+    return !!vk_funcs->p_vkGetDeviceProcAddr(device->host.device, params->name);
+}
+
+#endif /* _WIN64 */
+
+NTSTATUS vk_is_available_instance_function32(void *arg)
+{
+    struct
+    {
+        UINT32 instance;
+        UINT32 name;
+    } *params = arg;
+    struct wine_instance *instance = wine_instance_from_handle(UlongToPtr(params->instance));
+    const char *name = UlongToPtr(params->name);
+
+    if (!strcmp(UlongToPtr(params->name), "vkCreateWin32SurfaceKHR"))
+        return instance->enable_win32_surface;
+    if (!strcmp(UlongToPtr(params->name), "vkGetPhysicalDeviceWin32PresentationSupportKHR"))
+        return instance->enable_win32_surface;
+
+    substitute_function_name(&name);
+    return !!vk_funcs->p_vkGetInstanceProcAddr(instance->obj.host.instance, name);
+}
+
+NTSTATUS vk_is_available_device_function32(void *arg)
+{
+    struct
+    {
+        UINT32 device;
+        UINT32 name;
+    } *params = arg;
+    struct vulkan_device *device = vulkan_device_from_handle(UlongToPtr(params->device));
+    const char *name = UlongToPtr(params->name);
+    substitute_function_name(&name);
+    return !!vk_funcs->p_vkGetDeviceProcAddr(device->host.device, name);
+}
+
+VkResult wine_vkGetMemoryWin32HandleKHR(VkDevice device, const VkMemoryGetWin32HandleInfoKHR *handle_info, HANDLE *handle)
+{
+    struct wine_device_memory *dev_mem = wine_device_memory_from_handle(handle_info->memory);
+    const VkBaseInStructure *chain;
+    HANDLE ret;
+
+    TRACE("%p, %p %p\n", device, handle_info, handle);
+
+    if (!(dev_mem->handle_types & handle_info->handleType))
+        return VK_ERROR_UNKNOWN;
+
+    if ((chain = handle_info->pNext))
+        FIXME("Ignoring a linked structure of type %u.\n", chain->sType);
+
+    switch(handle_info->handleType)
+    {
+        case VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_BIT:
+        case VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_BIT:
+            return !NtDuplicateObject( NtCurrentProcess(), dev_mem->handle, NtCurrentProcess(), handle, dev_mem->access, dev_mem->inherit ? OBJ_INHERIT : 0, 0) ?
+                VK_SUCCESS : VK_ERROR_OUT_OF_HOST_MEMORY;
+        case VK_EXTERNAL_MEMORY_HANDLE_TYPE_OPAQUE_WIN32_KMT_BIT:
+        case VK_EXTERNAL_MEMORY_HANDLE_TYPE_D3D11_TEXTURE_KMT_BIT:
+        {
+            if ((ret = get_shared_resource_kmt_handle(dev_mem->handle)) == INVALID_HANDLE_VALUE)
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            *handle = ret;
+            return VK_SUCCESS;
+        }
+        default:
+            FIXME("Unable to get handle of type %x, did the application ignore the capabilities?\n", handle_info->handleType);
+            return VK_ERROR_UNKNOWN;
+    }
+}
+
+VkResult wine_vkGetMemoryWin32HandlePropertiesKHR(VkDevice device_handle, VkExternalMemoryHandleTypeFlagBits type, HANDLE handle, VkMemoryWin32HandlePropertiesKHR *properties)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+    struct wine_phys_dev *physical_device = CONTAINING_RECORD(device->physical_device, struct wine_phys_dev, obj);
+    unsigned int i;
+
+    TRACE("%p %u %p %p\n", device, type, handle, properties);
+
+    if (!(type & wine_vk_handle_over_fd_types))
+    {
+        FIXME("type %#x.\n", type);
+        return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+    }
+
+    properties->memoryTypeBits = 0;
+    for (i = 0; i < physical_device->memory_properties.memoryTypeCount; ++i)
+        if (physical_device->memory_properties.memoryTypes[i].propertyFlags == VK_MEMORY_PROPERTY_DEVICE_LOCAL_BIT)
+            properties->memoryTypeBits |= 1u << i;
+
+    return VK_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_SET_OBJECT           CTL_CODE(FILE_DEVICE_VIDEO, 6, METHOD_BUFFERED, FILE_WRITE_ACCESS)
+
+static bool set_shared_resource_object(HANDLE shared_resource, unsigned int index, HANDLE handle)
+{
+    IO_STATUS_BLOCK iosb;
+    struct shared_resource_set_object
+    {
+        unsigned int index;
+        obj_handle_t handle;
+    } params;
+
+    params.index = index;
+    params.handle = wine_server_obj_handle(handle);
+
+    return NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_SET_OBJECT,
+            &params, sizeof(params), NULL, 0) == STATUS_SUCCESS;
+}
+
+#define IOCTL_SHARED_GPU_RESOURCE_GET_OBJECT           CTL_CODE(FILE_DEVICE_VIDEO, 6, METHOD_BUFFERED, FILE_READ_ACCESS)
+
+static HANDLE get_shared_resource_object(HANDLE shared_resource, unsigned int index)
+{
+    IO_STATUS_BLOCK iosb;
+    obj_handle_t handle;
+
+    if (NtDeviceIoControlFile(shared_resource, NULL, NULL, NULL, &iosb, IOCTL_SHARED_GPU_RESOURCE_GET_OBJECT,
+            &index, sizeof(index), &handle, sizeof(handle)))
+        return NULL;
+
+    return wine_server_ptr_handle(handle);
+}
+
+static void d3d12_semaphore_lock(struct wine_semaphore *semaphore)
+{
+    assert( semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT );
+    pthread_mutex_lock(&semaphore->d3d12_fence_shm->mutex);
+}
+
+static void d3d12_semaphore_unlock(struct wine_semaphore *semaphore)
+{
+    assert( semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT );
+    pthread_mutex_unlock(&semaphore->d3d12_fence_shm->mutex);
+}
+
+static VkSemaphore create_timeline_semaphore(struct vulkan_device *device)
+{
+    VkSemaphoreTypeCreateInfo timeline_info = { 0 };
+    VkSemaphoreCreateInfo create_info = { 0 };
+    VkSemaphore sem = 0;
+    VkResult res;
+
+    timeline_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+    timeline_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+    create_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+    create_info.pNext = &timeline_info;
+
+    res = device->p_vkCreateSemaphore(device->host.device, &create_info, NULL, &sem);
+    if (res != VK_SUCCESS)
+        ERR("vkCreateSemaphore failed, res=%d\n", res);
+    return sem;
+}
+
+static void release_fence_op(struct vulkan_device *device, struct pending_d3d12_fence_op *op)
+{
+    list_remove(&op->entry);
+    vulkan_instance_remove_object(device->physical_device->instance, &op->semaphore->obj.obj);
+    vulkan_object_init(&op->semaphore->obj.obj, op->semaphore->semaphore);
+    vulkan_instance_insert_object(device->physical_device->instance, &op->semaphore->obj.obj);
+    op->semaphore = NULL;
+    list_add_head(&device->free_fence_ops_list, &op->entry);
+}
+
+static int wait_info_realloc(VkSemaphoreWaitInfo *wait_info, uint32_t *wait_alloc_count)
+{
+    VkSemaphore *new_sem;
+    uint64_t *new_values;
+
+    if (wait_info->semaphoreCount + 1 <= *wait_alloc_count)
+        return 1;
+    new_sem = realloc((void *)wait_info->pSemaphores, *wait_alloc_count * 2 * sizeof(*new_sem));
+    if (!new_sem)
+    {
+        fprintf(stderr, "err:winevulkan:wait_info_realloc no memory.\n");
+        return 0;
+    }
+    new_values = realloc((void *)wait_info->pValues, *wait_alloc_count * 2 * sizeof(*new_values));
+    if (!new_values)
+    {
+        fprintf(stderr, "err:winevulkan:wait_info_realloc no memory.\n");
+        return 0;
+    }
+    *wait_alloc_count *= 2;
+    wait_info->pSemaphores = new_sem;
+    wait_info->pValues = new_values;
+    return 1;
+}
+
+static int add_sem_wait(VkSemaphoreWaitInfo *wait_info, uint32_t *wait_alloc_count, VkSemaphore sem, uint64_t value)
+{
+    if (!wait_info_realloc(wait_info, wait_alloc_count))
+        return 0;
+    ((VkSemaphore *)wait_info->pSemaphores)[wait_info->semaphoreCount] = sem;
+    ((uint64_t *)wait_info->pValues)[wait_info->semaphoreCount] = value;
+    ++wait_info->semaphoreCount;
+    return 1;
+}
+
+static int semaphore_process(struct vulkan_device *device, struct wine_semaphore *sem,
+        VkSemaphoreWaitInfo *wait_info, uint32_t *wait_alloc_count)
+{
+    /* Called from native thread. */
+    struct pending_d3d12_fence_op *op, *op2;
+    uint64_t global_sem_wait_value;
+    int virtual_value_updated = 0;
+    uint64_t value, virtual_value;
+    VkResult res;
+    uint32_t i;
+
+    /* Check local pending signal ops completion, update shared semaphore. */
+    d3d12_semaphore_lock( sem );
+    virtual_value = sem->d3d12_fence_shm->virtual_value;
+    LIST_FOR_EACH_ENTRY_SAFE(op, op2, &sem->pending_signals, struct pending_d3d12_fence_op, entry)
+    {
+        res = get_semaphore_value(device, op->local_sem.sem, &value);
+        if (res != VK_SUCCESS)
+        {
+            fprintf(stderr, "err:winevulkan:semaphore_process vkGetSemaphoreCounterValue failed, res=%d.\n", res);
+            goto signal_op_complete;
+        }
+        if (value <= op->local_sem.value)
+        {
+            if (!add_sem_wait(wait_info, wait_alloc_count, op->local_sem.sem, op->local_sem.value + 1))
+            {
+                d3d12_semaphore_unlock(sem);
+                return 0;
+            }
+            continue;
+        }
+
+        virtual_value = max( sem->d3d12_fence_shm->virtual_value, op->virtual_value );
+        sem->d3d12_fence_shm->virtual_value = op->virtual_value;
+        virtual_value_updated = 1;
+signal_op_complete:
+        op->local_sem.value = value;
+        release_fence_op(device, op);
+    }
+
+    if (sem->d3d12_fence_shm->virtual_value < virtual_value)
+    {
+        uint32_t idx = sem->d3d12_fence_shm->reset_backlog_count;
+
+        if (debug_level >= 3)
+            fprintf(stderr, "warn:winevulkan:semaphore_process resetting semaphore %p virtual value.\n", sem);
+        if (idx == ARRAY_SIZE(sem->d3d12_fence_shm->reset_backlog))
+        {
+            sem->d3d12_fence_shm->last_dropped_reset_physical = sem->d3d12_fence_shm->reset_backlog[0].physical_at_reset;
+            --idx;
+            memmove(&sem->d3d12_fence_shm->reset_backlog[0], &sem->d3d12_fence_shm->reset_backlog[1],
+                    sizeof(*sem->d3d12_fence_shm->reset_backlog) * sem->d3d12_fence_shm->reset_backlog_count);
+        }
+        else
+        {
+            ++sem->d3d12_fence_shm->reset_backlog_count;
+        }
+        sem->d3d12_fence_shm->last_reset_physical = sem->d3d12_fence_shm->physical_value + 1;
+        sem->d3d12_fence_shm->reset_backlog[idx].physical_at_reset = sem->d3d12_fence_shm->last_reset_physical;
+        sem->d3d12_fence_shm->reset_backlog[idx].virtual_before_reset = virtual_value;
+    }
+    if (virtual_value_updated)
+        signal_timeline_sem(device, sem->fence_timeline_semaphore, &sem->d3d12_fence_shm->physical_value);
+    global_sem_wait_value = sem->d3d12_fence_shm->physical_value + 1;
+
+    /* Complete satisfied local waits. */
+    LIST_FOR_EACH_ENTRY_SAFE(op, op2, &sem->pending_waits, struct pending_d3d12_fence_op, entry)
+    {
+        if (op->virtual_value > virtual_value)
+        {
+            if (op->shared_physical_value > sem->d3d12_fence_shm->last_reset_physical)
+                continue;
+            for (i = 0; i < sem->d3d12_fence_shm->reset_backlog_count; ++i)
+            {
+                if (sem->d3d12_fence_shm->reset_backlog[i].physical_at_reset >= op->shared_physical_value
+                        && sem->d3d12_fence_shm->reset_backlog[i].virtual_before_reset >= op->virtual_value)
+                    break;
+            }
+            if (i == sem->d3d12_fence_shm->reset_backlog_count)
+            {
+                if (sem->d3d12_fence_shm->last_dropped_reset_physical < op->shared_physical_value)
+                    continue;
+                fprintf(stderr, "err:winevulkan:semaphore_process wait needs reset backlog beyond cut off.\n");
+            }
+        }
+
+        signal_timeline_sem(device, op->local_sem.sem, &op->local_sem.value);
+        release_fence_op(device, op);
+    }
+    d3d12_semaphore_unlock(sem);
+
+    /* Only poll shared semaphore if there are waits pending. */
+    if (list_empty(&sem->pending_waits))
+        return 1;
+    return add_sem_wait(wait_info, wait_alloc_count, sem->fence_timeline_semaphore, global_sem_wait_value);
+}
+
+#define SIGNALLER_INITIAL_WAIT_COUNT 256
+
+void *signaller_worker(void *arg)
+{
+#ifdef HAVE_SYS_SYSCALL_H
+    int unix_tid = syscall( __NR_gettid );
+#else
+    int unix_tid = -1;
+#endif
+    struct vulkan_device *device = arg;
+    struct wine_semaphore *sem;
+    VkSemaphoreWaitInfo wait_info = { 0 };
+    uint32_t wait_alloc_count = 0;
+    VkResult res;
+
+    if (debug_level)
+        fprintf(stderr, "[%d] msg:winevulkan:signaller_worker started.\n", unix_tid);
+
+    wait_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_WAIT_INFO;
+    wait_info.flags = VK_SEMAPHORE_WAIT_ANY_BIT;
+    wait_alloc_count = SIGNALLER_INITIAL_WAIT_COUNT;
+    if (!(wait_info.pSemaphores = malloc(sizeof(*wait_info.pSemaphores) * wait_alloc_count)))
+    {
+        fprintf(stderr, "err:winevulkan:signaller_worker no memory.\n");
+        return NULL;
+    }
+    if (!(wait_info.pValues = malloc(sizeof(*wait_info.pValues) * wait_alloc_count)))
+    {
+        fprintf(stderr, "err:winevulkan:signaller_worker no memory.\n");
+        free((void *)wait_info.pSemaphores);
+        return NULL;
+    }
+
+    for (;;)
+    {
+        pthread_mutex_lock(&device->signaller_mutex);
+        if (device->stop)
+        {
+            pthread_mutex_unlock(&device->signaller_mutex);
+            break;
+        }
+        wait_info.semaphoreCount = 1;
+        *(VkSemaphore *)wait_info.pSemaphores = device->sem_poll_update.sem;
+        *(uint64_t *)wait_info.pValues = device->sem_poll_update.value + 1;
+        LIST_FOR_EACH_ENTRY(sem, &device->sem_poll_list, struct wine_semaphore, poll_entry)
+        {
+            if (!semaphore_process(device, sem, &wait_info, &wait_alloc_count))
+            {
+                pthread_mutex_unlock(&device->signaller_mutex);
+                break;
+            }
+        }
+        device->sem_poll_update_value = device->sem_poll_update.value;
+        pthread_cond_signal(&device->sem_poll_updated_cond);
+        pthread_mutex_unlock(&device->signaller_mutex);
+        while ((res = wait_semaphores(device, &wait_info, 3000000000ull)) == VK_TIMEOUT)
+        {
+            if (wait_info.semaphoreCount > 1)
+                fprintf(stderr, "err:winevulkan:signaller_worker wait timed out with non-empty poll list.\n");
+        }
+        if (res != VK_SUCCESS)
+        {
+            fprintf(stderr, "err:winevulkan:signaller_worker error waiting for semaphores, vr %d.\n", res);
+            break;
+        }
+    }
+
+    free((void *)wait_info.pSemaphores);
+    free((void *)wait_info.pValues);
+    if (debug_level)
+        fprintf(stderr, "[%d] msg:winevulkan:signaller_worker exiting.\n", unix_tid);
+
+    return NULL;
+}
+
+static void register_sem_poll(struct vulkan_device *device, struct wine_semaphore *semaphore)
+{
+    pthread_mutex_lock(&device->signaller_mutex);
+    if (!device->signaller_thread)
+    {
+        device->sem_poll_update.sem = create_timeline_semaphore(device);
+        device->sem_poll_update.value = 0;
+        pthread_cond_init(&device->sem_poll_updated_cond, NULL);
+        if (TRACE_ON(vulkan))
+            debug_level = 4;
+        else if (WARN_ON(vulkan))
+            debug_level = 3;
+        else if (FIXME_ON(vulkan))
+            debug_level = 2;
+        else if (ERR_ON(vulkan))
+            debug_level = 1;
+        else
+            debug_level = 0;
+        if (pthread_create(&device->signaller_thread, NULL, signaller_worker, device))
+            ERR("Failed to create signaller_worker.\n");
+        WARN("d3d12 fence used, created signaller worker.\n");
+    }
+    assert(!semaphore->poll_entry.next);
+    list_add_head(&device->sem_poll_list, &semaphore->poll_entry);
+    signal_timeline_sem(device, device->sem_poll_update.sem, &device->sem_poll_update.value);
+    pthread_mutex_unlock(&device->signaller_mutex);
+}
+
+static void update_sem_poll_wait_processed(struct vulkan_device *device)
+{
+    uint64_t update_value;
+
+    signal_timeline_sem(device, device->sem_poll_update.sem, &device->sem_poll_update.value);
+    update_value = device->sem_poll_update.value;
+    while (device->sem_poll_update_value < update_value)
+        pthread_cond_wait(&device->sem_poll_updated_cond, &device->signaller_mutex);
+}
+
+static void unregister_sem_poll(struct vulkan_device *device, struct wine_semaphore *semaphore)
+{
+    struct list *entry;
+
+    pthread_mutex_lock(&device->signaller_mutex);
+    list_remove(&semaphore->poll_entry);
+    semaphore->poll_entry.next = semaphore->poll_entry.prev = NULL;
+    update_sem_poll_wait_processed(device);
+    pthread_mutex_unlock(&device->signaller_mutex);
+
+    while ((entry = list_head(&semaphore->pending_waits)))
+        release_fence_op(device, CONTAINING_RECORD(entry, struct pending_d3d12_fence_op, entry));
+    while ((entry = list_head(&semaphore->pending_signals)))
+        release_fence_op(device, CONTAINING_RECORD(entry, struct pending_d3d12_fence_op, entry));
+}
+
+static struct pending_d3d12_fence_op *get_free_fence_op(struct vulkan_device *device)
+{
+    struct pending_d3d12_fence_op *op;
+    struct list *entry;
+
+    if ((entry = list_head(&device->free_fence_ops_list)))
+    {
+        list_remove(entry);
+        return CONTAINING_RECORD(entry, struct pending_d3d12_fence_op, entry);
+    }
+
+    if (!(op = malloc(sizeof(*op))))
+    {
+        ERR("No memory.\n");
+        return NULL;
+    }
+    op->local_sem.sem = create_timeline_semaphore(device);
+    op->local_sem.value = 0;
+    ++device->allocated_fence_ops_count;
+    TRACE("Total allocated fence ops %u.\n", device->allocated_fence_ops_count);
+    return op;
+}
+
+static void add_sem_wait_op(struct vulkan_device *device, struct wine_semaphore *semaphore, uint64_t virtual_value,
+        VkSemaphore *phys_semaphore, uint64_t *phys_wait_value)
+{
+    struct pending_d3d12_fence_op *op;
+
+    pthread_mutex_lock(&device->signaller_mutex);
+    LIST_FOR_EACH_ENTRY(op, &semaphore->pending_waits, struct pending_d3d12_fence_op, entry)
+    {
+        if (op->virtual_value == virtual_value)
+        {
+            *phys_semaphore = op->local_sem.sem;
+            *phys_wait_value = op->local_sem.value + 1;
+            pthread_mutex_unlock(&device->signaller_mutex);
+            return;
+        }
+    }
+    if ((op = get_free_fence_op(device)))
+    {
+        op->virtual_value = virtual_value;
+        op->shared_physical_value = __atomic_load_n(&semaphore->d3d12_fence_shm->physical_value, __ATOMIC_ACQUIRE) + 1;
+        *phys_semaphore = op->local_sem.sem;
+        *phys_wait_value = op->local_sem.value + 1;
+        op->semaphore = semaphore;
+        list_add_tail(&semaphore->pending_waits, &op->entry);
+        vulkan_instance_remove_object(device->physical_device->instance, &semaphore->obj.obj);
+        vulkan_object_init(&semaphore->obj.obj, op->local_sem.sem);
+        vulkan_instance_insert_object(device->physical_device->instance, &semaphore->obj.obj);
+
+        signal_timeline_sem(device, device->sem_poll_update.sem, &device->sem_poll_update.value);
+        TRACE("added wait op, semaphore %p, %s, temp sem %s, %s.\n", semaphore, wine_dbgstr_longlong(virtual_value),
+                wine_dbgstr_longlong(op->local_sem.sem), wine_dbgstr_longlong(op->local_sem.value));
+    }
+    else
+    {
+        *phys_semaphore = 0;
+        *phys_wait_value = 0;
+    }
+    pthread_mutex_unlock(&device->signaller_mutex);
+}
+
+static void add_sem_signal_op(struct vulkan_device *device, struct wine_semaphore *semaphore, uint64_t virtual_value,
+        VkSemaphore *phys_semaphore, uint64_t *phys_signal_value, BOOL signal_immediate)
+{
+    struct pending_d3d12_fence_op *op;
+    UINT64 value;
+
+    pthread_mutex_lock(&device->signaller_mutex);
+    if ((op = get_free_fence_op(device)))
+    {
+        op->virtual_value = virtual_value;
+        *phys_semaphore = op->local_sem.sem;
+        *phys_signal_value = op->local_sem.value + 1;
+        op->semaphore = semaphore;
+        list_add_tail(&semaphore->pending_signals, &op->entry);
+        vulkan_instance_remove_object(device->physical_device->instance, &semaphore->obj.obj);
+        vulkan_object_init(&semaphore->obj.obj, op->local_sem.sem);
+        vulkan_instance_insert_object(device->physical_device->instance, &semaphore->obj.obj);
+
+        if (signal_immediate)
+        {
+            value = op->local_sem.value;
+            signal_timeline_sem(device, op->local_sem.sem, &value);
+            update_sem_poll_wait_processed(device);
+            TRACE("signal op %p, semaphore %p, %s, temp sem %s, %s.\n", op, semaphore, wine_dbgstr_longlong(virtual_value),
+                    wine_dbgstr_longlong(op->local_sem.sem), wine_dbgstr_longlong(op->local_sem.value));
+        }
+        else
+        {
+            signal_timeline_sem(device, device->sem_poll_update.sem, &device->sem_poll_update.value);
+            TRACE("added signal op, semaphore %p, %s, temp sem %s, %s.\n", semaphore, wine_dbgstr_longlong(virtual_value),
+                    wine_dbgstr_longlong(op->local_sem.sem), wine_dbgstr_longlong(op->local_sem.value));
+        }
+    }
+    else
+    {
+        *phys_semaphore = 0;
+        *phys_signal_value = 0;
+    }
+    pthread_mutex_unlock(&device->signaller_mutex);
+}
+
+VkResult wine_vkCreateSemaphore(VkDevice client_device, const VkSemaphoreCreateInfo *create_info,
+        const VkAllocationCallbacks *allocator, VkSemaphore *semaphore)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+
+    VkExportSemaphoreWin32HandleInfoKHR *export_handle_info = wine_vk_find_unlink_struct(create_info, EXPORT_SEMAPHORE_WIN32_HANDLE_INFO_KHR);
+    VkExportSemaphoreCreateInfo *export_semaphore_info, timeline_export_info;
+    VkSemaphoreCreateInfo create_info_dup = *create_info;
+    VkSemaphoreTypeCreateInfo *found_type_info, type_info;
+    VkSemaphoreGetFdInfoKHR fd_info;
+    pthread_mutexattr_t mutex_attr;
+    struct wine_semaphore *object;
+    OBJECT_ATTRIBUTES attr;
+    HANDLE section_handle;
+    LARGE_INTEGER li;
+    VkResult res;
+    SIZE_T size;
+    int fd;
+
+    TRACE("(%p, %p, %p, %p)\n", device, create_info, allocator, semaphore);
+
+    if (allocator)
+        FIXME("Support for allocation callbacks not implemented yet\n");
+
+    if (!(object = calloc(1, sizeof(*object))))
+        return VK_ERROR_OUT_OF_HOST_MEMORY;
+
+    list_init(&object->pending_signals);
+    list_init(&object->pending_waits);
+
+    object->handle = INVALID_HANDLE_VALUE;
+
+    if ((export_semaphore_info = find_next_struct(&create_info_dup, VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO)))
+    {
+        object->export_types = export_semaphore_info->handleTypes;
+        if (export_semaphore_info->handleTypes & VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT)
+            export_semaphore_info->handleTypes |= VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+        wine_vk_normalize_semaphore_handle_types_host(&export_semaphore_info->handleTypes);
+    }
+
+    if ((res = device->p_vkCreateSemaphore(device->host.device, &create_info_dup, NULL, &object->semaphore)) != VK_SUCCESS)
+        goto done;
+
+    if (export_semaphore_info && export_semaphore_info->handleTypes == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT)
+    {
+        fd_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR;
+        fd_info.pNext = NULL;
+        fd_info.semaphore = object->semaphore;
+        fd_info.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+        if ((res = device->p_vkGetSemaphoreFdKHR(device->host.device, &fd_info, &fd)) == VK_SUCCESS)
+        {
+            object->handle = create_gpu_resource(fd, export_handle_info ? export_handle_info->name : NULL, 0);
+            close(fd);
+        }
+
+        if (object->handle == INVALID_HANDLE_VALUE)
+        {
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+    }
+    else if (object->export_types & VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+    {
+        /* compatibleHandleTypes doesn't include any other types */
+        assert(object->export_types == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT);
+        object->handle_type = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT;
+
+        timeline_export_info.sType = VK_STRUCTURE_TYPE_EXPORT_SEMAPHORE_CREATE_INFO;
+        timeline_export_info.pNext = NULL;
+        timeline_export_info.handleTypes = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+        type_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+        type_info.pNext = &timeline_export_info;
+        type_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+        type_info.initialValue = 0;
+
+        create_info_dup.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+        create_info_dup.pNext = &type_info;
+        create_info_dup.flags = 0;
+
+        if ((res = device->p_vkCreateSemaphore(device->host.device, &create_info_dup, NULL, &object->fence_timeline_semaphore)) != VK_SUCCESS)
+            goto done;
+
+        fd_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_GET_FD_INFO_KHR;
+        fd_info.pNext = NULL;
+        fd_info.semaphore = object->fence_timeline_semaphore;
+        fd_info.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+
+        if ((res = device->p_vkGetSemaphoreFdKHR(device->host.device, &fd_info, &fd)) == VK_SUCCESS)
+        {
+            object->handle = create_gpu_resource(fd, export_handle_info ? export_handle_info->name : NULL, 0);
+            close(fd);
+        }
+
+        if (object->handle == INVALID_HANDLE_VALUE)
+        {
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+
+        /* Shared Fence Memory */
+        InitializeObjectAttributes(&attr, NULL, 0, NULL, NULL);
+        size = li.QuadPart = sizeof(*object->d3d12_fence_shm);
+        if (NtCreateSection(&section_handle, STANDARD_RIGHTS_REQUIRED | SECTION_QUERY | SECTION_MAP_READ | SECTION_MAP_WRITE, &attr, &li, PAGE_READWRITE, SEC_COMMIT, NULL))
+        {
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+
+        if (!set_shared_resource_object(object->handle, 0, section_handle))
+        {
+            NtClose(section_handle);
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+
+        if (NtMapViewOfSection(section_handle, GetCurrentProcess(), (void**) &object->d3d12_fence_shm, 0, 0, NULL, &size, ViewShare, 0, PAGE_READWRITE))
+        {
+            NtClose(section_handle);
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+
+        NtClose(section_handle);
+
+        if ((found_type_info = find_next_struct(create_info, VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO)))
+            object->d3d12_fence_shm->virtual_value = found_type_info->initialValue;
+
+        pthread_mutexattr_init(&mutex_attr);
+        pthread_mutexattr_setpshared(&mutex_attr, PTHREAD_PROCESS_SHARED);
+        if (pthread_mutex_init(&object->d3d12_fence_shm->mutex, &mutex_attr))
+        {
+            pthread_mutexattr_destroy(&mutex_attr);
+            res = VK_ERROR_OUT_OF_HOST_MEMORY;
+            goto done;
+        }
+        pthread_mutexattr_destroy(&mutex_attr);
+
+        vulkan_object_init(&object->obj.obj, object->fence_timeline_semaphore);
+        vulkan_instance_insert_object(device->physical_device->instance, &object->obj.obj);
+        object->obj.d3d12_fence = TRUE;
+    }
+    if (object->fence_timeline_semaphore == VK_NULL_HANDLE)
+    {
+        vulkan_object_init(&object->obj.obj, object->semaphore);
+        vulkan_instance_insert_object(device->physical_device->instance, &object->obj.obj);
+    }
+    *semaphore = object->obj.client.handle;
+
+    done:
+
+    if (res != VK_SUCCESS)
+    {
+        if (object->d3d12_fence_shm)
+        {
+            pthread_mutex_destroy(&object->d3d12_fence_shm->mutex);
+            NtUnmapViewOfSection(GetCurrentProcess(), object->d3d12_fence_shm);
+        }
+        if (object->handle != INVALID_HANDLE_VALUE)
+            NtClose(object->handle);
+        if (object->semaphore != VK_NULL_HANDLE)
+            device->p_vkDestroySemaphore(device->host.device, object->semaphore, NULL);
+        if (object->fence_timeline_semaphore != VK_NULL_HANDLE)
+            device->p_vkDestroySemaphore(device->host.device, object->fence_timeline_semaphore, NULL);
+        free(object);
+    }
+    else if (object->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+        register_sem_poll(device, object);
+    if (res == VK_SUCCESS)
+    {
+        TRACE("-> %p (native %#llx, shared %#llx).\n", object, (long long)object->semaphore, (long long)object->fence_timeline_semaphore);
+    }
+
+    return res;
+}
+
+VkResult wine_vkGetSemaphoreWin32HandleKHR(VkDevice client_device, const VkSemaphoreGetWin32HandleInfoKHR *handle_info,
+        HANDLE *handle)
+{
+    struct wine_semaphore *semaphore = wine_semaphore_from_handle(handle_info->semaphore);
+
+    if (!(semaphore->export_types & handle_info->handleType))
+        return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+
+    if (NtDuplicateObject( NtCurrentProcess(), semaphore->handle, NtCurrentProcess(), handle, 0, 0, DUPLICATE_SAME_ACCESS ))
+        return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+
+    return VK_SUCCESS;
+}
+
+void wine_vkDestroySemaphore(VkDevice client_device, VkSemaphore semaphore_handle, const VkAllocationCallbacks *allocator)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_semaphore *semaphore = wine_semaphore_from_handle(semaphore_handle);
+
+    TRACE("%p, %p, %p\n", device, semaphore, allocator);
+
+    if (allocator)
+        FIXME("Support for allocation callbacks not implemented yet\n");
+
+    if (!semaphore)
+        return;
+
+    if (semaphore->poll_entry.next)
+        unregister_sem_poll(device, semaphore);
+
+    if (semaphore->handle != INVALID_HANDLE_VALUE)
+        NtClose(semaphore->handle);
+
+    if (semaphore->d3d12_fence_shm)
+        NtUnmapViewOfSection(GetCurrentProcess(), semaphore->d3d12_fence_shm);
+
+    vulkan_instance_remove_object(device->physical_device->instance, &semaphore->obj.obj);
+    device->p_vkDestroySemaphore(device->host.device, semaphore->semaphore, NULL);
+
+    if (semaphore->fence_timeline_semaphore)
+        device->p_vkDestroySemaphore(device->host.device, semaphore->fence_timeline_semaphore, NULL);
+
+    free(semaphore);
+}
+
+VkResult wine_vkImportSemaphoreWin32HandleKHR(VkDevice client_device,
+        const VkImportSemaphoreWin32HandleInfoKHR *handle_info)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(client_device);
+    struct wine_semaphore *semaphore = wine_semaphore_from_handle(handle_info->semaphore);
+    struct wine_semaphore output_semaphore;
+    VkSemaphoreTypeCreateInfo type_info;
+    VkImportSemaphoreFdInfoKHR fd_info;
+    VkSemaphoreCreateInfo create_info;
+    HANDLE d3d12_fence_shm;
+    NTSTATUS stat;
+    VkResult res;
+    SIZE_T size;
+
+    TRACE("(%p, %p). semaphore = %p handle = %p\n", device, handle_info, semaphore, handle_info->handle);
+
+    if (semaphore->poll_entry.next)
+        unregister_sem_poll(device, semaphore);
+
+    if (handle_info->handleType == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT && !semaphore->fence_timeline_semaphore)
+    {
+        type_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_TYPE_CREATE_INFO;
+        type_info.pNext = NULL;
+        type_info.semaphoreType = VK_SEMAPHORE_TYPE_TIMELINE;
+        type_info.initialValue = 0;
+
+        create_info.sType = VK_STRUCTURE_TYPE_SEMAPHORE_CREATE_INFO;
+        create_info.pNext = &type_info;
+        create_info.flags = 0;
+
+        if ((res = device->p_vkCreateSemaphore(device->host.device, &create_info, NULL, &semaphore->fence_timeline_semaphore)) != VK_SUCCESS)
+        {
+            ERR("Failed to create timeline semaphore backing D3D12 semaphore. vr %d.\n", res);
+            return res;
+        };
+
+        vulkan_instance_remove_object(device->physical_device->instance, &semaphore->obj.obj);
+        vulkan_object_init(&semaphore->obj.obj, semaphore->fence_timeline_semaphore);
+        vulkan_instance_insert_object(device->physical_device->instance, &semaphore->obj.obj);
+        semaphore->obj.d3d12_fence = TRUE;
+    }
+
+    output_semaphore = *semaphore;
+    output_semaphore.handle = NULL;
+    output_semaphore.handle_type = handle_info->handleType;
+    output_semaphore.d3d12_fence_shm = NULL;
+
+    fd_info.sType = VK_STRUCTURE_TYPE_IMPORT_SEMAPHORE_FD_INFO_KHR;
+    fd_info.pNext = handle_info->pNext;
+    fd_info.semaphore = output_semaphore.obj.host.semaphore;
+    fd_info.flags = handle_info->flags;
+    fd_info.handleType = handle_info->handleType;
+
+    if (handle_info->handleType == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_WIN32_BIT ||
+        handle_info->handleType == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+    {
+        if (handle_info->name)
+        {
+            FIXME("Importing win32 semaphore by name not supported.\n");
+            return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+        }
+
+        if (NtDuplicateObject( NtCurrentProcess(), handle_info->handle, NtCurrentProcess(), &output_semaphore.handle, 0, 0, DUPLICATE_SAME_ACCESS ))
+            return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+
+        fd_info.handleType = VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_OPAQUE_FD_BIT;
+        if ((fd_info.fd = get_shared_resource_fd(output_semaphore.handle)) == -1)
+        {
+            WARN("Invalid handle %p.\n", handle_info->handle);
+            NtClose(output_semaphore.handle);
+            return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+        }
+
+        if (handle_info->handleType == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+        {
+            if (handle_info->flags & VK_SEMAPHORE_IMPORT_TEMPORARY_BIT)
+            {
+                FIXME("Temporarily importing d3d12 fences unsupported.\n");
+                close(fd_info.fd);
+                NtClose(output_semaphore.handle);
+                return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+            }
+
+            if (!(d3d12_fence_shm = get_shared_resource_object(output_semaphore.handle, 0)))
+            {
+                ERR("Failed to get D3D12 semaphore memory.\n");
+                close(fd_info.fd);
+                NtClose(output_semaphore.handle);
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            }
+
+            size = sizeof(*output_semaphore.d3d12_fence_shm);
+            if ((stat = NtMapViewOfSection(d3d12_fence_shm, GetCurrentProcess(), (void**) &output_semaphore.d3d12_fence_shm, 0, 0, NULL, &size, ViewShare, 0, PAGE_READWRITE)))
+            {
+                ERR("Failed to map D3D12 semaphore memory. stat %#x.\n", (int)stat);
+                close(fd_info.fd);
+                NtClose(d3d12_fence_shm);
+                NtClose(output_semaphore.handle);
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            }
+
+            NtClose(d3d12_fence_shm);
+        }
+    }
+
+    wine_vk_normalize_semaphore_handle_types_host(&fd_info.handleType);
+
+    if (!fd_info.handleType)
+    {
+        FIXME("Importing win32 semaphore with handle type %#x not supported.\n", handle_info->handleType);
+        return VK_ERROR_INVALID_EXTERNAL_HANDLE;
+    }
+
+    if ((res = device->p_vkImportSemaphoreFdKHR(device->host.device, &fd_info)) == VK_SUCCESS)
+    {
+        if (semaphore->handle)
+            NtClose(semaphore->handle);
+        if (semaphore->d3d12_fence_shm)
+            NtUnmapViewOfSection(GetCurrentProcess(), semaphore->d3d12_fence_shm);
+
+        *semaphore = output_semaphore;
+        assert(!semaphore->poll_entry.next);
+        if (semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+            register_sem_poll(device, semaphore);
+    }
+    else
+    {
+        if (output_semaphore.handle)
+            NtClose(output_semaphore.handle);
+        if (output_semaphore.d3d12_fence_shm)
+            NtUnmapViewOfSection(GetCurrentProcess(), output_semaphore.d3d12_fence_shm);
+
+        /* importing FDs transfers ownership, importing NT handles does not  */
+        close(fd_info.fd);
+    }
+
+    return res;
+}
+
+static VkResult wine_vk_get_semaphore_counter_value(VkDevice device_handle, VkSemaphore semaphore_handle, uint64_t *value, bool khr)
+{
+    struct wine_semaphore *semaphore = wine_semaphore_from_handle(semaphore_handle);
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+
+    if (semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+    {
+        d3d12_semaphore_lock(semaphore);
+        *value = semaphore->d3d12_fence_shm->virtual_value;
+        d3d12_semaphore_unlock(semaphore);
+        return VK_SUCCESS;
+    }
+
+    if (khr)
+        return device->p_vkGetSemaphoreCounterValueKHR(device->host.device, semaphore->obj.host.semaphore, value);
+    else
+        return device->p_vkGetSemaphoreCounterValue(device->host.device, semaphore->obj.host.semaphore, value);
+}
+
+VkResult wine_vkGetSemaphoreCounterValue(VkDevice device_handle, VkSemaphore semaphore_handle, uint64_t *value)
+{
+    return wine_vk_get_semaphore_counter_value(device_handle, semaphore_handle, value, false);
+}
+
+VkResult wine_vkGetSemaphoreCounterValueKHR(VkDevice device_handle, VkSemaphore semaphore_handle, uint64_t *value)
+{
+    return wine_vk_get_semaphore_counter_value(device_handle, semaphore_handle, value, true);
+}
+
+static NTSTATUS wine_vk_signal_semaphore(VkDevice device_handle, const VkSemaphoreSignalInfo *signal_info, bool khr)
+{
+    struct wine_semaphore *semaphore = wine_semaphore_from_handle(signal_info->semaphore);
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+    VkSemaphoreSignalInfo dup_signal_info = *signal_info;
+
+    TRACE("(%p, %p)\n", device, signal_info);
+
+    if (semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+    {
+        add_sem_signal_op(device, semaphore, signal_info->value, &dup_signal_info.semaphore, &dup_signal_info.value, TRUE);
+        return VK_SUCCESS;
+    }
+    else
+        dup_signal_info.semaphore = semaphore->obj.host.semaphore;
+
+    if (khr)
+        return device->p_vkSignalSemaphoreKHR(device->host.device, &dup_signal_info);
+    else
+        return device->p_vkSignalSemaphore(device->host.device, &dup_signal_info);
+}
+
+VkResult wine_vkSignalSemaphore(VkDevice device_handle, const VkSemaphoreSignalInfo *signal_info)
+{
+    return wine_vk_signal_semaphore(device_handle, signal_info, false);
+}
+
+VkResult wine_vkSignalSemaphoreKHR(VkDevice device_handle, const VkSemaphoreSignalInfo *signal_info)
+{
+    return wine_vk_signal_semaphore(device_handle, signal_info, true);
+}
+
+static void unwrap_semaphore(struct vulkan_device *device, VkSemaphore *sem_handle, uint64_t *value, BOOL signal)
+{
+    struct wine_semaphore *sem = wine_semaphore_from_handle(*sem_handle);
+
+    if (!sem)
+        return;
+
+    if (sem->handle_type != VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+    {
+        *sem_handle = sem->obj.host.semaphore;
+        return;
+    }
+    if (signal)
+        add_sem_signal_op(device, sem, *value, sem_handle, value, FALSE);
+    else
+        add_sem_wait_op(device, sem, *value, sem_handle, value);
+}
+
+static VkResult unwrap_semaphore_array(const VkSemaphore **sems, const uint64_t **values_out,
+        uint32_t count, struct conversion_context *ctx, BOOL signal, struct vulkan_device *device)
+{
+    const uint64_t *values = NULL;
+    const VkSemaphore *in;
+    VkSemaphore *out;
+    unsigned int i;
+
+    in = *sems;
+    *sems = NULL;
+
+    if (!in || !count)
+        return VK_SUCCESS;
+
+    out = conversion_context_alloc(ctx, count * sizeof(*out));
+    for (i = 0; i < count; ++i)
+    {
+        struct wine_semaphore *sem;
+        if (!in[i])
+        {
+            out[i] = VK_NULL_HANDLE;
+            continue;
+        }
+        sem = wine_semaphore_from_handle(in[i]);
+        if (sem->handle_type != VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+        {
+            out[i] = sem->obj.host.semaphore;
+            continue;
+        }
+        if (!values_out)
+        {
+            ERR("D3D12 fence without values specified.\n");
+            return VK_ERROR_UNKNOWN;
+        }
+        if (!values)
+        {
+            values = *values_out;
+            *values_out = conversion_context_alloc(ctx, count * sizeof(*values_out));
+            memcpy((void *)*values_out, values, count * sizeof(*values));
+        }
+        if (signal)
+            add_sem_signal_op(device, sem, values[i], &out[i], (uint64_t *)&(*values_out)[i], FALSE);
+        else
+            add_sem_wait_op(device, sem, values[i], &out[i], (uint64_t *)&(*values_out)[i]);
+    }
+    *sems = out;
+    return VK_SUCCESS;
+}
+
+static VkResult wine_vk_wait_semaphores(VkDevice device_handle, const VkSemaphoreWaitInfo *wait_info, uint64_t timeout, bool khr)
 {
-    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
-    struct wine_debug_utils_messenger *object;
+    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
+    VkSemaphoreWaitInfo wait_info_dup = *wait_info;
+    struct conversion_context ctx;
+    VkResult ret;
 
-    object = wine_debug_utils_messenger_from_handle(messenger);
+    init_conversion_context(&ctx);
+    if ((ret = unwrap_semaphore_array(&wait_info_dup.pSemaphores, &wait_info_dup.pValues,
+            wait_info->semaphoreCount, &ctx, FALSE, device)))
+        goto done;
 
-    if (!object)
-        return;
+    if (khr)
+        ret = device->p_vkWaitSemaphoresKHR(device->host.device, &wait_info_dup, timeout);
+    else
+        ret = device->p_vkWaitSemaphores(device->host.device, &wait_info_dup, timeout);
+done:
+    free_conversion_context(&ctx);
+    return ret;
+}
 
-    instance->p_vkDestroyDebugUtilsMessengerEXT(instance->host.instance, object->host.debug_messenger, NULL);
-    vulkan_instance_remove_object(instance, &object->obj);
+VkResult wine_vkWaitSemaphores(VkDevice device, const VkSemaphoreWaitInfo *wait_info, uint64_t timeout)
+{
+    TRACE("%p %p %s.\n", device, wait_info, wine_dbgstr_longlong(timeout));
 
-    free(object);
+    return wine_vk_wait_semaphores(device, wait_info, timeout, false);
 }
 
-VkResult wine_vkCreateDebugReportCallbackEXT(VkInstance client_instance,
-                                             const VkDebugReportCallbackCreateInfoEXT *create_info,
-                                             const VkAllocationCallbacks *allocator,
-                                             VkDebugReportCallbackEXT *callback)
+VkResult wine_vkWaitSemaphoresKHR(VkDevice device, const VkSemaphoreWaitInfo *wait_info, uint64_t timeout)
 {
-    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
-    VkDebugReportCallbackCreateInfoEXT wine_create_info;
-    VkDebugReportCallbackEXT host_debug_callback;
-    struct wine_debug_report_callback *object;
-    VkResult res;
+    TRACE("%p %p %s.\n", device, wait_info, wine_dbgstr_longlong(timeout));
 
-    if (allocator)
-        FIXME("Support for allocation callbacks not implemented yet\n");
+    return wine_vk_wait_semaphores(device, wait_info, timeout, true);
+}
 
-    if (!(object = calloc(1, sizeof(*object))))
-        return VK_ERROR_OUT_OF_HOST_MEMORY;
+struct struct_chain_def
+{
+    VkStructureType sType;
+    unsigned int size;
+};
 
-    wine_create_info = *create_info;
-    wine_create_info.pfnCallback = (void *) debug_report_callback_conversion;
-    wine_create_info.pUserData = object;
+static VkResult process_keyed_mutexes(struct conversion_context *ctx, struct vulkan_device *device,
+        uint32_t submit_count, const void *submits_win, size_t submit_size, uint32_t **signal_counts,
+        VkSemaphoreSubmitInfo ***signal_infos)
+{
+    VkWin32KeyedMutexAcquireReleaseInfoKHR *keyed_mutex_info;
+    struct wine_device_memory *memory;
+    VkResult ret = VK_ERROR_UNKNOWN;
+    uint32_t i, j, signal_count = 0;
+    void *ptr;
 
-    res = instance->p_vkCreateDebugReportCallbackEXT(instance->host.instance, &wine_create_info,
-                                                           NULL, &host_debug_callback);
-    if (res != VK_SUCCESS)
+    for (i = 0; i < submit_count; ++i)
     {
-        free(object);
-        return res;
+        ptr = (char *)submits_win + i * submit_size;
+        if (!(keyed_mutex_info = find_next_struct(ptr, VK_STRUCTURE_TYPE_WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR)))
+            continue;
+        for (j = 0; j < keyed_mutex_info->acquireCount; ++j)
+        {
+            memory = wine_device_memory_from_handle(keyed_mutex_info->pAcquireSyncs[j]);
+            if ((ret = acquire_keyed_mutex(device, memory, keyed_mutex_info->pAcquireKeys[j],
+                    keyed_mutex_info->pAcquireTimeouts[j])) == VK_SUCCESS)
+                continue;
+            while (j)
+            {
+                --j;
+                memory = wine_device_memory_from_handle(keyed_mutex_info->pAcquireSyncs[j]);
+                release_keyed_mutex(device, memory, keyed_mutex_info->pAcquireKeys[j], NULL);
+            }
+            goto error;
+        }
+        /* Pre-check release error conditions. */
+        for (j = 0; j < keyed_mutex_info->releaseCount; ++j)
+        {
+            memory = wine_device_memory_from_handle(keyed_mutex_info->pReleaseSyncs[j]);
+            if (!memory->keyed_mutex_shm)
+                goto error;
+            if (memory->keyed_mutex_shm->acquired_to_instance != memory->keyed_mutex_instance_id)
+                goto error;
+        }
+        signal_count += keyed_mutex_info->releaseCount;
     }
 
-    vulkan_object_init(&object->obj, host_debug_callback);
-    object->instance = instance;
-    object->user_callback = (UINT_PTR)create_info->pfnCallback;
-    object->user_data = (UINT_PTR)create_info->pUserData;
-    vulkan_instance_insert_object(instance, &object->obj);
+    if (!signal_count)
+    {
+        *signal_counts = NULL;
+        return VK_SUCCESS;
+    }
+    *signal_counts = conversion_context_alloc(ctx, sizeof(**signal_counts) * submit_count);
+    *signal_infos = conversion_context_alloc(ctx, sizeof(**signal_infos) * submit_count);
+    for (i = 0; i < submit_count; ++i)
+    {
+        ptr = (char *)submits_win + i * submit_size;
+        if (!(keyed_mutex_info = wine_vk_find_unlink_struct(ptr, WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR)))
+        {
+            (*signal_counts)[i] = 0;
+            continue;
+        }
+        (*signal_counts)[i] = keyed_mutex_info->releaseCount;
+        (*signal_infos)[i] = conversion_context_alloc(ctx, sizeof(***signal_infos) * keyed_mutex_info->releaseCount);
+        for (j = 0; j < keyed_mutex_info->releaseCount; ++j)
+        {
+            memory = wine_device_memory_from_handle(keyed_mutex_info->pReleaseSyncs[j]);
+            (*signal_infos)[i][j].sType = VK_STRUCTURE_TYPE_SEMAPHORE_SUBMIT_INFO;
+            (*signal_infos)[i][j].pNext = NULL;
+            (*signal_infos)[i][j].semaphore = memory->keyed_mutex_sem;
+            (*signal_infos)[i][j].stageMask = VK_PIPELINE_STAGE_ALL_COMMANDS_BIT;
+            (*signal_infos)[i][j].deviceIndex = 0;
+            ret = release_keyed_mutex(device, memory, keyed_mutex_info->pReleaseKeys[j], &(*signal_infos)[i][j].value);
+            if (ret != VK_SUCCESS)
+            {
+                /* This should only be possible if a racing submit queued release before us, currently not handled. */
+                ERR("release_keyed_mutex failed, ret %d.\n", ret);
+                (*signal_infos)[i][j].value = 0;
+            }
+        }
+    }
 
-    *callback = object->client.debug_callback;
     return VK_SUCCESS;
+
+error:
+    while (i)
+    {
+        --i;
+        ptr = (char *)submits_win + i * submit_size;
+        if (!(keyed_mutex_info = wine_vk_find_unlink_struct(ptr, WIN32_KEYED_MUTEX_ACQUIRE_RELEASE_INFO_KHR)))
+            continue;
+        for (j = 0; j < keyed_mutex_info->acquireCount; ++j)
+        {
+            memory = wine_device_memory_from_handle(keyed_mutex_info->pAcquireSyncs[j]);
+            release_keyed_mutex(device, memory, keyed_mutex_info->pAcquireKeys[j], NULL);
+        }
+    }
+    return ret;
 }
 
-void wine_vkDestroyDebugReportCallbackEXT(VkInstance client_instance, VkDebugReportCallbackEXT callback,
-                                          const VkAllocationCallbacks *allocator)
+static void duplicate_array_for_unwrapping_copy_size(struct conversion_context *ctx, void **ptr, unsigned int size,
+        unsigned int copy_size)
 {
-    struct vulkan_instance *instance = vulkan_instance_from_handle(client_instance);
-    struct wine_debug_report_callback *object;
+    void *out;
 
-    object = wine_debug_report_callback_from_handle(callback);
-
-    if (!object)
+    if (!size)
         return;
 
-    instance->p_vkDestroyDebugReportCallbackEXT(instance->host.instance, object->host.debug_callback, NULL);
-    vulkan_instance_remove_object(instance, &object->obj);
+    out = conversion_context_alloc(ctx, size);
+    if (*ptr)
+        memcpy(out, *ptr, copy_size);
+    *ptr = out;
+}
 
-    free(object);
+VkResult wine_vkQueueSubmit(VkQueue queue_handle, uint32_t submit_count, const VkSubmitInfo *submits_orig, VkFence fence)
+{
+    struct vulkan_queue *queue = vulkan_queue_from_handle(queue_handle);
+    struct vulkan_device *device = queue->device;
+    VkTimelineSemaphoreSubmitInfo *timeline_submit_info, ts_info_copy;
+    VkD3D12FenceSubmitInfoKHR *d3d12_submit_info;
+    const uint64_t **values;
+    struct conversion_context ctx;
+    VkSubmitInfo *submits;
+    VkSemaphoreSubmitInfo **km_infos;
+    uint32_t *km_counts;
+    unsigned int i, j;
+    VkResult ret;
+
+    TRACE("(%p %u %p 0x%s)\n", queue_handle, submit_count, submits_orig, wine_dbgstr_longlong(fence));
+
+    init_conversion_context(&ctx);
+    MEMDUP(&ctx, submits, submits_orig, submit_count);
+    if ((ret = process_keyed_mutexes(&ctx, device, submit_count, submits, sizeof(*submits), &km_counts, &km_infos)))
+        return ret;
+
+    for (i = 0; i < submit_count; ++i)
+    {
+        timeline_submit_info = find_next_struct(&submits[i], VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO);
+        d3d12_submit_info = wine_vk_find_unlink_struct(&submits[i], D3D12_FENCE_SUBMIT_INFO_KHR);
+        if (d3d12_submit_info && timeline_submit_info)
+            WARN("Both TIMELINE_SEMAPHORE_SUBMIT_INFO and D3D12_FENCE_SUBMIT_INFO_KHR specified.\n");
+        if (d3d12_submit_info && !timeline_submit_info)
+        {
+            timeline_submit_info = conversion_context_alloc(&ctx, sizeof(*timeline_submit_info));
+            timeline_submit_info->sType = VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO;
+            timeline_submit_info->pNext = submits[i].pNext;
+            timeline_submit_info->waitSemaphoreValueCount = d3d12_submit_info->waitSemaphoreValuesCount;
+            MEMDUP(&ctx, timeline_submit_info->pWaitSemaphoreValues, d3d12_submit_info->pWaitSemaphoreValues, d3d12_submit_info->waitSemaphoreValuesCount);
+            timeline_submit_info->signalSemaphoreValueCount = d3d12_submit_info->signalSemaphoreValuesCount;
+            MEMDUP(&ctx, timeline_submit_info->pSignalSemaphoreValues, d3d12_submit_info->pSignalSemaphoreValues, d3d12_submit_info->signalSemaphoreValuesCount);
+            submits[i].pNext = timeline_submit_info;
+        }
+
+        if (timeline_submit_info)
+            values = &timeline_submit_info->pWaitSemaphoreValues;
+        else
+            values = NULL;
+        unwrap_semaphore_array(&submits[i].pWaitSemaphores, values, submits[i].waitSemaphoreCount, &ctx, FALSE, device);
+
+        if (timeline_submit_info)
+            values = &timeline_submit_info->pSignalSemaphoreValues;
+        else
+            values = NULL;
+        unwrap_semaphore_array(&submits[i].pSignalSemaphores, values, submits[i].signalSemaphoreCount, &ctx, TRUE, device);
+        if (km_counts && km_counts[i])
+        {
+            if (timeline_submit_info)
+            {
+                ts_info_copy = *timeline_submit_info;
+                timeline_submit_info = &ts_info_copy;
+                duplicate_array_for_unwrapping_copy_size(&ctx, (void **)&timeline_submit_info->pSignalSemaphoreValues,
+                        (timeline_submit_info->signalSemaphoreValueCount + km_counts[i]) * sizeof(*timeline_submit_info->pSignalSemaphoreValues),
+                        timeline_submit_info->signalSemaphoreValueCount * sizeof(*timeline_submit_info->pSignalSemaphoreValues));
+            }
+            else
+            {
+                timeline_submit_info = &ts_info_copy;
+                timeline_submit_info->sType = VK_STRUCTURE_TYPE_TIMELINE_SEMAPHORE_SUBMIT_INFO;
+                timeline_submit_info->pNext = submits[i].pNext;
+                timeline_submit_info->waitSemaphoreValueCount = 0;
+                timeline_submit_info->signalSemaphoreValueCount = 0;
+                timeline_submit_info->pSignalSemaphoreValues = conversion_context_alloc(&ctx, km_counts[i] * sizeof(*timeline_submit_info->pSignalSemaphoreValues));
+                submits[i].pNext = timeline_submit_info;
+            }
+            duplicate_array_for_unwrapping_copy_size(&ctx, (void **)&submits[i].pSignalSemaphores,
+                    (submits[i].signalSemaphoreCount + km_counts[i]) * sizeof(*submits[i].pSignalSemaphores),
+                    submits[i].signalSemaphoreCount * sizeof(*submits[i].pSignalSemaphores));
+            for (j = 0; j < km_counts[i]; ++j)
+            {
+                ((uint64_t *)timeline_submit_info->pSignalSemaphoreValues)[j + timeline_submit_info->signalSemaphoreValueCount++]
+                        = km_infos[i][j].value;
+                ((VkSemaphore *)submits[i].pSignalSemaphores)[j + submits[i].signalSemaphoreCount++] = km_infos[i][j].semaphore;
+            }
+        }
+
+        if (submits[i].pCommandBuffers && submits[i].commandBufferCount)
+        {
+            VkCommandBuffer *out;
+
+            out = conversion_context_alloc(&ctx, submits[i].commandBufferCount * sizeof(*out));
+            for (j = 0; j < submits[i].commandBufferCount; ++j)
+                out[j] = wine_cmd_buffer_from_handle(submits[i].pCommandBuffers[j])->host.command_buffer;
+            submits[i].pCommandBuffers = out;
+        }
+    }
+    ret = queue->device->p_vkQueueSubmit(queue->host.queue, submit_count, submits, fence);
+    free_conversion_context(&ctx);
+    return ret;
 }
 
-VkResult wine_vkCreateDeferredOperationKHR(VkDevice device_handle,
-                                           const VkAllocationCallbacks* allocator,
-                                           VkDeferredOperationKHR*      operation)
+static void duplicate_array_for_unwrapping(struct conversion_context *ctx, void **ptr, unsigned int size)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
-    struct vulkan_instance *instance = device->physical_device->instance;
-    VkDeferredOperationKHR host_deferred_operation;
-    struct wine_deferred_operation *object;
-    VkResult res;
+    duplicate_array_for_unwrapping_copy_size(ctx, ptr, size, size);
+}
 
-    if (allocator)
-        FIXME("Support for allocation callbacks not implemented yet\n");
+static VkResult vk_queue_submit_2(VkQueue queue_handle, uint32_t submit_count, const VkSubmitInfo2 *submits_orig,
+        VkFence fence, bool khr)
+{
+    struct vulkan_queue *queue = vulkan_queue_from_handle(queue_handle);
+    struct vulkan_device *device = queue->device;
+    struct conversion_context ctx;
+    VkSemaphoreSubmitInfo **km_infos;
+    uint32_t *km_counts, count;
+    VkSubmitInfo2 *submits;
+    unsigned int i, j;
+    VkResult ret;
 
-    if (!(object = calloc(1, sizeof(*object))))
-        return VK_ERROR_OUT_OF_HOST_MEMORY;
+    TRACE("(%p, %u, %p, %s)\n", queue_handle, submit_count, submits_orig, wine_dbgstr_longlong(fence));
 
-    res = device->p_vkCreateDeferredOperationKHR(device->host.device, NULL, &host_deferred_operation);
-    if (res != VK_SUCCESS)
+    init_conversion_context(&ctx);
+    MEMDUP(&ctx, submits, submits_orig, submit_count);
+    if ((ret = process_keyed_mutexes(&ctx, device, submit_count, submits, sizeof(*submits), &km_counts, &km_infos)))
+        return ret;
+    for (i = 0; i < submit_count; ++i)
     {
-        free(object);
-        return res;
+        duplicate_array_for_unwrapping(&ctx, (void **)&submits[i].pWaitSemaphoreInfos,
+                submits[i].waitSemaphoreInfoCount * sizeof(*submits[i].pWaitSemaphoreInfos));
+        for (j = 0; j < submits[i].waitSemaphoreInfoCount; ++j)
+            unwrap_semaphore(queue->device, &((VkSemaphoreSubmitInfo *)submits[i].pWaitSemaphoreInfos)[j].semaphore,
+                    &((VkSemaphoreSubmitInfo *)submits[i].pWaitSemaphoreInfos)[j].value, FALSE);
+
+        count = submits[i].signalSemaphoreInfoCount + (km_counts ? km_counts[i] : 0);
+        duplicate_array_for_unwrapping_copy_size(&ctx, (void **)&submits[i].pSignalSemaphoreInfos,
+                count * sizeof(*submits[i].pSignalSemaphoreInfos),
+                submits[i].signalSemaphoreInfoCount * sizeof(*submits[i].pSignalSemaphoreInfos));
+        for (j = 0; j < submits[i].signalSemaphoreInfoCount; ++j)
+            unwrap_semaphore(queue->device, &((VkSemaphoreSubmitInfo *)submits[i].pSignalSemaphoreInfos)[j].semaphore,
+                    &((VkSemaphoreSubmitInfo *)submits[i].pSignalSemaphoreInfos)[j].value, TRUE);
+        for (; j < count; ++j)
+            ((VkSemaphoreSubmitInfo *)submits[i].pSignalSemaphoreInfos)[j] = km_infos[i][j - submits[i].signalSemaphoreInfoCount];
+        submits[i].signalSemaphoreInfoCount = count;
+
+        if (submits[i].pCommandBufferInfos && submits[i].commandBufferInfoCount)
+        {
+            duplicate_array_for_unwrapping(&ctx, (void **)&submits[i].pCommandBufferInfos,
+                    submits[i].commandBufferInfoCount * sizeof(*submits[i].pCommandBufferInfos));
+            for (j = 0; j < submits[i].commandBufferInfoCount; ++j)
+                ((VkCommandBufferSubmitInfo *)submits[i].pCommandBufferInfos)[j].commandBuffer
+                        = wine_cmd_buffer_from_handle(submits[i].pCommandBufferInfos[j].commandBuffer)->host.command_buffer;
+        }
     }
 
-    vulkan_object_init(&object->obj, host_deferred_operation);
-    init_conversion_context(&object->ctx);
-    vulkan_instance_insert_object(instance, &object->obj);
+    if (khr)
+        ret = queue->device->p_vkQueueSubmit2KHR(queue->host.queue, submit_count, submits, fence);
+    else
+        ret = queue->device->p_vkQueueSubmit2(queue->host.queue, submit_count, submits, fence);
+    free_conversion_context(&ctx);
+    return ret;
+}
 
-    *operation = object->client.deferred_operation;
-    return VK_SUCCESS;
+VkResult wine_vkQueueSubmit2(VkQueue queue, uint32_t submit_count, const VkSubmitInfo2 *submits, VkFence fence)
+{
+    return vk_queue_submit_2(queue, submit_count, submits, fence, false);
 }
 
-void wine_vkDestroyDeferredOperationKHR(VkDevice device_handle,
-                                        VkDeferredOperationKHR       operation,
-                                        const VkAllocationCallbacks* allocator)
+VkResult wine_vkQueueSubmit2KHR(VkQueue queue, uint32_t submit_count, const VkSubmitInfo2 *submits, VkFence fence)
 {
-    struct vulkan_device *device = vulkan_device_from_handle(device_handle);
-    struct vulkan_instance *instance = device->physical_device->instance;
-    struct wine_deferred_operation *object;
+    return vk_queue_submit_2(queue, submit_count, submits, fence, true);
+}
 
-    object = wine_deferred_operation_from_handle(operation);
+VkResult wine_vkQueueBindSparse(VkQueue queue_handle, uint32_t bind_info_count, const VkBindSparseInfo *bind_info, VkFence fence)
+{
+    struct vulkan_queue *queue = vulkan_queue_from_handle(queue_handle);
+    struct wine_semaphore *semaphore;
+    struct conversion_context ctx;
+    VkBindSparseInfo *batch;
+    unsigned int i, j, k;
+    VkResult ret;
 
-    if (!object)
-        return;
+    TRACE("(%p, %u, %p, 0x%s)\n", queue, bind_info_count, bind_info, wine_dbgstr_longlong(fence));
 
-    device->p_vkDestroyDeferredOperationKHR(device->host.device, object->host.deferred_operation, NULL);
-    vulkan_instance_remove_object(instance, &object->obj);
+    for (i = 0; i < bind_info_count; i++)
+    {
+        batch = (VkBindSparseInfo *)&bind_info[i];
 
-    free_conversion_context(&object->ctx);
-    free(object);
+        for (k = 0; k < batch->waitSemaphoreCount; k++)
+        {
+            semaphore = wine_semaphore_from_handle(batch->pWaitSemaphores[k]);
+
+            if (semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+            {
+                FIXME("Waiting on D3D12-Fence compatible timeline semaphore not supported.\n");
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            }
+        }
+
+        for(k = 0; k < batch->signalSemaphoreCount; k++)
+        {
+            semaphore = wine_semaphore_from_handle(batch->pSignalSemaphores[k]);
+
+            if (semaphore->handle_type == VK_EXTERNAL_SEMAPHORE_HANDLE_TYPE_D3D12_FENCE_BIT)
+            {
+                FIXME("Signalling D3D12-Fence compatible timeline semaphore not supported.\n");
+                return VK_ERROR_OUT_OF_HOST_MEMORY;
+            }
+        }
+    }
+
+    init_conversion_context(&ctx);
+    for (i = 0; i < bind_info_count; ++i)
+    {
+        batch = (VkBindSparseInfo *)&bind_info[i];
+        unwrap_semaphore_array(&batch->pWaitSemaphores, NULL, batch->waitSemaphoreCount, &ctx, FALSE, queue->device);
+        unwrap_semaphore_array(&batch->pSignalSemaphores, NULL, batch->signalSemaphoreCount, &ctx, TRUE, queue->device);
+
+        duplicate_array_for_unwrapping(&ctx, (void **)&batch->pBufferBinds, batch->bufferBindCount * sizeof(*batch->pBufferBinds));
+        for (j = 0; j < batch->bufferBindCount; ++j)
+        {
+            VkSparseBufferMemoryBindInfo *bind = (VkSparseBufferMemoryBindInfo *)&batch->pBufferBinds[j];
+            duplicate_array_for_unwrapping(&ctx, (void **)&bind->pBinds, bind->bindCount * sizeof(*bind->pBinds));
+            for (k = 0; k < bind->bindCount; ++k)
+                if (bind->pBinds[k].memory)
+                    ((VkSparseMemoryBind *)bind->pBinds)[k].memory = wine_device_memory_from_handle(bind->pBinds[k].memory)->host.device_memory;
+        }
+
+        duplicate_array_for_unwrapping(&ctx, (void **)&batch->pImageOpaqueBinds, batch->imageOpaqueBindCount * sizeof(*batch->pImageOpaqueBinds));
+        for (j = 0; j < batch->imageOpaqueBindCount; ++j)
+        {
+            VkSparseImageOpaqueMemoryBindInfo *bind = (VkSparseImageOpaqueMemoryBindInfo *)&batch->pImageOpaqueBinds[j];
+            duplicate_array_for_unwrapping(&ctx, (void **)&bind->pBinds, bind->bindCount * sizeof(*bind->pBinds));
+            for (k = 0; k < bind->bindCount; ++k)
+                if (bind->pBinds[k].memory)
+                    ((VkSparseMemoryBind *)bind->pBinds)[k].memory = wine_device_memory_from_handle(bind->pBinds[k].memory)->host.device_memory;
+        }
+
+        duplicate_array_for_unwrapping(&ctx, (void **)&batch->pImageBinds, batch->imageBindCount * sizeof(*batch->pImageBinds));
+        for (j = 0; j < batch->imageBindCount; ++j)
+        {
+            VkSparseImageMemoryBindInfo *bind = (VkSparseImageMemoryBindInfo *)&batch->pImageBinds[j];
+            duplicate_array_for_unwrapping(&ctx, (void **)&bind->pBinds, bind->bindCount * sizeof(*bind->pBinds));
+            for (k = 0; k < bind->bindCount; ++k)
+                if (bind->pBinds[k].memory)
+                    ((VkSparseImageMemoryBind *)bind->pBinds)[k].memory = wine_device_memory_from_handle(bind->pBinds[k].memory)->host.device_memory;
+        }
+    }
+    ret = queue->device->p_vkQueueBindSparse(queue->host.queue, bind_info_count, bind_info, fence);
+    free_conversion_context(&ctx);
+    return ret;
 }
 
-#ifdef _WIN64
+VkResult wine_wine_vkAcquireKeyedMutex(VkDevice device, VkDeviceMemory memory, uint64_t key, uint32_t timeout_ms)
+{
+    return acquire_keyed_mutex(vulkan_device_from_handle(device), wine_device_memory_from_handle(memory), key, timeout_ms);
+}
 
-NTSTATUS vk_is_available_instance_function(void *arg)
+VkResult wine_wine_vkReleaseKeyedMutex(VkDevice device, VkDeviceMemory memory, uint64_t key)
 {
-    struct is_available_instance_function_params *params = arg;
-    struct wine_instance *instance = wine_instance_from_handle(params->instance);
+    return release_keyed_mutex(vulkan_device_from_handle(device), wine_device_memory_from_handle(memory), key, NULL);
+}
 
-    if (!strcmp(params->name, "vkCreateWin32SurfaceKHR"))
-        return instance->enable_win32_surface;
-    if (!strcmp(params->name, "vkGetPhysicalDeviceWin32PresentationSupportKHR"))
-        return instance->enable_win32_surface;
+DECLSPEC_EXPORT VkDevice __wine_get_native_VkDevice(VkDevice handle)
+{
+    struct vulkan_device *device = vulkan_device_from_handle(handle);
 
-    return !!vk_funcs->p_vkGetInstanceProcAddr(instance->obj.host.instance, params->name);
+    return device->host.device;
 }
 
-NTSTATUS vk_is_available_device_function(void *arg)
+DECLSPEC_EXPORT VkInstance __wine_get_native_VkInstance(VkInstance handle)
 {
-    struct is_available_device_function_params *params = arg;
-    struct vulkan_device *device = vulkan_device_from_handle(params->device);
-    return !!vk_funcs->p_vkGetDeviceProcAddr(device->host.device, params->name);
-}
+    struct vulkan_instance *instance = vulkan_instance_from_handle(handle);
 
-#endif /* _WIN64 */
+    return instance->host.instance;
+}
 
-NTSTATUS vk_is_available_instance_function32(void *arg)
+DECLSPEC_EXPORT VkPhysicalDevice __wine_get_native_VkPhysicalDevice(VkPhysicalDevice handle)
 {
-    struct
-    {
-        UINT32 instance;
-        UINT32 name;
-    } *params = arg;
-    struct wine_instance *instance = wine_instance_from_handle(UlongToPtr(params->instance));
+    struct vulkan_physical_device *phys_dev;
 
-    if (!strcmp(UlongToPtr(params->name), "vkCreateWin32SurfaceKHR"))
-        return instance->enable_win32_surface;
-    if (!strcmp(UlongToPtr(params->name), "vkGetPhysicalDeviceWin32PresentationSupportKHR"))
-        return instance->enable_win32_surface;
+    if (!handle) return NULL;
 
-    return !!vk_funcs->p_vkGetInstanceProcAddr(instance->obj.host.instance, UlongToPtr(params->name));
+    phys_dev = vulkan_physical_device_from_handle(handle);
+    return phys_dev->host.physical_device;
 }
 
-NTSTATUS vk_is_available_device_function32(void *arg)
+DECLSPEC_EXPORT VkQueue __wine_get_native_VkQueue(VkQueue handle)
 {
-    struct
+    struct vulkan_queue *queue = vulkan_queue_from_handle(handle);
+
+    return queue->host.queue;
+}
+
+DECLSPEC_EXPORT VkPhysicalDevice __wine_get_wrapped_VkPhysicalDevice(VkInstance handle, VkPhysicalDevice native_phys_dev)
+{
+    struct wine_instance *instance = wine_instance_from_handle(handle);
+    unsigned int i;
+
+    for (i = 0; i < instance->phys_dev_count; ++i)
     {
-        UINT32 device;
-        UINT32 name;
-    } *params = arg;
-    struct vulkan_device *device = vulkan_device_from_handle(UlongToPtr(params->device));
-    return !!vk_funcs->p_vkGetDeviceProcAddr(device->host.device, UlongToPtr(params->name));
+        if (instance->phys_devs[i].obj.host.physical_device == native_phys_dev)
+            return instance->phys_devs[i].obj.client.physical_device;
+    }
+
+    ERR("Unknown native physical device: %p, instance %p, handle %p\n", native_phys_dev, instance, handle);
+    return NULL;
 }
diff --git a/dlls/winevulkan/vulkan_private.h b/dlls/winevulkan/vulkan_private.h
index 59b900930b3..9a6a4680af5 100644
--- a/dlls/winevulkan/vulkan_private.h
+++ b/dlls/winevulkan/vulkan_private.h
@@ -21,6 +21,7 @@
 #define __WINE_VULKAN_PRIVATE_H
 
 #include <pthread.h>
+#include <stdbool.h>
 
 #include "vulkan_loader.h"
 #include "vulkan_thunks.h"
@@ -41,24 +42,20 @@ static inline struct wine_cmd_buffer *wine_cmd_buffer_from_handle(VkCommandBuffe
     return (struct wine_cmd_buffer *)(UINT_PTR)client->unix_handle;
 }
 
-struct wine_queue
-{
-    struct vulkan_queue obj;
-
-    uint32_t family_index;
-    uint32_t queue_index;
-    VkDeviceQueueCreateFlags flags;
-};
+struct wine_semaphore;
 
-struct wine_device
+struct pending_d3d12_fence_op
 {
-    struct vulkan_device obj;
-    uint64_t queue_count;
-    struct wine_queue queues[];
+    /* Vulkan native local semaphore. */
+    struct local_timeline_semaphore local_sem;
+
+    /* Operation values. */
+    struct list entry;
+    uint64_t virtual_value;
+    uint64_t shared_physical_value;
+    struct wine_semaphore *semaphore;
 };
 
-C_ASSERT(sizeof(struct wine_device) == offsetof(struct wine_device, queues[0]));
-
 struct wine_debug_utils_messenger;
 
 struct wine_debug_report_callback
@@ -100,6 +97,8 @@ struct wine_instance
     struct rb_tree objects;
     pthread_rwlock_t objects_lock;
 
+    pthread_key_t transient_object_handle;
+
     /* We cache devices as we need to wrap them as they are dispatchable objects. */
     uint32_t phys_dev_count;
     struct wine_phys_dev phys_devs[];
@@ -118,11 +117,28 @@ static inline struct wine_cmd_pool *wine_cmd_pool_from_handle(VkCommandPool hand
     return (struct wine_cmd_pool *)(UINT_PTR)client->unix_handle;
 }
 
+struct keyed_mutex_shm
+{
+    pthread_mutex_t mutex;
+    uint64_t instance_id_counter;
+    uint64_t acquired_to_instance;
+    uint64_t key;
+    UINT64 timeline_value;
+    uint64_t timeline_queued_release;
+};
+
 struct wine_device_memory
 {
     VULKAN_OBJECT_HEADER( VkDeviceMemory, device_memory );
     VkDeviceSize size;
     void *vm_map;
+    VkExternalMemoryHandleTypeFlagBits handle_types;
+    BOOL inherit;
+    DWORD access;
+    HANDLE handle;
+    struct keyed_mutex_shm *keyed_mutex_shm;
+    VkSemaphore keyed_mutex_sem;
+    uint64_t keyed_mutex_instance_id;
 };
 
 static inline struct wine_device_memory *wine_device_memory_from_handle(VkDeviceMemory handle)
@@ -184,6 +200,38 @@ static inline void free_conversion_context(struct conversion_context *pool)
         free(entry);
 }
 
+struct wine_semaphore
+{
+    struct vulkan_semaphore obj;
+    VkSemaphore semaphore;
+
+    VkExternalSemaphoreHandleTypeFlagBits export_types;
+
+    /* mutable members */
+    VkExternalSemaphoreHandleTypeFlagBits handle_type;
+    struct list poll_entry;
+    struct list pending_waits;
+    struct list pending_signals;
+    HANDLE handle;
+    struct
+    {
+        /* Shared mem access mutex. The non-shared parts access is guarded with device global signaller_mutex. */
+        pthread_mutex_t mutex;
+        UINT64 virtual_value, physical_value;
+        uint64_t last_reset_physical;
+        uint64_t last_dropped_reset_physical;
+        struct
+        {
+            uint64_t physical_at_reset;
+            uint64_t virtual_before_reset;
+        }
+        reset_backlog[16];
+        uint32_t reset_backlog_count;
+    } *d3d12_fence_shm;
+    /* The Vulkan shared semaphore is only waited or signaled in signaller_worker(). */
+    VkSemaphore fence_timeline_semaphore;
+};
+
 static inline void *conversion_context_alloc(struct conversion_context *pool, size_t size)
 {
     if (pool->used + size <= sizeof(pool->buffer))
@@ -254,4 +302,16 @@ static inline void *find_next_struct(const void *s, VkStructureType t)
     return NULL;
 }
 
+static inline void init_unicode_string( UNICODE_STRING *str, const WCHAR *data )
+{
+    str->Length = lstrlenW(data) * sizeof(WCHAR);
+    str->MaximumLength = str->Length + sizeof(WCHAR);
+    str->Buffer = (WCHAR *)data;
+}
+
+#define MEMDUP(ctx, dst, src, count) dst = conversion_context_alloc((ctx), sizeof(*(dst)) * (count)); \
+    memcpy((void *)(dst), (src), sizeof(*(dst)) * (count));
+#define MEMDUP_VOID(ctx, dst, src, size) dst = conversion_context_alloc((ctx), size); \
+    memcpy((void *)(dst), (src), size);
+
 #endif /* __WINE_VULKAN_PRIVATE_H */
diff --git a/include/ddk/wdm.h b/include/ddk/wdm.h
index fcaf7b4a462..3e15ed150a9 100644
--- a/include/ddk/wdm.h
+++ b/include/ddk/wdm.h
@@ -1889,6 +1889,7 @@ NTSTATUS  WINAPI ObRegisterCallbacks(POB_CALLBACK_REGISTRATION, void**);
 NTSTATUS  WINAPI ObReferenceObjectByHandle(HANDLE,ACCESS_MASK,POBJECT_TYPE,KPROCESSOR_MODE,PVOID*,POBJECT_HANDLE_INFORMATION);
 NTSTATUS  WINAPI ObReferenceObjectByName(UNICODE_STRING*,ULONG,ACCESS_STATE*,ACCESS_MASK,POBJECT_TYPE,KPROCESSOR_MODE,void*,void**);
 NTSTATUS  WINAPI ObReferenceObjectByPointer(void*,ACCESS_MASK,POBJECT_TYPE,KPROCESSOR_MODE);
+NTSTATUS  WINAPI ObOpenObjectByPointer(void *,ULONG,ACCESS_STATE*,ACCESS_MASK,POBJECT_TYPE,KPROCESSOR_MODE,HANDLE*);
 void      WINAPI ObUnRegisterCallbacks(void*);
 
 NTSTATUS  WINAPI PoCallDriver(DEVICE_OBJECT*,IRP*);
diff --git a/include/wine/vulkan_driver.h b/include/wine/vulkan_driver.h
index 0579ea7773f..911230eb46e 100644
--- a/include/wine/vulkan_driver.h
+++ b/include/wine/vulkan_driver.h
@@ -45,6 +45,7 @@ struct vulkan_client_object
 
 #include "wine/vulkan.h"
 #include "wine/rbtree.h"
+#include "wine/list.h"
 
 /* Wine internal vulkan driver version, needs to be bumped upon vulkan_funcs changes. */
 #define WINE_VULKAN_DRIVER_VERSION 36
@@ -79,6 +80,7 @@ struct vulkan_instance
 #undef USE_VK_FUNC
     void (*p_insert_object)( struct vulkan_instance *instance, struct vulkan_object *obj );
     void (*p_remove_object)( struct vulkan_instance *instance, struct vulkan_object *obj );
+    uint32_t api_version;
 };
 
 static inline struct vulkan_instance *vulkan_instance_from_handle( VkInstance handle )
@@ -91,6 +93,7 @@ struct vulkan_physical_device
 {
     VULKAN_OBJECT_HEADER( VkPhysicalDevice, physical_device );
     struct vulkan_instance *instance;
+    uint32_t api_version;
     bool has_swapchain_maintenance1;
 };
 
@@ -100,6 +103,12 @@ static inline struct vulkan_physical_device *vulkan_physical_device_from_handle(
     return (struct vulkan_physical_device *)(UINT_PTR)client->unix_handle;
 }
 
+struct local_timeline_semaphore
+{
+    VkSemaphore sem;
+    uint64_t value;
+};
+
 struct vulkan_device
 {
     VULKAN_OBJECT_HEADER( VkDevice, device );
@@ -107,6 +116,21 @@ struct vulkan_device
 #define USE_VK_FUNC(x) PFN_ ## x p_ ## x;
     ALL_VK_DEVICE_FUNCS
 #undef USE_VK_FUNC
+    uint64_t queue_count;
+    struct vulkan_queue *queues;
+    VkQueueFamilyProperties *queue_props;
+
+    pthread_t signaller_thread;
+    pthread_mutex_t signaller_mutex;
+    BOOL stop;
+    struct list free_fence_ops_list;
+    struct list sem_poll_list;
+    struct local_timeline_semaphore sem_poll_update;
+    pthread_cond_t sem_poll_updated_cond;
+    uint64_t sem_poll_update_value; /* set to sem_poll_update.value by signaller thread once update is processed. */
+    unsigned int allocated_fence_ops_count;
+
+    BOOL keyed_mutexes_enabled;
 };
 
 static inline struct vulkan_device *vulkan_device_from_handle( VkDevice handle )
@@ -119,6 +143,9 @@ struct vulkan_queue
 {
     VULKAN_OBJECT_HEADER( VkQueue, queue );
     struct vulkan_device *device;
+    uint32_t family_index;
+    uint32_t queue_index;
+    VkDeviceQueueCreateFlags flags;
 };
 
 static inline struct vulkan_queue *vulkan_queue_from_handle( VkQueue handle )
@@ -148,6 +175,17 @@ static inline struct vulkan_swapchain *vulkan_swapchain_from_handle( VkSwapchain
     return (struct vulkan_swapchain *)(UINT_PTR)handle;
 }
 
+struct vulkan_semaphore
+{
+    VULKAN_OBJECT_HEADER( VkSemaphore, semaphore );
+    BOOL d3d12_fence;
+};
+
+static inline struct vulkan_semaphore *vulkan_semaphore_from_handle( VkSemaphore handle )
+{
+    return (struct vulkan_semaphore *)(UINT_PTR)handle;
+}
+
 struct vulkan_funcs
 {
     /* Vulkan global functions. These are the only calls at this point a graphics driver
diff --git a/loader/wine.inf.in b/loader/wine.inf.in
index 8a8e56d633a..f54d79da0a3 100644
--- a/loader/wine.inf.in
+++ b/loader/wine.inf.in
@@ -162,6 +162,7 @@ AddService=Winmgmt,0,WinmgmtService
 AddService=wuauserv,0,wuauService
 AddService=NDIS,0x800,NDISService
 AddService=nsiproxy,0x800,NsiProxyService
+AddService=SharedGpuResources,0x800,SharedGpuResourcesService
 
 [DefaultInstall.ntx86.Services]
 AddService=BITS,0,BITSService
@@ -182,6 +183,7 @@ AddService=Winmgmt,0,WinmgmtService
 AddService=wuauserv,0,wuauService
 AddService=NDIS,0x800,NDISService
 AddService=nsiproxy,0x800,NsiProxyService
+AddService=SharedGpuResources,0x800,SharedGpuResourcesService
 
 [DefaultInstall.ntamd64.Services]
 AddService=BITS,0,BITSService
@@ -202,6 +204,7 @@ AddService=Winmgmt,0,WinmgmtService
 AddService=wuauserv,0,wuauService
 AddService=NDIS,0x800,NDISService
 AddService=nsiproxy,0x800,NsiProxyService
+AddService=SharedGpuResources,0x800,SharedGpuResourcesService
 
 [DefaultInstall.ntarm64.Services]
 AddService=BITS,0,BITSService
@@ -222,6 +225,7 @@ AddService=Winmgmt,0,WinmgmtService
 AddService=wuauserv,0,wuauService
 AddService=NDIS,0x800,NDISService
 AddService=nsiproxy,0x800,NsiProxyService
+AddService=SharedGpuResources,0x800,SharedGpuResourcesService
 
 [Strings]
 MciExtStr="Software\Microsoft\Windows NT\CurrentVersion\MCI Extensions"
@@ -1204,6 +1208,15 @@ LoadOrderGroup="System Bus Extender"
 [NsiProxyServiceKeys]
 HKR,,"Tag",0x10001,1
 
+[SharedGpuResourcesService]
+Description="Shared GPU Resources Manager Service"
+DisplayName="Shared GPU Resources Manager"
+ServiceBinary="%12%\sharedgpures.sys"
+ServiceType=1
+StartType=2
+ErrorControl=1
+LoadOrderGroup="System Bus Extender"
+
 [RpcSsService]
 Description="RPC service"
 DisplayName="Remote Procedure Call (RPC)"
